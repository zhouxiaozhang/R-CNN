{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "import pickle\n",
    "import CNN\n",
    "import math\n",
    "from CNN import malware_CNN\n",
    "from config import get_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data parameters\n",
    "tf.flags.DEFINE_string(\"data_path\", \"/home/zx/gram3_gain1000/data_process_data_original_value_train\",\"data_path\")\n",
    "tf.flags.DEFINE_string(\"data_path1\", \"/home/zx/gram3_gain1000/data_process_data_original_value_test\",\"data_path\")\n",
    "tf.flags.DEFINE_string(\"save_path\" , \"/home/zx/cuckoo_1000/session_save/\",\"Model output directory.\")\n",
    "tf.flags.DEFINE_string(\"board_path\", \"/home/zx/cuckoo_1000/tensor_board/\",\"Tensor board output directory.\")\n",
    "tf.flags.DEFINE_string(\"log_path\", \"/home/zx/cuckoo_1000/log.log\", \"log output path.\")\n",
    "#Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\",True,\"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\",False,\"Log placement of ops on devices\")\n",
    "#train Parameters\n",
    "tf.flags.DEFINE_string(\"evaluate_every\",2,\"Evaluate model on dev set after this many epochs\")\n",
    "\n",
    "FLAGS =tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#log\n",
    "LOG = None\n",
    "def init_logger():\n",
    "    global LOG\n",
    "\n",
    "    LOG = logging.getLogger('seq')\n",
    "    LOG.setLevel(logging.DEBUG)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    file_handler = logging.FileHandler(filename=FLAGS.log_path, encoding=\"utf-8\")\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    LOG.addHandler(file_handler)\n",
    "\n",
    "    stream_handler = logging.StreamHandler(sys.stdout)\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    LOG.addHandler(stream_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        raw_x, raw_y = pickle.load(f)\n",
    "#         l = len(raw_x)\n",
    "#         train_data = []\n",
    "#         train_lable=[]\n",
    "#         test_data = []\n",
    "#         test_lable=[]\n",
    "#         pos_1 = int(l * 0.9)\n",
    "#         train_data = raw_x[:pos_1]\n",
    "#         train_lable=raw_y[:pos_1]\n",
    "#         test_data  = raw_x[pos_1:]\n",
    "#         test_lable  = raw_y[pos_1:]\n",
    "        #x_train,x_dev,y_train,y_dev=train_test_split(raw_x, raw_y,test_size=0.1)\n",
    "        return raw_x,raw_y\n",
    "        #return x_train,x_dev,y_train,y_dev\n",
    "    \n",
    "def batch_iter(x_data,y_data, batch_size, num_epochs, shuffle=True):\n",
    "    x_data=np.array(x_data)\n",
    "    y_data=np.array(y_data)\n",
    "    data_size =len(x_data)\n",
    "    num_batches_per_epoch = int((data_size-1) / batch_size)+1\n",
    "    #for epoch in range(num_epochs):\n",
    "    if shuffle:\n",
    "        shuffle_indices=np.random.permutation(data_size)\n",
    "        shuffled_data_x=x_data[shuffle_indices]\n",
    "        shuffled_data_y=y_data[shuffle_indices]\n",
    "                \n",
    "    else:\n",
    "        shuffled_data_x=x_data\n",
    "        shuffled_data_y=y_data\n",
    "    for batch_num in range(num_batches_per_epoch):\n",
    "        start_index=batch_num*batch_size\n",
    "        end_index=min((batch_num+1)*batch_size,data_size)\n",
    "        yield shuffled_data_x[start_index:end_index],shuffled_data_y[start_index:end_index]\n",
    "        \n",
    "def real_len(batches,max_pool):\n",
    "    return[ np.ceil(np.argmin(batch+[0])*1.0/max_pool) for batch in batches]\n",
    "            \n",
    "                    \n",
    "def run_epoch(\n",
    "        session,\n",
    "        x_batch,\n",
    "        y_batch,\n",
    "        dropout,\n",
    "        model,\n",
    "        global_step,\n",
    "        summary_op,\n",
    "        eval_op=None,\n",
    "        verbose=False,\n",
    "        max_pool=4,\n",
    "        embedding_dim=64\n",
    "       \n",
    "):\n",
    "    #feed,give,input [array,array]\n",
    "    feed_dict={\n",
    "        model.input_x:x_batch,\n",
    "        model.input_y:y_batch,\n",
    "        model.dropout_keep_prob:dropout,\n",
    "        model.batch_size:len(x_batch),\n",
    "        model.real_len:real_len(x_batch,max_pool),\n",
    "        model.pad:np.zeros([len(x_batch),1,embedding_dim,1])\n",
    "              }\n",
    "    #out\n",
    "    fetches = {\n",
    "        \"loss\": model.loss,\n",
    "        \"accuracy\": model.accuracy,\n",
    "        \"global_step\":global_step,\n",
    "        \"summary_op\" :summary_op\n",
    "    }\n",
    "    if eval_op is not None:\n",
    "        fetches[\"eval_op\"] = eval_op\n",
    "    \n",
    "    fetches_ret = session.run(fetches, feed_dict)\n",
    "    if verbose:\n",
    "        LOG.info( \"step: %d,loss: %.3f accuracy: %.3f\" \n",
    "                  % ( fetches_ret[\"global_step\"], fetches_ret[\"loss\"],fetches_ret[\"accuracy\"])\n",
    "                 )\n",
    "    return fetches_ret[\"accuracy\"], fetches_ret[\"loss\"],fetches_ret[\"summary_op\"]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    #training \n",
    "    x_train,y_train=load_data(FLAGS.data_path)\n",
    "    x_dev,y_dev=load_data(FLAGS.data_path1)\n",
    "    init_logger()\n",
    "    train_config=get_config(\"train\")\n",
    "    valid_config=get_config(\"valid\")\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf=tf.ConfigProto(allow_soft_placement=FLAGS.allow_soft_placement,log_device_placement=FLAGS.log_device_placement)\n",
    "        sess=tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            cnn=malware_CNN(config=train_config)\n",
    "            global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "            trainable_vars = tf.trainable_variables()\n",
    "            grads, _ = tf.clip_by_global_norm( tf.gradients(cnn.loss, trainable_vars),train_config.MAX_GRAD)\n",
    "            optimizer = tf.train.AdamOptimizer(train_config.learning_rate)\n",
    "            train_op = optimizer.apply_gradients( zip(grads, trainable_vars),global_step=global_step)\n",
    "        \n",
    "            #optimizer=tf.train.RMSPropOptimizer(train_config.learning_rate,decay=0.9)\n",
    "            #grads_and_vars=optimizer.compute_gradients(cnn.loss)\n",
    "            #train_op=optimizer.apply_gradients(grads_and_vars,global_step=global_step)\n",
    "            \n",
    "            #keep track of gradient values and sparsity\n",
    "            grad_summaries=[]\n",
    "            for g,v in zip(grads, trainable_vars):\n",
    "                if g is not None:\n",
    "                    grad_hist_summary=tf.summary.histogram(\"{}/grad/hist\".format(v.name),g)\n",
    "                    sparsity_summary=tf.summary.scalar(\"{}/grad/sparsity\".format(v.name),tf.nn.zero_fraction(g))\n",
    "                    grad_summaries.append(grad_hist_summary)\n",
    "                    grad_summaries.append(sparsity_summary)\n",
    "            grad_summaries_merged=tf.summary.merge(grad_summaries)\n",
    "            #Summaries for loss and acc\n",
    "            loss_summary=tf.summary.scalar(\"loss\",cnn.loss)\n",
    "            acc_summary=tf.summary.scalar(\"accuracy\",cnn.accuracy)\n",
    "            \n",
    "            #Train summaries\n",
    "            train_summary_op=tf.summary.merge([grad_summaries_merged,loss_summary,acc_summary])\n",
    "            train_summary_dir=os.path.join(FLAGS.board_path,\"summaries\",\"train\")\n",
    "            train_summary_write=tf.summary.FileWriter(train_summary_dir,sess.graph)\n",
    "            #Dev summaries\n",
    "            dev_summary_op=tf.summary.merge([loss_summary,acc_summary])\n",
    "            dev_summary_dir=os.path.join(FLAGS.board_path,\"summaries\",\"dev\")\n",
    "            dev_summary_write=tf.summary.FileWriter(dev_summary_dir,sess.graph)\n",
    "            \n",
    "            \n",
    "            #init\n",
    "            checkpoint_dir=os.path.join(FLAGS.save_path,\"checkpoints\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            checkpoint_prefix=os.path.join(checkpoint_dir,\"model\")\n",
    "            \n",
    "            saver=tf.train.Saver(tf.all_variables())\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            #generate batches\n",
    "            \n",
    "            best_acc,best_at_step=0,0\n",
    "            #training loop\n",
    "            accuracy_total=0.0\n",
    "            loss_total=0.0\n",
    "            for epoch_id in range(0, train_config.num_epochs):\n",
    "                accuracy_total=0.0\n",
    "                loss_total=0.0\n",
    "                batches=batch_iter(x_train,y_train,train_config.batch_size,train_config.num_epochs)\n",
    "                for batch_x,batch_y in batches:\n",
    "                    acc_train,loss_train,summaries=run_epoch( sess,batch_x,batch_y,dropout=train_config.dropout_keep_prob,model=cnn, eval_op=train_op,verbose=True, global_step= global_step,summary_op=train_summary_op,max_pool=train_config.max_pool_size)\n",
    "                    accuracy_total+=acc_train\n",
    "                    loss_total+=loss_train\n",
    "                    current_step=tf.train.global_step(sess,global_step)\n",
    "                    train_summary_write.add_summary(summaries,epoch_id)\n",
    "                    # LOG.info( \"loss_total: %.3f accuracy_total: %.3f\"% ( loss_total,accuracy_total))\n",
    "                accuracy_total=accuracy_total/ (int((len(x_train)-1) / train_config.batch_size)+1)\n",
    "                loss_total=loss_total/(int((len(x_train)-1) / train_config.batch_size)+1)\n",
    "                LOG.info(\"\\ntrain_epoch:%.3f\"% epoch_id)\n",
    "                LOG.info( \"loss_total: %.3f accuracy_total: %.3f\" \n",
    "                  % ( loss_total,accuracy_total))\n",
    "                if epoch_id%FLAGS.evaluate_every==0:\n",
    "                    LOG.info(\"\\nEvaluation:%.3f\"%epoch_id)\n",
    "                    acc,loss,summaries=run_epoch( sess,x_dev,y_dev,dropout=valid_config.dropout_keep_prob,model=cnn,verbose=True, global_step= global_step,summary_op=dev_summary_op,max_pool=valid_config.max_pool_size) \n",
    "                    LOG.info(\"\\nEvaluation-end\")\n",
    "                    dev_summary_write.add_summary(summaries,epoch_id)\n",
    "                    if acc>=best_acc:\n",
    "                        best_acc,best_at_step=acc,epoch_id\n",
    "                        path=saver.save(sess,checkpoint_prefix,global_step=global_step)\n",
    "                        LOG.info(\"Saving model to %s at epoch %d.\" % (path,epoch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    if not FLAGS.data_path:\n",
    "        raise ValueError(\"Must set --data_path to data file\")\n",
    "    train()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conv', TensorShape([Dimension(None), Dimension(1000), Dimension(1), Dimension(20)]))\n",
      "('pooled_max', TensorShape([Dimension(None), Dimension(250), Dimension(1), Dimension(20)]))\n",
      "('pooled', TensorShape([Dimension(None), Dimension(250), Dimension(20)]))\n",
      "('conv', TensorShape([Dimension(None), Dimension(1000), Dimension(1), Dimension(20)]))\n",
      "('pooled_max', TensorShape([Dimension(None), Dimension(250), Dimension(1), Dimension(20)]))\n",
      "('pooled', TensorShape([Dimension(None), Dimension(250), Dimension(20)]))\n",
      "('conv', TensorShape([Dimension(None), Dimension(1000), Dimension(1), Dimension(20)]))\n",
      "('pooled_max', TensorShape([Dimension(None), Dimension(250), Dimension(1), Dimension(20)]))\n",
      "('pooled', TensorShape([Dimension(None), Dimension(250), Dimension(20)]))\n",
      "('self.h_pool', TensorShape([Dimension(None), Dimension(250), Dimension(60)]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zx/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name embedded:0/grad/hist is illegal; using embedded_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name embedded:0/grad/sparsity is illegal; using embedded_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name LSTM/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0/grad/hist is illegal; using LSTM/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name LSTM/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0/grad/sparsity is illegal; using LSTM/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name LSTM/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0/grad/hist is illegal; using LSTM/rnn/multi_rnn_cell/cell_0/lstm_cell/bias_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name LSTM/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0/grad/sparsity is illegal; using LSTM/rnn/multi_rnn_cell/cell_0/lstm_cell/bias_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name LSTM/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0/grad/hist is illegal; using LSTM/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name LSTM/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0/grad/sparsity is illegal; using LSTM/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name LSTM/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0/grad/hist is illegal; using LSTM/rnn/multi_rnn_cell/cell_1/lstm_cell/bias_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name LSTM/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0/grad/sparsity is illegal; using LSTM/rnn/multi_rnn_cell/cell_1/lstm_cell/bias_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name output/softmax_w:0/grad/hist is illegal; using output/softmax_w_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name output/softmax_w:0/grad/sparsity is illegal; using output/softmax_w_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name output/softmax_b:0/grad/hist is illegal; using output/softmax_b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name output/softmax_b:0/grad/sparsity is illegal; using output/softmax_b_0/grad/sparsity instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-a629c86cee62>:53: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "2017-09-06 08:23:26,461 - INFO - step: 1,loss: 0.726 accuracy: 0.492\n",
      "2017-09-06 08:23:27,692 - INFO - step: 2,loss: 2.898 accuracy: 0.500\n",
      "2017-09-06 08:23:28,908 - INFO - step: 3,loss: 0.879 accuracy: 0.586\n",
      "2017-09-06 08:23:30,127 - INFO - step: 4,loss: 1.294 accuracy: 0.555\n",
      "2017-09-06 08:23:31,335 - INFO - step: 5,loss: 0.728 accuracy: 0.680\n",
      "2017-09-06 08:23:32,575 - INFO - step: 6,loss: 0.592 accuracy: 0.750\n",
      "2017-09-06 08:23:33,814 - INFO - step: 7,loss: 0.756 accuracy: 0.555\n",
      "2017-09-06 08:23:35,041 - INFO - step: 8,loss: 0.598 accuracy: 0.664\n",
      "2017-09-06 08:23:36,290 - INFO - step: 9,loss: 0.648 accuracy: 0.641\n",
      "2017-09-06 08:23:37,505 - INFO - step: 10,loss: 0.534 accuracy: 0.766\n",
      "2017-09-06 08:23:38,702 - INFO - step: 11,loss: 0.559 accuracy: 0.711\n",
      "2017-09-06 08:23:39,928 - INFO - step: 12,loss: 0.609 accuracy: 0.664\n",
      "2017-09-06 08:23:41,163 - INFO - step: 13,loss: 0.614 accuracy: 0.625\n",
      "2017-09-06 08:23:42,413 - INFO - step: 14,loss: 0.489 accuracy: 0.742\n",
      "2017-09-06 08:23:43,642 - INFO - step: 15,loss: 0.557 accuracy: 0.680\n",
      "2017-09-06 08:23:44,895 - INFO - step: 16,loss: 0.654 accuracy: 0.672\n",
      "2017-09-06 08:23:46,122 - INFO - step: 17,loss: 0.540 accuracy: 0.766\n",
      "2017-09-06 08:23:47,383 - INFO - step: 18,loss: 0.523 accuracy: 0.719\n",
      "2017-09-06 08:23:48,622 - INFO - step: 19,loss: 0.589 accuracy: 0.680\n",
      "2017-09-06 08:23:53,688 - INFO - step: 20,loss: 0.559 accuracy: 0.738\n",
      "2017-09-06 08:23:53,693 - INFO - \n",
      "train_epoch:0.000\n",
      "2017-09-06 08:23:53,696 - INFO - loss_total: 0.767 accuracy_total: 0.659\n",
      "2017-09-06 08:23:53,697 - INFO - \n",
      "Evaluation:0.000\n",
      "2017-09-06 08:23:54,443 - INFO - step: 20,loss: 0.499 accuracy: 0.770\n",
      "2017-09-06 08:23:54,445 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:23:54,699 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-20 at epoch 0.\n",
      "2017-09-06 08:23:55,951 - INFO - step: 21,loss: 0.495 accuracy: 0.750\n",
      "2017-09-06 08:23:57,199 - INFO - step: 22,loss: 0.471 accuracy: 0.750\n",
      "2017-09-06 08:23:58,471 - INFO - step: 23,loss: 0.466 accuracy: 0.797\n",
      "2017-09-06 08:23:59,702 - INFO - step: 24,loss: 0.490 accuracy: 0.750\n",
      "2017-09-06 08:24:00,935 - INFO - step: 25,loss: 0.539 accuracy: 0.727\n",
      "2017-09-06 08:24:02,177 - INFO - step: 26,loss: 0.548 accuracy: 0.742\n",
      "2017-09-06 08:24:03,401 - INFO - step: 27,loss: 0.508 accuracy: 0.820\n",
      "2017-09-06 08:24:04,636 - INFO - step: 28,loss: 0.512 accuracy: 0.773\n",
      "2017-09-06 08:24:05,823 - INFO - step: 29,loss: 0.486 accuracy: 0.773\n",
      "2017-09-06 08:24:07,047 - INFO - step: 30,loss: 0.471 accuracy: 0.773\n",
      "2017-09-06 08:24:08,285 - INFO - step: 31,loss: 0.490 accuracy: 0.766\n",
      "2017-09-06 08:24:09,468 - INFO - step: 32,loss: 0.517 accuracy: 0.742\n",
      "2017-09-06 08:24:10,691 - INFO - step: 33,loss: 0.472 accuracy: 0.789\n",
      "2017-09-06 08:24:11,910 - INFO - step: 34,loss: 0.502 accuracy: 0.766\n",
      "2017-09-06 08:24:13,122 - INFO - step: 35,loss: 0.501 accuracy: 0.766\n",
      "2017-09-06 08:24:14,333 - INFO - step: 36,loss: 0.451 accuracy: 0.773\n",
      "2017-09-06 08:24:15,548 - INFO - step: 37,loss: 0.488 accuracy: 0.750\n",
      "2017-09-06 08:24:16,792 - INFO - step: 38,loss: 0.494 accuracy: 0.773\n",
      "2017-09-06 08:24:17,990 - INFO - step: 39,loss: 0.424 accuracy: 0.797\n",
      "2017-09-06 08:24:19,122 - INFO - step: 40,loss: 0.470 accuracy: 0.800\n",
      "2017-09-06 08:24:19,125 - INFO - \n",
      "train_epoch:1.000\n",
      "2017-09-06 08:24:19,127 - INFO - loss_total: 0.490 accuracy_total: 0.769\n",
      "2017-09-06 08:24:20,380 - INFO - step: 41,loss: 0.481 accuracy: 0.742\n",
      "2017-09-06 08:24:21,595 - INFO - step: 42,loss: 0.449 accuracy: 0.773\n",
      "2017-09-06 08:24:22,816 - INFO - step: 43,loss: 0.407 accuracy: 0.828\n",
      "2017-09-06 08:24:24,038 - INFO - step: 44,loss: 0.487 accuracy: 0.805\n",
      "2017-09-06 08:24:25,280 - INFO - step: 45,loss: 0.396 accuracy: 0.820\n",
      "2017-09-06 08:24:26,493 - INFO - step: 46,loss: 0.424 accuracy: 0.820\n",
      "2017-09-06 08:24:27,698 - INFO - step: 47,loss: 0.502 accuracy: 0.734\n",
      "2017-09-06 08:24:28,917 - INFO - step: 48,loss: 0.450 accuracy: 0.828\n",
      "2017-09-06 08:24:30,165 - INFO - step: 49,loss: 0.441 accuracy: 0.781\n",
      "2017-09-06 08:24:31,359 - INFO - step: 50,loss: 0.430 accuracy: 0.859\n",
      "2017-09-06 08:24:32,551 - INFO - step: 51,loss: 0.342 accuracy: 0.828\n",
      "2017-09-06 08:24:33,819 - INFO - step: 52,loss: 0.445 accuracy: 0.836\n",
      "2017-09-06 08:24:35,044 - INFO - step: 53,loss: 0.458 accuracy: 0.836\n",
      "2017-09-06 08:24:36,227 - INFO - step: 54,loss: 0.428 accuracy: 0.820\n",
      "2017-09-06 08:24:37,434 - INFO - step: 55,loss: 0.487 accuracy: 0.812\n",
      "2017-09-06 08:24:38,648 - INFO - step: 56,loss: 0.376 accuracy: 0.852\n",
      "2017-09-06 08:24:39,855 - INFO - step: 57,loss: 0.463 accuracy: 0.828\n",
      "2017-09-06 08:24:41,056 - INFO - step: 58,loss: 0.479 accuracy: 0.773\n",
      "2017-09-06 08:24:42,272 - INFO - step: 59,loss: 0.397 accuracy: 0.852\n",
      "2017-09-06 08:24:43,389 - INFO - step: 60,loss: 0.424 accuracy: 0.800\n",
      "2017-09-06 08:24:43,393 - INFO - \n",
      "train_epoch:2.000\n",
      "2017-09-06 08:24:43,395 - INFO - loss_total: 0.438 accuracy_total: 0.811\n",
      "2017-09-06 08:24:43,397 - INFO - \n",
      "Evaluation:2.000\n",
      "2017-09-06 08:24:43,940 - INFO - step: 60,loss: 0.463 accuracy: 0.791\n",
      "2017-09-06 08:24:43,941 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:24:44,176 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-60 at epoch 2.\n",
      "2017-09-06 08:24:45,400 - INFO - step: 61,loss: 0.429 accuracy: 0.789\n",
      "2017-09-06 08:24:46,640 - INFO - step: 62,loss: 0.374 accuracy: 0.867\n",
      "2017-09-06 08:24:47,870 - INFO - step: 63,loss: 0.387 accuracy: 0.891\n",
      "2017-09-06 08:24:49,085 - INFO - step: 64,loss: 0.365 accuracy: 0.867\n",
      "2017-09-06 08:24:50,357 - INFO - step: 65,loss: 0.387 accuracy: 0.828\n",
      "2017-09-06 08:24:51,577 - INFO - step: 66,loss: 0.366 accuracy: 0.852\n",
      "2017-09-06 08:24:52,796 - INFO - step: 67,loss: 0.372 accuracy: 0.820\n",
      "2017-09-06 08:24:54,032 - INFO - step: 68,loss: 0.440 accuracy: 0.812\n",
      "2017-09-06 08:24:55,246 - INFO - step: 69,loss: 0.402 accuracy: 0.852\n",
      "2017-09-06 08:24:56,491 - INFO - step: 70,loss: 0.481 accuracy: 0.781\n",
      "2017-09-06 08:24:57,701 - INFO - step: 71,loss: 0.432 accuracy: 0.789\n",
      "2017-09-06 08:24:58,913 - INFO - step: 72,loss: 0.365 accuracy: 0.828\n",
      "2017-09-06 08:25:00,108 - INFO - step: 73,loss: 0.370 accuracy: 0.859\n",
      "2017-09-06 08:25:01,335 - INFO - step: 74,loss: 0.397 accuracy: 0.812\n",
      "2017-09-06 08:25:02,566 - INFO - step: 75,loss: 0.383 accuracy: 0.828\n",
      "2017-09-06 08:25:03,811 - INFO - step: 76,loss: 0.387 accuracy: 0.766\n",
      "2017-09-06 08:25:05,025 - INFO - step: 77,loss: 0.387 accuracy: 0.836\n",
      "2017-09-06 08:25:06,244 - INFO - step: 78,loss: 0.342 accuracy: 0.836\n",
      "2017-09-06 08:25:07,460 - INFO - step: 79,loss: 0.389 accuracy: 0.859\n",
      "2017-09-06 08:25:08,582 - INFO - step: 80,loss: 0.329 accuracy: 0.892\n",
      "2017-09-06 08:25:08,585 - INFO - \n",
      "train_epoch:3.000\n",
      "2017-09-06 08:25:08,587 - INFO - loss_total: 0.389 accuracy_total: 0.833\n",
      "2017-09-06 08:25:09,824 - INFO - step: 81,loss: 0.299 accuracy: 0.859\n",
      "2017-09-06 08:25:11,074 - INFO - step: 82,loss: 0.347 accuracy: 0.875\n",
      "2017-09-06 08:25:12,293 - INFO - step: 83,loss: 0.345 accuracy: 0.859\n",
      "2017-09-06 08:25:13,506 - INFO - step: 84,loss: 0.308 accuracy: 0.859\n",
      "2017-09-06 08:25:14,732 - INFO - step: 85,loss: 0.384 accuracy: 0.805\n",
      "2017-09-06 08:25:15,940 - INFO - step: 86,loss: 0.435 accuracy: 0.820\n",
      "2017-09-06 08:25:17,154 - INFO - step: 87,loss: 0.360 accuracy: 0.852\n",
      "2017-09-06 08:25:18,368 - INFO - step: 88,loss: 0.359 accuracy: 0.859\n",
      "2017-09-06 08:25:19,586 - INFO - step: 89,loss: 0.393 accuracy: 0.797\n",
      "2017-09-06 08:25:20,807 - INFO - step: 90,loss: 0.327 accuracy: 0.898\n",
      "2017-09-06 08:25:22,014 - INFO - step: 91,loss: 0.444 accuracy: 0.773\n",
      "2017-09-06 08:25:23,230 - INFO - step: 92,loss: 0.368 accuracy: 0.828\n",
      "2017-09-06 08:25:24,441 - INFO - step: 93,loss: 0.371 accuracy: 0.836\n",
      "2017-09-06 08:25:25,657 - INFO - step: 94,loss: 0.301 accuracy: 0.922\n",
      "2017-09-06 08:25:26,868 - INFO - step: 95,loss: 0.418 accuracy: 0.820\n",
      "2017-09-06 08:25:28,075 - INFO - step: 96,loss: 0.420 accuracy: 0.859\n",
      "2017-09-06 08:25:29,299 - INFO - step: 97,loss: 0.321 accuracy: 0.883\n",
      "2017-09-06 08:25:30,522 - INFO - step: 98,loss: 0.341 accuracy: 0.867\n",
      "2017-09-06 08:25:31,711 - INFO - step: 99,loss: 0.384 accuracy: 0.852\n",
      "2017-09-06 08:25:32,848 - INFO - step: 100,loss: 0.334 accuracy: 0.831\n",
      "2017-09-06 08:25:32,851 - INFO - \n",
      "train_epoch:4.000\n",
      "2017-09-06 08:25:32,853 - INFO - loss_total: 0.363 accuracy_total: 0.848\n",
      "2017-09-06 08:25:32,855 - INFO - \n",
      "Evaluation:4.000\n",
      "2017-09-06 08:25:33,398 - INFO - step: 100,loss: 0.318 accuracy: 0.881\n",
      "2017-09-06 08:25:33,399 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:25:33,627 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-100 at epoch 4.\n",
      "2017-09-06 08:25:34,842 - INFO - step: 101,loss: 0.383 accuracy: 0.828\n",
      "2017-09-06 08:25:36,064 - INFO - step: 102,loss: 0.305 accuracy: 0.891\n",
      "2017-09-06 08:25:37,283 - INFO - step: 103,loss: 0.306 accuracy: 0.867\n",
      "2017-09-06 08:25:38,503 - INFO - step: 104,loss: 0.326 accuracy: 0.875\n",
      "2017-09-06 08:25:39,730 - INFO - step: 105,loss: 0.324 accuracy: 0.867\n",
      "2017-09-06 08:25:40,954 - INFO - step: 106,loss: 0.312 accuracy: 0.875\n",
      "2017-09-06 08:25:42,167 - INFO - step: 107,loss: 0.345 accuracy: 0.836\n",
      "2017-09-06 08:25:43,385 - INFO - step: 108,loss: 0.386 accuracy: 0.789\n",
      "2017-09-06 08:25:44,606 - INFO - step: 109,loss: 0.366 accuracy: 0.828\n",
      "2017-09-06 08:25:45,828 - INFO - step: 110,loss: 0.282 accuracy: 0.875\n",
      "2017-09-06 08:25:47,063 - INFO - step: 111,loss: 0.342 accuracy: 0.875\n",
      "2017-09-06 08:25:48,270 - INFO - step: 112,loss: 0.364 accuracy: 0.859\n",
      "2017-09-06 08:25:49,512 - INFO - step: 113,loss: 0.446 accuracy: 0.797\n",
      "2017-09-06 08:25:50,718 - INFO - step: 114,loss: 0.375 accuracy: 0.852\n",
      "2017-09-06 08:25:51,931 - INFO - step: 115,loss: 0.265 accuracy: 0.883\n",
      "2017-09-06 08:25:53,172 - INFO - step: 116,loss: 0.367 accuracy: 0.875\n",
      "2017-09-06 08:25:54,395 - INFO - step: 117,loss: 0.308 accuracy: 0.914\n",
      "2017-09-06 08:25:55,609 - INFO - step: 118,loss: 0.352 accuracy: 0.867\n",
      "2017-09-06 08:25:56,864 - INFO - step: 119,loss: 0.300 accuracy: 0.898\n",
      "2017-09-06 08:25:57,977 - INFO - step: 120,loss: 0.355 accuracy: 0.846\n",
      "2017-09-06 08:25:57,981 - INFO - \n",
      "train_epoch:5.000\n",
      "2017-09-06 08:25:57,983 - INFO - loss_total: 0.340 accuracy_total: 0.860\n",
      "2017-09-06 08:25:59,225 - INFO - step: 121,loss: 0.321 accuracy: 0.875\n",
      "2017-09-06 08:26:00,416 - INFO - step: 122,loss: 0.320 accuracy: 0.836\n",
      "2017-09-06 08:26:01,627 - INFO - step: 123,loss: 0.380 accuracy: 0.859\n",
      "2017-09-06 08:26:02,862 - INFO - step: 124,loss: 0.386 accuracy: 0.844\n",
      "2017-09-06 08:26:04,085 - INFO - step: 125,loss: 0.286 accuracy: 0.891\n",
      "2017-09-06 08:26:05,285 - INFO - step: 126,loss: 0.358 accuracy: 0.867\n",
      "2017-09-06 08:26:06,506 - INFO - step: 127,loss: 0.299 accuracy: 0.859\n",
      "2017-09-06 08:26:07,695 - INFO - step: 128,loss: 0.326 accuracy: 0.852\n",
      "2017-09-06 08:26:08,914 - INFO - step: 129,loss: 0.305 accuracy: 0.914\n",
      "2017-09-06 08:26:10,132 - INFO - step: 130,loss: 0.264 accuracy: 0.914\n",
      "2017-09-06 08:26:11,322 - INFO - step: 131,loss: 0.377 accuracy: 0.820\n",
      "2017-09-06 08:26:12,502 - INFO - step: 132,loss: 0.433 accuracy: 0.812\n",
      "2017-09-06 08:26:13,706 - INFO - step: 133,loss: 0.309 accuracy: 0.859\n",
      "2017-09-06 08:26:14,914 - INFO - step: 134,loss: 0.276 accuracy: 0.922\n",
      "2017-09-06 08:26:16,146 - INFO - step: 135,loss: 0.451 accuracy: 0.805\n",
      "2017-09-06 08:26:17,364 - INFO - step: 136,loss: 0.303 accuracy: 0.859\n",
      "2017-09-06 08:26:18,584 - INFO - step: 137,loss: 0.380 accuracy: 0.852\n",
      "2017-09-06 08:26:19,798 - INFO - step: 138,loss: 0.312 accuracy: 0.883\n",
      "2017-09-06 08:26:21,059 - INFO - step: 139,loss: 0.489 accuracy: 0.805\n",
      "2017-09-06 08:26:22,158 - INFO - step: 140,loss: 0.268 accuracy: 0.892\n",
      "2017-09-06 08:26:22,161 - INFO - \n",
      "train_epoch:6.000\n",
      "2017-09-06 08:26:22,163 - INFO - loss_total: 0.342 accuracy_total: 0.861\n",
      "2017-09-06 08:26:22,164 - INFO - \n",
      "Evaluation:6.000\n",
      "2017-09-06 08:26:22,708 - INFO - step: 140,loss: 0.321 accuracy: 0.871\n",
      "2017-09-06 08:26:22,710 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:26:23,945 - INFO - step: 141,loss: 0.278 accuracy: 0.930\n",
      "2017-09-06 08:26:25,133 - INFO - step: 142,loss: 0.387 accuracy: 0.844\n",
      "2017-09-06 08:26:26,342 - INFO - step: 143,loss: 0.430 accuracy: 0.805\n",
      "2017-09-06 08:26:27,551 - INFO - step: 144,loss: 0.374 accuracy: 0.812\n",
      "2017-09-06 08:26:28,771 - INFO - step: 145,loss: 0.310 accuracy: 0.906\n",
      "2017-09-06 08:26:30,029 - INFO - step: 146,loss: 0.458 accuracy: 0.797\n",
      "2017-09-06 08:26:31,243 - INFO - step: 147,loss: 0.338 accuracy: 0.844\n",
      "2017-09-06 08:26:32,463 - INFO - step: 148,loss: 0.344 accuracy: 0.852\n",
      "2017-09-06 08:26:33,695 - INFO - step: 149,loss: 0.305 accuracy: 0.914\n",
      "2017-09-06 08:26:34,899 - INFO - step: 150,loss: 0.258 accuracy: 0.898\n",
      "2017-09-06 08:26:36,142 - INFO - step: 151,loss: 0.267 accuracy: 0.891\n",
      "2017-09-06 08:26:37,356 - INFO - step: 152,loss: 0.290 accuracy: 0.891\n",
      "2017-09-06 08:26:38,566 - INFO - step: 153,loss: 0.331 accuracy: 0.867\n",
      "2017-09-06 08:26:39,787 - INFO - step: 154,loss: 0.406 accuracy: 0.836\n",
      "2017-09-06 08:26:41,007 - INFO - step: 155,loss: 0.398 accuracy: 0.820\n",
      "2017-09-06 08:26:42,220 - INFO - step: 156,loss: 0.327 accuracy: 0.844\n",
      "2017-09-06 08:26:43,417 - INFO - step: 157,loss: 0.320 accuracy: 0.852\n",
      "2017-09-06 08:26:44,627 - INFO - step: 158,loss: 0.349 accuracy: 0.852\n",
      "2017-09-06 08:26:45,839 - INFO - step: 159,loss: 0.294 accuracy: 0.875\n",
      "2017-09-06 08:26:46,958 - INFO - step: 160,loss: 0.293 accuracy: 0.846\n",
      "2017-09-06 08:26:46,960 - INFO - \n",
      "train_epoch:7.000\n",
      "2017-09-06 08:26:46,962 - INFO - loss_total: 0.338 accuracy_total: 0.859\n",
      "2017-09-06 08:26:48,159 - INFO - step: 161,loss: 0.396 accuracy: 0.820\n",
      "2017-09-06 08:26:49,383 - INFO - step: 162,loss: 0.314 accuracy: 0.820\n",
      "2017-09-06 08:26:50,600 - INFO - step: 163,loss: 0.293 accuracy: 0.898\n",
      "2017-09-06 08:26:51,831 - INFO - step: 164,loss: 0.308 accuracy: 0.875\n",
      "2017-09-06 08:26:53,034 - INFO - step: 165,loss: 0.321 accuracy: 0.852\n",
      "2017-09-06 08:26:54,262 - INFO - step: 166,loss: 0.356 accuracy: 0.805\n",
      "2017-09-06 08:26:55,473 - INFO - step: 167,loss: 0.309 accuracy: 0.883\n",
      "2017-09-06 08:26:56,698 - INFO - step: 168,loss: 0.351 accuracy: 0.852\n",
      "2017-09-06 08:26:57,947 - INFO - step: 169,loss: 0.356 accuracy: 0.867\n",
      "2017-09-06 08:26:59,160 - INFO - step: 170,loss: 0.315 accuracy: 0.836\n",
      "2017-09-06 08:27:00,374 - INFO - step: 171,loss: 0.397 accuracy: 0.844\n",
      "2017-09-06 08:27:01,583 - INFO - step: 172,loss: 0.317 accuracy: 0.852\n",
      "2017-09-06 08:27:02,801 - INFO - step: 173,loss: 0.240 accuracy: 0.898\n",
      "2017-09-06 08:27:04,033 - INFO - step: 174,loss: 0.314 accuracy: 0.883\n",
      "2017-09-06 08:27:05,256 - INFO - step: 175,loss: 0.337 accuracy: 0.867\n",
      "2017-09-06 08:27:06,474 - INFO - step: 176,loss: 0.267 accuracy: 0.898\n",
      "2017-09-06 08:27:07,706 - INFO - step: 177,loss: 0.338 accuracy: 0.844\n",
      "2017-09-06 08:27:08,912 - INFO - step: 178,loss: 0.320 accuracy: 0.852\n",
      "2017-09-06 08:27:10,107 - INFO - step: 179,loss: 0.279 accuracy: 0.898\n",
      "2017-09-06 08:27:11,225 - INFO - step: 180,loss: 0.229 accuracy: 0.908\n",
      "2017-09-06 08:27:11,228 - INFO - \n",
      "train_epoch:8.000\n",
      "2017-09-06 08:27:11,229 - INFO - loss_total: 0.318 accuracy_total: 0.863\n",
      "2017-09-06 08:27:11,231 - INFO - \n",
      "Evaluation:8.000\n",
      "2017-09-06 08:27:11,775 - INFO - step: 180,loss: 0.314 accuracy: 0.871\n",
      "2017-09-06 08:27:11,776 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:27:13,023 - INFO - step: 181,loss: 0.305 accuracy: 0.852\n",
      "2017-09-06 08:27:14,237 - INFO - step: 182,loss: 0.306 accuracy: 0.867\n",
      "2017-09-06 08:27:15,444 - INFO - step: 183,loss: 0.254 accuracy: 0.906\n",
      "2017-09-06 08:27:16,662 - INFO - step: 184,loss: 0.225 accuracy: 0.938\n",
      "2017-09-06 08:27:17,882 - INFO - step: 185,loss: 0.350 accuracy: 0.891\n",
      "2017-09-06 08:27:19,102 - INFO - step: 186,loss: 0.329 accuracy: 0.844\n",
      "2017-09-06 08:27:20,311 - INFO - step: 187,loss: 0.305 accuracy: 0.898\n",
      "2017-09-06 08:27:21,495 - INFO - step: 188,loss: 0.305 accuracy: 0.883\n",
      "2017-09-06 08:27:22,703 - INFO - step: 189,loss: 0.219 accuracy: 0.883\n",
      "2017-09-06 08:27:23,908 - INFO - step: 190,loss: 0.284 accuracy: 0.852\n",
      "2017-09-06 08:27:25,159 - INFO - step: 191,loss: 0.315 accuracy: 0.867\n",
      "2017-09-06 08:27:26,380 - INFO - step: 192,loss: 0.274 accuracy: 0.867\n",
      "2017-09-06 08:27:27,560 - INFO - step: 193,loss: 0.307 accuracy: 0.891\n",
      "2017-09-06 08:27:28,764 - INFO - step: 194,loss: 0.234 accuracy: 0.922\n",
      "2017-09-06 08:27:29,992 - INFO - step: 195,loss: 0.339 accuracy: 0.836\n",
      "2017-09-06 08:27:31,201 - INFO - step: 196,loss: 0.328 accuracy: 0.898\n",
      "2017-09-06 08:27:32,436 - INFO - step: 197,loss: 0.282 accuracy: 0.914\n",
      "2017-09-06 08:27:33,692 - INFO - step: 198,loss: 0.375 accuracy: 0.828\n",
      "2017-09-06 08:27:34,901 - INFO - step: 199,loss: 0.340 accuracy: 0.828\n",
      "2017-09-06 08:27:35,992 - INFO - step: 200,loss: 0.372 accuracy: 0.815\n",
      "2017-09-06 08:27:35,995 - INFO - \n",
      "train_epoch:9.000\n",
      "2017-09-06 08:27:35,997 - INFO - loss_total: 0.302 accuracy_total: 0.874\n",
      "2017-09-06 08:27:37,236 - INFO - step: 201,loss: 0.337 accuracy: 0.844\n",
      "2017-09-06 08:27:38,437 - INFO - step: 202,loss: 0.281 accuracy: 0.891\n",
      "2017-09-06 08:27:39,651 - INFO - step: 203,loss: 0.316 accuracy: 0.852\n",
      "2017-09-06 08:27:40,878 - INFO - step: 204,loss: 0.304 accuracy: 0.891\n",
      "2017-09-06 08:27:42,126 - INFO - step: 205,loss: 0.332 accuracy: 0.883\n",
      "2017-09-06 08:27:43,374 - INFO - step: 206,loss: 0.274 accuracy: 0.883\n",
      "2017-09-06 08:27:44,587 - INFO - step: 207,loss: 0.287 accuracy: 0.898\n",
      "2017-09-06 08:27:45,796 - INFO - step: 208,loss: 0.357 accuracy: 0.867\n",
      "2017-09-06 08:27:46,997 - INFO - step: 209,loss: 0.288 accuracy: 0.883\n",
      "2017-09-06 08:27:48,214 - INFO - step: 210,loss: 0.347 accuracy: 0.844\n",
      "2017-09-06 08:27:49,487 - INFO - step: 211,loss: 0.294 accuracy: 0.883\n",
      "2017-09-06 08:27:50,669 - INFO - step: 212,loss: 0.210 accuracy: 0.914\n",
      "2017-09-06 08:27:51,882 - INFO - step: 213,loss: 0.335 accuracy: 0.891\n",
      "2017-09-06 08:27:53,104 - INFO - step: 214,loss: 0.291 accuracy: 0.898\n",
      "2017-09-06 08:27:54,323 - INFO - step: 215,loss: 0.260 accuracy: 0.883\n",
      "2017-09-06 08:27:55,528 - INFO - step: 216,loss: 0.405 accuracy: 0.820\n",
      "2017-09-06 08:27:56,729 - INFO - step: 217,loss: 0.315 accuracy: 0.867\n",
      "2017-09-06 08:27:57,937 - INFO - step: 218,loss: 0.325 accuracy: 0.875\n",
      "2017-09-06 08:27:59,187 - INFO - step: 219,loss: 0.389 accuracy: 0.867\n",
      "2017-09-06 08:28:00,284 - INFO - step: 220,loss: 0.274 accuracy: 0.846\n",
      "2017-09-06 08:28:00,289 - INFO - \n",
      "train_epoch:10.000\n",
      "2017-09-06 08:28:00,290 - INFO - loss_total: 0.311 accuracy_total: 0.874\n",
      "2017-09-06 08:28:00,292 - INFO - \n",
      "Evaluation:10.000\n",
      "2017-09-06 08:28:00,824 - INFO - step: 220,loss: 0.292 accuracy: 0.892\n",
      "2017-09-06 08:28:00,826 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:28:01,075 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-220 at epoch 10.\n",
      "2017-09-06 08:28:02,287 - INFO - step: 221,loss: 0.306 accuracy: 0.906\n",
      "2017-09-06 08:28:03,492 - INFO - step: 222,loss: 0.360 accuracy: 0.812\n",
      "2017-09-06 08:28:04,709 - INFO - step: 223,loss: 0.307 accuracy: 0.906\n",
      "2017-09-06 08:28:05,935 - INFO - step: 224,loss: 0.258 accuracy: 0.875\n",
      "2017-09-06 08:28:07,141 - INFO - step: 225,loss: 0.270 accuracy: 0.852\n",
      "2017-09-06 08:28:08,363 - INFO - step: 226,loss: 0.237 accuracy: 0.906\n",
      "2017-09-06 08:28:09,605 - INFO - step: 227,loss: 0.289 accuracy: 0.844\n",
      "2017-09-06 08:28:10,849 - INFO - step: 228,loss: 0.276 accuracy: 0.891\n",
      "2017-09-06 08:28:12,074 - INFO - step: 229,loss: 0.267 accuracy: 0.875\n",
      "2017-09-06 08:28:13,286 - INFO - step: 230,loss: 0.200 accuracy: 0.945\n",
      "2017-09-06 08:28:14,499 - INFO - step: 231,loss: 0.304 accuracy: 0.867\n",
      "2017-09-06 08:28:15,706 - INFO - step: 232,loss: 0.289 accuracy: 0.891\n",
      "2017-09-06 08:28:16,943 - INFO - step: 233,loss: 0.356 accuracy: 0.898\n",
      "2017-09-06 08:28:18,131 - INFO - step: 234,loss: 0.308 accuracy: 0.891\n",
      "2017-09-06 08:28:19,380 - INFO - step: 235,loss: 0.316 accuracy: 0.844\n",
      "2017-09-06 08:28:20,632 - INFO - step: 236,loss: 0.258 accuracy: 0.883\n",
      "2017-09-06 08:28:21,850 - INFO - step: 237,loss: 0.260 accuracy: 0.922\n",
      "2017-09-06 08:28:23,061 - INFO - step: 238,loss: 0.302 accuracy: 0.883\n",
      "2017-09-06 08:28:24,269 - INFO - step: 239,loss: 0.310 accuracy: 0.867\n",
      "2017-09-06 08:28:25,355 - INFO - step: 240,loss: 0.196 accuracy: 0.954\n",
      "2017-09-06 08:28:25,358 - INFO - \n",
      "train_epoch:11.000\n",
      "2017-09-06 08:28:25,360 - INFO - loss_total: 0.284 accuracy_total: 0.886\n",
      "2017-09-06 08:28:26,590 - INFO - step: 241,loss: 0.371 accuracy: 0.844\n",
      "2017-09-06 08:28:27,789 - INFO - step: 242,loss: 0.351 accuracy: 0.836\n",
      "2017-09-06 08:28:28,981 - INFO - step: 243,loss: 0.245 accuracy: 0.898\n",
      "2017-09-06 08:28:30,204 - INFO - step: 244,loss: 0.236 accuracy: 0.922\n",
      "2017-09-06 08:28:31,419 - INFO - step: 245,loss: 0.299 accuracy: 0.883\n",
      "2017-09-06 08:28:32,636 - INFO - step: 246,loss: 0.221 accuracy: 0.922\n",
      "2017-09-06 08:28:33,858 - INFO - step: 247,loss: 0.227 accuracy: 0.922\n",
      "2017-09-06 08:28:35,076 - INFO - step: 248,loss: 0.404 accuracy: 0.844\n",
      "2017-09-06 08:28:36,296 - INFO - step: 249,loss: 0.431 accuracy: 0.844\n",
      "2017-09-06 08:28:37,552 - INFO - step: 250,loss: 0.276 accuracy: 0.891\n",
      "2017-09-06 08:28:38,758 - INFO - step: 251,loss: 0.235 accuracy: 0.922\n",
      "2017-09-06 08:28:39,977 - INFO - step: 252,loss: 0.266 accuracy: 0.891\n",
      "2017-09-06 08:28:41,184 - INFO - step: 253,loss: 0.253 accuracy: 0.883\n",
      "2017-09-06 08:28:42,400 - INFO - step: 254,loss: 0.253 accuracy: 0.891\n",
      "2017-09-06 08:28:43,586 - INFO - step: 255,loss: 0.203 accuracy: 0.945\n",
      "2017-09-06 08:28:44,799 - INFO - step: 256,loss: 0.269 accuracy: 0.914\n",
      "2017-09-06 08:28:46,010 - INFO - step: 257,loss: 0.274 accuracy: 0.891\n",
      "2017-09-06 08:28:47,234 - INFO - step: 258,loss: 0.356 accuracy: 0.875\n",
      "2017-09-06 08:28:48,459 - INFO - step: 259,loss: 0.225 accuracy: 0.914\n",
      "2017-09-06 08:28:49,560 - INFO - step: 260,loss: 0.265 accuracy: 0.908\n",
      "2017-09-06 08:28:49,562 - INFO - \n",
      "train_epoch:12.000\n",
      "2017-09-06 08:28:49,564 - INFO - loss_total: 0.283 accuracy_total: 0.892\n",
      "2017-09-06 08:28:49,566 - INFO - \n",
      "Evaluation:12.000\n",
      "2017-09-06 08:28:50,104 - INFO - step: 260,loss: 0.282 accuracy: 0.892\n",
      "2017-09-06 08:28:50,105 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:28:50,466 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-260 at epoch 12.\n",
      "2017-09-06 08:28:51,692 - INFO - step: 261,loss: 0.185 accuracy: 0.945\n",
      "2017-09-06 08:28:52,915 - INFO - step: 262,loss: 0.323 accuracy: 0.891\n",
      "2017-09-06 08:28:54,134 - INFO - step: 263,loss: 0.345 accuracy: 0.836\n",
      "2017-09-06 08:28:55,349 - INFO - step: 264,loss: 0.224 accuracy: 0.891\n",
      "2017-09-06 08:28:56,545 - INFO - step: 265,loss: 0.282 accuracy: 0.875\n",
      "2017-09-06 08:28:57,779 - INFO - step: 266,loss: 0.268 accuracy: 0.898\n",
      "2017-09-06 08:28:58,990 - INFO - step: 267,loss: 0.277 accuracy: 0.867\n",
      "2017-09-06 08:29:00,197 - INFO - step: 268,loss: 0.243 accuracy: 0.883\n",
      "2017-09-06 08:29:01,405 - INFO - step: 269,loss: 0.245 accuracy: 0.898\n",
      "2017-09-06 08:29:02,611 - INFO - step: 270,loss: 0.241 accuracy: 0.914\n",
      "2017-09-06 08:29:03,808 - INFO - step: 271,loss: 0.353 accuracy: 0.852\n",
      "2017-09-06 08:29:05,022 - INFO - step: 272,loss: 0.296 accuracy: 0.891\n",
      "2017-09-06 08:29:06,233 - INFO - step: 273,loss: 0.238 accuracy: 0.906\n",
      "2017-09-06 08:29:07,442 - INFO - step: 274,loss: 0.312 accuracy: 0.891\n",
      "2017-09-06 08:29:08,649 - INFO - step: 275,loss: 0.273 accuracy: 0.898\n",
      "2017-09-06 08:29:09,897 - INFO - step: 276,loss: 0.271 accuracy: 0.852\n",
      "2017-09-06 08:29:11,109 - INFO - step: 277,loss: 0.322 accuracy: 0.828\n",
      "2017-09-06 08:29:12,327 - INFO - step: 278,loss: 0.230 accuracy: 0.922\n",
      "2017-09-06 08:29:13,569 - INFO - step: 279,loss: 0.293 accuracy: 0.883\n",
      "2017-09-06 08:29:14,684 - INFO - step: 280,loss: 0.205 accuracy: 0.923\n",
      "2017-09-06 08:29:14,687 - INFO - \n",
      "train_epoch:13.000\n",
      "2017-09-06 08:29:14,689 - INFO - loss_total: 0.271 accuracy_total: 0.887\n",
      "2017-09-06 08:29:15,931 - INFO - step: 281,loss: 0.258 accuracy: 0.859\n",
      "2017-09-06 08:29:17,134 - INFO - step: 282,loss: 0.285 accuracy: 0.891\n",
      "2017-09-06 08:29:18,352 - INFO - step: 283,loss: 0.267 accuracy: 0.906\n",
      "2017-09-06 08:29:19,545 - INFO - step: 284,loss: 0.189 accuracy: 0.953\n",
      "2017-09-06 08:29:20,762 - INFO - step: 285,loss: 0.313 accuracy: 0.875\n",
      "2017-09-06 08:29:21,978 - INFO - step: 286,loss: 0.239 accuracy: 0.930\n",
      "2017-09-06 08:29:23,194 - INFO - step: 287,loss: 0.162 accuracy: 0.930\n",
      "2017-09-06 08:29:24,400 - INFO - step: 288,loss: 0.275 accuracy: 0.922\n",
      "2017-09-06 08:29:25,600 - INFO - step: 289,loss: 0.300 accuracy: 0.875\n",
      "2017-09-06 08:29:26,847 - INFO - step: 290,loss: 0.264 accuracy: 0.875\n",
      "2017-09-06 08:29:28,035 - INFO - step: 291,loss: 0.236 accuracy: 0.906\n",
      "2017-09-06 08:29:29,259 - INFO - step: 292,loss: 0.180 accuracy: 0.953\n",
      "2017-09-06 08:29:30,463 - INFO - step: 293,loss: 0.212 accuracy: 0.914\n",
      "2017-09-06 08:29:31,660 - INFO - step: 294,loss: 0.172 accuracy: 0.922\n",
      "2017-09-06 08:29:32,842 - INFO - step: 295,loss: 0.320 accuracy: 0.906\n",
      "2017-09-06 08:29:34,045 - INFO - step: 296,loss: 0.274 accuracy: 0.867\n",
      "2017-09-06 08:29:35,253 - INFO - step: 297,loss: 0.261 accuracy: 0.883\n",
      "2017-09-06 08:29:36,499 - INFO - step: 298,loss: 0.231 accuracy: 0.914\n",
      "2017-09-06 08:29:37,705 - INFO - step: 299,loss: 0.335 accuracy: 0.836\n",
      "2017-09-06 08:29:38,820 - INFO - step: 300,loss: 0.271 accuracy: 0.877\n",
      "2017-09-06 08:29:38,824 - INFO - \n",
      "train_epoch:14.000\n",
      "2017-09-06 08:29:38,826 - INFO - loss_total: 0.252 accuracy_total: 0.900\n",
      "2017-09-06 08:29:38,827 - INFO - \n",
      "Evaluation:14.000\n",
      "2017-09-06 08:29:39,371 - INFO - step: 300,loss: 0.295 accuracy: 0.874\n",
      "2017-09-06 08:29:39,372 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:29:40,603 - INFO - step: 301,loss: 0.200 accuracy: 0.922\n",
      "2017-09-06 08:29:41,827 - INFO - step: 302,loss: 0.203 accuracy: 0.953\n",
      "2017-09-06 08:29:43,043 - INFO - step: 303,loss: 0.220 accuracy: 0.914\n",
      "2017-09-06 08:29:44,250 - INFO - step: 304,loss: 0.254 accuracy: 0.867\n",
      "2017-09-06 08:29:45,467 - INFO - step: 305,loss: 0.281 accuracy: 0.906\n",
      "2017-09-06 08:29:46,742 - INFO - step: 306,loss: 0.292 accuracy: 0.883\n",
      "2017-09-06 08:29:47,955 - INFO - step: 307,loss: 0.244 accuracy: 0.867\n",
      "2017-09-06 08:29:49,153 - INFO - step: 308,loss: 0.335 accuracy: 0.852\n",
      "2017-09-06 08:29:50,373 - INFO - step: 309,loss: 0.206 accuracy: 0.922\n",
      "2017-09-06 08:29:51,595 - INFO - step: 310,loss: 0.232 accuracy: 0.922\n",
      "2017-09-06 08:29:52,807 - INFO - step: 311,loss: 0.221 accuracy: 0.922\n",
      "2017-09-06 08:29:54,013 - INFO - step: 312,loss: 0.258 accuracy: 0.883\n",
      "2017-09-06 08:29:55,227 - INFO - step: 313,loss: 0.205 accuracy: 0.930\n",
      "2017-09-06 08:29:56,444 - INFO - step: 314,loss: 0.221 accuracy: 0.906\n",
      "2017-09-06 08:29:57,654 - INFO - step: 315,loss: 0.300 accuracy: 0.867\n",
      "2017-09-06 08:29:58,846 - INFO - step: 316,loss: 0.282 accuracy: 0.914\n",
      "2017-09-06 08:30:00,062 - INFO - step: 317,loss: 0.261 accuracy: 0.914\n",
      "2017-09-06 08:30:01,280 - INFO - step: 318,loss: 0.277 accuracy: 0.852\n",
      "2017-09-06 08:30:02,493 - INFO - step: 319,loss: 0.265 accuracy: 0.914\n",
      "2017-09-06 08:30:03,619 - INFO - step: 320,loss: 0.459 accuracy: 0.800\n",
      "2017-09-06 08:30:03,623 - INFO - \n",
      "train_epoch:15.000\n",
      "2017-09-06 08:30:03,625 - INFO - loss_total: 0.261 accuracy_total: 0.895\n",
      "2017-09-06 08:30:04,847 - INFO - step: 321,loss: 0.260 accuracy: 0.867\n",
      "2017-09-06 08:30:06,074 - INFO - step: 322,loss: 0.188 accuracy: 0.930\n",
      "2017-09-06 08:30:07,284 - INFO - step: 323,loss: 0.220 accuracy: 0.906\n",
      "2017-09-06 08:30:08,537 - INFO - step: 324,loss: 0.319 accuracy: 0.852\n",
      "2017-09-06 08:30:09,740 - INFO - step: 325,loss: 0.195 accuracy: 0.930\n",
      "2017-09-06 08:30:10,916 - INFO - step: 326,loss: 0.257 accuracy: 0.898\n",
      "2017-09-06 08:30:12,122 - INFO - step: 327,loss: 0.268 accuracy: 0.914\n",
      "2017-09-06 08:30:13,330 - INFO - step: 328,loss: 0.284 accuracy: 0.844\n",
      "2017-09-06 08:30:14,516 - INFO - step: 329,loss: 0.277 accuracy: 0.891\n",
      "2017-09-06 08:30:15,709 - INFO - step: 330,loss: 0.236 accuracy: 0.898\n",
      "2017-09-06 08:30:16,925 - INFO - step: 331,loss: 0.292 accuracy: 0.883\n",
      "2017-09-06 08:30:18,128 - INFO - step: 332,loss: 0.287 accuracy: 0.875\n",
      "2017-09-06 08:30:19,323 - INFO - step: 333,loss: 0.227 accuracy: 0.898\n",
      "2017-09-06 08:30:20,538 - INFO - step: 334,loss: 0.272 accuracy: 0.898\n",
      "2017-09-06 08:30:21,756 - INFO - step: 335,loss: 0.233 accuracy: 0.906\n",
      "2017-09-06 08:30:22,961 - INFO - step: 336,loss: 0.201 accuracy: 0.938\n",
      "2017-09-06 08:30:24,153 - INFO - step: 337,loss: 0.209 accuracy: 0.922\n",
      "2017-09-06 08:30:25,359 - INFO - step: 338,loss: 0.214 accuracy: 0.930\n",
      "2017-09-06 08:30:26,586 - INFO - step: 339,loss: 0.275 accuracy: 0.883\n",
      "2017-09-06 08:30:27,734 - INFO - step: 340,loss: 0.173 accuracy: 0.954\n",
      "2017-09-06 08:30:27,738 - INFO - \n",
      "train_epoch:16.000\n",
      "2017-09-06 08:30:27,740 - INFO - loss_total: 0.244 accuracy_total: 0.901\n",
      "2017-09-06 08:30:27,741 - INFO - \n",
      "Evaluation:16.000\n",
      "2017-09-06 08:30:28,284 - INFO - step: 340,loss: 0.267 accuracy: 0.899\n",
      "2017-09-06 08:30:28,286 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:30:28,542 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-340 at epoch 16.\n",
      "2017-09-06 08:30:29,753 - INFO - step: 341,loss: 0.189 accuracy: 0.953\n",
      "2017-09-06 08:30:30,988 - INFO - step: 342,loss: 0.228 accuracy: 0.906\n",
      "2017-09-06 08:30:32,210 - INFO - step: 343,loss: 0.220 accuracy: 0.906\n",
      "2017-09-06 08:30:33,410 - INFO - step: 344,loss: 0.243 accuracy: 0.883\n",
      "2017-09-06 08:30:34,608 - INFO - step: 345,loss: 0.276 accuracy: 0.891\n",
      "2017-09-06 08:30:35,822 - INFO - step: 346,loss: 0.418 accuracy: 0.820\n",
      "2017-09-06 08:30:37,034 - INFO - step: 347,loss: 0.252 accuracy: 0.914\n",
      "2017-09-06 08:30:38,242 - INFO - step: 348,loss: 0.248 accuracy: 0.898\n",
      "2017-09-06 08:30:39,438 - INFO - step: 349,loss: 0.191 accuracy: 0.945\n",
      "2017-09-06 08:30:40,651 - INFO - step: 350,loss: 0.264 accuracy: 0.891\n",
      "2017-09-06 08:30:41,871 - INFO - step: 351,loss: 0.283 accuracy: 0.906\n",
      "2017-09-06 08:30:43,088 - INFO - step: 352,loss: 0.269 accuracy: 0.891\n",
      "2017-09-06 08:30:44,297 - INFO - step: 353,loss: 0.266 accuracy: 0.867\n",
      "2017-09-06 08:30:45,523 - INFO - step: 354,loss: 0.222 accuracy: 0.898\n",
      "2017-09-06 08:30:46,747 - INFO - step: 355,loss: 0.237 accuracy: 0.898\n",
      "2017-09-06 08:30:47,957 - INFO - step: 356,loss: 0.209 accuracy: 0.883\n",
      "2017-09-06 08:30:49,167 - INFO - step: 357,loss: 0.219 accuracy: 0.914\n",
      "2017-09-06 08:30:50,388 - INFO - step: 358,loss: 0.220 accuracy: 0.953\n",
      "2017-09-06 08:30:51,548 - INFO - step: 359,loss: 0.237 accuracy: 0.930\n",
      "2017-09-06 08:30:52,666 - INFO - step: 360,loss: 0.300 accuracy: 0.877\n",
      "2017-09-06 08:30:52,670 - INFO - \n",
      "train_epoch:17.000\n",
      "2017-09-06 08:30:52,672 - INFO - loss_total: 0.250 accuracy_total: 0.901\n",
      "2017-09-06 08:30:53,909 - INFO - step: 361,loss: 0.197 accuracy: 0.922\n",
      "2017-09-06 08:30:55,124 - INFO - step: 362,loss: 0.238 accuracy: 0.930\n",
      "2017-09-06 08:30:56,309 - INFO - step: 363,loss: 0.235 accuracy: 0.898\n",
      "2017-09-06 08:30:57,554 - INFO - step: 364,loss: 0.209 accuracy: 0.930\n",
      "2017-09-06 08:30:58,819 - INFO - step: 365,loss: 0.337 accuracy: 0.859\n",
      "2017-09-06 08:31:00,039 - INFO - step: 366,loss: 0.236 accuracy: 0.922\n",
      "2017-09-06 08:31:01,245 - INFO - step: 367,loss: 0.238 accuracy: 0.914\n",
      "2017-09-06 08:31:02,449 - INFO - step: 368,loss: 0.221 accuracy: 0.898\n",
      "2017-09-06 08:31:03,628 - INFO - step: 369,loss: 0.203 accuracy: 0.914\n",
      "2017-09-06 08:31:04,842 - INFO - step: 370,loss: 0.272 accuracy: 0.891\n",
      "2017-09-06 08:31:06,047 - INFO - step: 371,loss: 0.216 accuracy: 0.914\n",
      "2017-09-06 08:31:07,208 - INFO - step: 372,loss: 0.267 accuracy: 0.891\n",
      "2017-09-06 08:31:08,430 - INFO - step: 373,loss: 0.244 accuracy: 0.883\n",
      "2017-09-06 08:31:09,654 - INFO - step: 374,loss: 0.192 accuracy: 0.922\n",
      "2017-09-06 08:31:10,888 - INFO - step: 375,loss: 0.239 accuracy: 0.891\n",
      "2017-09-06 08:31:12,102 - INFO - step: 376,loss: 0.226 accuracy: 0.922\n",
      "2017-09-06 08:31:13,308 - INFO - step: 377,loss: 0.169 accuracy: 0.914\n",
      "2017-09-06 08:31:14,532 - INFO - step: 378,loss: 0.207 accuracy: 0.906\n",
      "2017-09-06 08:31:15,698 - INFO - step: 379,loss: 0.258 accuracy: 0.898\n",
      "2017-09-06 08:31:16,857 - INFO - step: 380,loss: 0.262 accuracy: 0.908\n",
      "2017-09-06 08:31:16,861 - INFO - \n",
      "train_epoch:18.000\n",
      "2017-09-06 08:31:16,863 - INFO - loss_total: 0.233 accuracy_total: 0.906\n",
      "2017-09-06 08:31:16,865 - INFO - \n",
      "Evaluation:18.000\n",
      "2017-09-06 08:31:17,407 - INFO - step: 380,loss: 0.310 accuracy: 0.892\n",
      "2017-09-06 08:31:17,408 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:31:18,649 - INFO - step: 381,loss: 0.192 accuracy: 0.922\n",
      "2017-09-06 08:31:19,866 - INFO - step: 382,loss: 0.186 accuracy: 0.945\n",
      "2017-09-06 08:31:21,106 - INFO - step: 383,loss: 0.178 accuracy: 0.938\n",
      "2017-09-06 08:31:22,288 - INFO - step: 384,loss: 0.280 accuracy: 0.875\n",
      "2017-09-06 08:31:23,494 - INFO - step: 385,loss: 0.292 accuracy: 0.922\n",
      "2017-09-06 08:31:24,689 - INFO - step: 386,loss: 0.213 accuracy: 0.914\n",
      "2017-09-06 08:31:25,865 - INFO - step: 387,loss: 0.220 accuracy: 0.891\n",
      "2017-09-06 08:31:27,073 - INFO - step: 388,loss: 0.168 accuracy: 0.938\n",
      "2017-09-06 08:31:28,300 - INFO - step: 389,loss: 0.265 accuracy: 0.898\n",
      "2017-09-06 08:31:29,525 - INFO - step: 390,loss: 0.230 accuracy: 0.883\n",
      "2017-09-06 08:31:30,746 - INFO - step: 391,loss: 0.262 accuracy: 0.898\n",
      "2017-09-06 08:31:31,937 - INFO - step: 392,loss: 0.252 accuracy: 0.891\n",
      "2017-09-06 08:31:33,181 - INFO - step: 393,loss: 0.231 accuracy: 0.906\n",
      "2017-09-06 08:31:34,388 - INFO - step: 394,loss: 0.259 accuracy: 0.883\n",
      "2017-09-06 08:31:35,598 - INFO - step: 395,loss: 0.336 accuracy: 0.898\n",
      "2017-09-06 08:31:36,845 - INFO - step: 396,loss: 0.304 accuracy: 0.828\n",
      "2017-09-06 08:31:38,092 - INFO - step: 397,loss: 0.223 accuracy: 0.930\n",
      "2017-09-06 08:31:39,310 - INFO - step: 398,loss: 0.279 accuracy: 0.875\n",
      "2017-09-06 08:31:40,525 - INFO - step: 399,loss: 0.297 accuracy: 0.859\n",
      "2017-09-06 08:31:41,627 - INFO - step: 400,loss: 0.189 accuracy: 0.908\n",
      "2017-09-06 08:31:41,631 - INFO - \n",
      "train_epoch:19.000\n",
      "2017-09-06 08:31:41,633 - INFO - loss_total: 0.243 accuracy_total: 0.900\n",
      "2017-09-06 08:31:42,840 - INFO - step: 401,loss: 0.222 accuracy: 0.922\n",
      "2017-09-06 08:31:44,024 - INFO - step: 402,loss: 0.263 accuracy: 0.891\n",
      "2017-09-06 08:31:45,269 - INFO - step: 403,loss: 0.173 accuracy: 0.922\n",
      "2017-09-06 08:31:46,478 - INFO - step: 404,loss: 0.277 accuracy: 0.859\n",
      "2017-09-06 08:31:47,679 - INFO - step: 405,loss: 0.175 accuracy: 0.953\n",
      "2017-09-06 08:31:48,894 - INFO - step: 406,loss: 0.173 accuracy: 0.930\n",
      "2017-09-06 08:31:50,112 - INFO - step: 407,loss: 0.217 accuracy: 0.930\n",
      "2017-09-06 08:31:51,319 - INFO - step: 408,loss: 0.239 accuracy: 0.898\n",
      "2017-09-06 08:31:52,536 - INFO - step: 409,loss: 0.178 accuracy: 0.922\n",
      "2017-09-06 08:31:53,744 - INFO - step: 410,loss: 0.222 accuracy: 0.922\n",
      "2017-09-06 08:31:55,023 - INFO - step: 411,loss: 0.206 accuracy: 0.922\n",
      "2017-09-06 08:31:56,209 - INFO - step: 412,loss: 0.198 accuracy: 0.922\n",
      "2017-09-06 08:31:57,447 - INFO - step: 413,loss: 0.292 accuracy: 0.898\n",
      "2017-09-06 08:31:58,676 - INFO - step: 414,loss: 0.162 accuracy: 0.961\n",
      "2017-09-06 08:31:59,902 - INFO - step: 415,loss: 0.211 accuracy: 0.938\n",
      "2017-09-06 08:32:01,092 - INFO - step: 416,loss: 0.227 accuracy: 0.914\n",
      "2017-09-06 08:32:02,310 - INFO - step: 417,loss: 0.308 accuracy: 0.852\n",
      "2017-09-06 08:32:03,522 - INFO - step: 418,loss: 0.228 accuracy: 0.914\n",
      "2017-09-06 08:32:04,734 - INFO - step: 419,loss: 0.174 accuracy: 0.953\n",
      "2017-09-06 08:32:05,882 - INFO - step: 420,loss: 0.166 accuracy: 0.938\n",
      "2017-09-06 08:32:05,885 - INFO - \n",
      "train_epoch:20.000\n",
      "2017-09-06 08:32:05,887 - INFO - loss_total: 0.215 accuracy_total: 0.918\n",
      "2017-09-06 08:32:05,889 - INFO - \n",
      "Evaluation:20.000\n",
      "2017-09-06 08:32:06,432 - INFO - step: 420,loss: 0.262 accuracy: 0.888\n",
      "2017-09-06 08:32:06,434 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:32:07,678 - INFO - step: 421,loss: 0.217 accuracy: 0.914\n",
      "2017-09-06 08:32:08,887 - INFO - step: 422,loss: 0.233 accuracy: 0.922\n",
      "2017-09-06 08:32:10,104 - INFO - step: 423,loss: 0.248 accuracy: 0.883\n",
      "2017-09-06 08:32:11,335 - INFO - step: 424,loss: 0.227 accuracy: 0.922\n",
      "2017-09-06 08:32:12,603 - INFO - step: 425,loss: 0.201 accuracy: 0.898\n",
      "2017-09-06 08:32:13,818 - INFO - step: 426,loss: 0.217 accuracy: 0.891\n",
      "2017-09-06 08:32:15,033 - INFO - step: 427,loss: 0.217 accuracy: 0.906\n",
      "2017-09-06 08:32:16,241 - INFO - step: 428,loss: 0.217 accuracy: 0.906\n",
      "2017-09-06 08:32:17,452 - INFO - step: 429,loss: 0.213 accuracy: 0.938\n",
      "2017-09-06 08:32:18,674 - INFO - step: 430,loss: 0.224 accuracy: 0.914\n",
      "2017-09-06 08:32:19,917 - INFO - step: 431,loss: 0.179 accuracy: 0.961\n",
      "2017-09-06 08:32:21,128 - INFO - step: 432,loss: 0.194 accuracy: 0.922\n",
      "2017-09-06 08:32:22,372 - INFO - step: 433,loss: 0.324 accuracy: 0.867\n",
      "2017-09-06 08:32:23,580 - INFO - step: 434,loss: 0.189 accuracy: 0.891\n",
      "2017-09-06 08:32:24,801 - INFO - step: 435,loss: 0.209 accuracy: 0.898\n",
      "2017-09-06 08:32:26,056 - INFO - step: 436,loss: 0.185 accuracy: 0.938\n",
      "2017-09-06 08:32:27,263 - INFO - step: 437,loss: 0.288 accuracy: 0.875\n",
      "2017-09-06 08:32:28,475 - INFO - step: 438,loss: 0.172 accuracy: 0.969\n",
      "2017-09-06 08:32:29,684 - INFO - step: 439,loss: 0.203 accuracy: 0.930\n",
      "2017-09-06 08:32:30,788 - INFO - step: 440,loss: 0.215 accuracy: 0.923\n",
      "2017-09-06 08:32:30,792 - INFO - \n",
      "train_epoch:21.000\n",
      "2017-09-06 08:32:30,794 - INFO - loss_total: 0.219 accuracy_total: 0.913\n",
      "2017-09-06 08:32:32,012 - INFO - step: 441,loss: 0.244 accuracy: 0.891\n",
      "2017-09-06 08:32:33,253 - INFO - step: 442,loss: 0.196 accuracy: 0.906\n",
      "2017-09-06 08:32:34,464 - INFO - step: 443,loss: 0.247 accuracy: 0.914\n",
      "2017-09-06 08:32:35,670 - INFO - step: 444,loss: 0.206 accuracy: 0.906\n",
      "2017-09-06 08:32:36,865 - INFO - step: 445,loss: 0.236 accuracy: 0.906\n",
      "2017-09-06 08:32:38,064 - INFO - step: 446,loss: 0.193 accuracy: 0.930\n",
      "2017-09-06 08:32:39,265 - INFO - step: 447,loss: 0.236 accuracy: 0.891\n",
      "2017-09-06 08:32:40,493 - INFO - step: 448,loss: 0.164 accuracy: 0.953\n",
      "2017-09-06 08:32:41,709 - INFO - step: 449,loss: 0.311 accuracy: 0.898\n",
      "2017-09-06 08:32:42,909 - INFO - step: 450,loss: 0.210 accuracy: 0.930\n",
      "2017-09-06 08:32:44,127 - INFO - step: 451,loss: 0.246 accuracy: 0.891\n",
      "2017-09-06 08:32:45,357 - INFO - step: 452,loss: 0.161 accuracy: 0.938\n",
      "2017-09-06 08:32:46,570 - INFO - step: 453,loss: 0.300 accuracy: 0.875\n",
      "2017-09-06 08:32:47,813 - INFO - step: 454,loss: 0.209 accuracy: 0.930\n",
      "2017-09-06 08:32:49,044 - INFO - step: 455,loss: 0.215 accuracy: 0.922\n",
      "2017-09-06 08:32:50,226 - INFO - step: 456,loss: 0.209 accuracy: 0.922\n",
      "2017-09-06 08:32:51,476 - INFO - step: 457,loss: 0.239 accuracy: 0.906\n",
      "2017-09-06 08:32:52,702 - INFO - step: 458,loss: 0.240 accuracy: 0.883\n",
      "2017-09-06 08:32:53,918 - INFO - step: 459,loss: 0.197 accuracy: 0.922\n",
      "2017-09-06 08:32:55,030 - INFO - step: 460,loss: 0.157 accuracy: 0.954\n",
      "2017-09-06 08:32:55,035 - INFO - \n",
      "train_epoch:22.000\n",
      "2017-09-06 08:32:55,037 - INFO - loss_total: 0.221 accuracy_total: 0.913\n",
      "2017-09-06 08:32:55,038 - INFO - \n",
      "Evaluation:22.000\n",
      "2017-09-06 08:32:55,581 - INFO - step: 460,loss: 0.283 accuracy: 0.903\n",
      "2017-09-06 08:32:55,582 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:32:55,848 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-460 at epoch 22.\n",
      "2017-09-06 08:32:57,064 - INFO - step: 461,loss: 0.177 accuracy: 0.930\n",
      "2017-09-06 08:32:58,322 - INFO - step: 462,loss: 0.175 accuracy: 0.906\n",
      "2017-09-06 08:32:59,521 - INFO - step: 463,loss: 0.226 accuracy: 0.922\n",
      "2017-09-06 08:33:00,748 - INFO - step: 464,loss: 0.213 accuracy: 0.883\n",
      "2017-09-06 08:33:01,971 - INFO - step: 465,loss: 0.203 accuracy: 0.898\n",
      "2017-09-06 08:33:03,182 - INFO - step: 466,loss: 0.266 accuracy: 0.875\n",
      "2017-09-06 08:33:04,337 - INFO - step: 467,loss: 0.205 accuracy: 0.938\n",
      "2017-09-06 08:33:05,557 - INFO - step: 468,loss: 0.228 accuracy: 0.875\n",
      "2017-09-06 08:33:06,755 - INFO - step: 469,loss: 0.251 accuracy: 0.898\n",
      "2017-09-06 08:33:07,997 - INFO - step: 470,loss: 0.195 accuracy: 0.938\n",
      "2017-09-06 08:33:09,225 - INFO - step: 471,loss: 0.229 accuracy: 0.914\n",
      "2017-09-06 08:33:10,444 - INFO - step: 472,loss: 0.227 accuracy: 0.914\n",
      "2017-09-06 08:33:11,679 - INFO - step: 473,loss: 0.300 accuracy: 0.867\n",
      "2017-09-06 08:33:12,898 - INFO - step: 474,loss: 0.217 accuracy: 0.891\n",
      "2017-09-06 08:33:14,074 - INFO - step: 475,loss: 0.276 accuracy: 0.883\n",
      "2017-09-06 08:33:15,291 - INFO - step: 476,loss: 0.263 accuracy: 0.883\n",
      "2017-09-06 08:33:16,524 - INFO - step: 477,loss: 0.239 accuracy: 0.906\n",
      "2017-09-06 08:33:17,761 - INFO - step: 478,loss: 0.177 accuracy: 0.938\n",
      "2017-09-06 08:33:18,990 - INFO - step: 479,loss: 0.187 accuracy: 0.938\n",
      "2017-09-06 08:33:20,081 - INFO - step: 480,loss: 0.146 accuracy: 0.938\n",
      "2017-09-06 08:33:20,085 - INFO - \n",
      "train_epoch:23.000\n",
      "2017-09-06 08:33:20,087 - INFO - loss_total: 0.220 accuracy_total: 0.907\n",
      "2017-09-06 08:33:21,323 - INFO - step: 481,loss: 0.209 accuracy: 0.906\n",
      "2017-09-06 08:33:22,568 - INFO - step: 482,loss: 0.163 accuracy: 0.938\n",
      "2017-09-06 08:33:23,775 - INFO - step: 483,loss: 0.191 accuracy: 0.930\n",
      "2017-09-06 08:33:24,977 - INFO - step: 484,loss: 0.215 accuracy: 0.906\n",
      "2017-09-06 08:33:26,176 - INFO - step: 485,loss: 0.153 accuracy: 0.938\n",
      "2017-09-06 08:33:27,379 - INFO - step: 486,loss: 0.227 accuracy: 0.922\n",
      "2017-09-06 08:33:28,587 - INFO - step: 487,loss: 0.211 accuracy: 0.930\n",
      "2017-09-06 08:33:29,799 - INFO - step: 488,loss: 0.228 accuracy: 0.930\n",
      "2017-09-06 08:33:31,023 - INFO - step: 489,loss: 0.193 accuracy: 0.930\n",
      "2017-09-06 08:33:32,255 - INFO - step: 490,loss: 0.283 accuracy: 0.898\n",
      "2017-09-06 08:33:33,489 - INFO - step: 491,loss: 0.266 accuracy: 0.883\n",
      "2017-09-06 08:33:34,716 - INFO - step: 492,loss: 0.240 accuracy: 0.906\n",
      "2017-09-06 08:33:35,932 - INFO - step: 493,loss: 0.189 accuracy: 0.891\n",
      "2017-09-06 08:33:37,163 - INFO - step: 494,loss: 0.230 accuracy: 0.930\n",
      "2017-09-06 08:33:38,364 - INFO - step: 495,loss: 0.204 accuracy: 0.914\n",
      "2017-09-06 08:33:39,585 - INFO - step: 496,loss: 0.181 accuracy: 0.930\n",
      "2017-09-06 08:33:40,785 - INFO - step: 497,loss: 0.206 accuracy: 0.914\n",
      "2017-09-06 08:33:41,999 - INFO - step: 498,loss: 0.204 accuracy: 0.898\n",
      "2017-09-06 08:33:43,213 - INFO - step: 499,loss: 0.208 accuracy: 0.938\n",
      "2017-09-06 08:33:44,345 - INFO - step: 500,loss: 0.239 accuracy: 0.908\n",
      "2017-09-06 08:33:44,349 - INFO - \n",
      "train_epoch:24.000\n",
      "2017-09-06 08:33:44,351 - INFO - loss_total: 0.212 accuracy_total: 0.917\n",
      "2017-09-06 08:33:44,352 - INFO - \n",
      "Evaluation:24.000\n",
      "2017-09-06 08:33:44,895 - INFO - step: 500,loss: 0.297 accuracy: 0.896\n",
      "2017-09-06 08:33:44,896 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:33:46,125 - INFO - step: 501,loss: 0.214 accuracy: 0.898\n",
      "2017-09-06 08:33:47,340 - INFO - step: 502,loss: 0.173 accuracy: 0.922\n",
      "2017-09-06 08:33:48,558 - INFO - step: 503,loss: 0.200 accuracy: 0.914\n",
      "2017-09-06 08:33:49,757 - INFO - step: 504,loss: 0.154 accuracy: 0.938\n",
      "2017-09-06 08:33:51,051 - INFO - step: 505,loss: 0.172 accuracy: 0.961\n",
      "2017-09-06 08:33:52,241 - INFO - step: 506,loss: 0.193 accuracy: 0.938\n",
      "2017-09-06 08:33:53,459 - INFO - step: 507,loss: 0.129 accuracy: 0.977\n",
      "2017-09-06 08:33:54,669 - INFO - step: 508,loss: 0.222 accuracy: 0.883\n",
      "2017-09-06 08:33:55,891 - INFO - step: 509,loss: 0.218 accuracy: 0.898\n",
      "2017-09-06 08:33:57,092 - INFO - step: 510,loss: 0.282 accuracy: 0.898\n",
      "2017-09-06 08:33:58,323 - INFO - step: 511,loss: 0.174 accuracy: 0.938\n",
      "2017-09-06 08:33:59,496 - INFO - step: 512,loss: 0.215 accuracy: 0.898\n",
      "2017-09-06 08:34:00,700 - INFO - step: 513,loss: 0.191 accuracy: 0.945\n",
      "2017-09-06 08:34:01,939 - INFO - step: 514,loss: 0.236 accuracy: 0.844\n",
      "2017-09-06 08:34:03,151 - INFO - step: 515,loss: 0.179 accuracy: 0.945\n",
      "2017-09-06 08:34:04,375 - INFO - step: 516,loss: 0.198 accuracy: 0.938\n",
      "2017-09-06 08:34:05,584 - INFO - step: 517,loss: 0.311 accuracy: 0.852\n",
      "2017-09-06 08:34:06,803 - INFO - step: 518,loss: 0.296 accuracy: 0.867\n",
      "2017-09-06 08:34:08,009 - INFO - step: 519,loss: 0.213 accuracy: 0.914\n",
      "2017-09-06 08:34:09,131 - INFO - step: 520,loss: 0.183 accuracy: 0.908\n",
      "2017-09-06 08:34:09,134 - INFO - \n",
      "train_epoch:25.000\n",
      "2017-09-06 08:34:09,136 - INFO - loss_total: 0.208 accuracy_total: 0.914\n",
      "2017-09-06 08:34:10,363 - INFO - step: 521,loss: 0.204 accuracy: 0.914\n",
      "2017-09-06 08:34:11,540 - INFO - step: 522,loss: 0.172 accuracy: 0.938\n",
      "2017-09-06 08:34:12,754 - INFO - step: 523,loss: 0.244 accuracy: 0.906\n",
      "2017-09-06 08:34:13,954 - INFO - step: 524,loss: 0.179 accuracy: 0.930\n",
      "2017-09-06 08:34:15,159 - INFO - step: 525,loss: 0.149 accuracy: 0.953\n",
      "2017-09-06 08:34:16,397 - INFO - step: 526,loss: 0.213 accuracy: 0.914\n",
      "2017-09-06 08:34:17,604 - INFO - step: 527,loss: 0.242 accuracy: 0.898\n",
      "2017-09-06 08:34:18,831 - INFO - step: 528,loss: 0.228 accuracy: 0.891\n",
      "2017-09-06 08:34:20,035 - INFO - step: 529,loss: 0.136 accuracy: 0.953\n",
      "2017-09-06 08:34:21,254 - INFO - step: 530,loss: 0.257 accuracy: 0.898\n",
      "2017-09-06 08:34:22,471 - INFO - step: 531,loss: 0.160 accuracy: 0.938\n",
      "2017-09-06 08:34:23,641 - INFO - step: 532,loss: 0.251 accuracy: 0.906\n",
      "2017-09-06 08:34:24,861 - INFO - step: 533,loss: 0.186 accuracy: 0.938\n",
      "2017-09-06 08:34:26,068 - INFO - step: 534,loss: 0.157 accuracy: 0.961\n",
      "2017-09-06 08:34:27,320 - INFO - step: 535,loss: 0.224 accuracy: 0.891\n",
      "2017-09-06 08:34:28,541 - INFO - step: 536,loss: 0.234 accuracy: 0.891\n",
      "2017-09-06 08:34:29,761 - INFO - step: 537,loss: 0.198 accuracy: 0.914\n",
      "2017-09-06 08:34:30,981 - INFO - step: 538,loss: 0.169 accuracy: 0.930\n",
      "2017-09-06 08:34:32,205 - INFO - step: 539,loss: 0.210 accuracy: 0.898\n",
      "2017-09-06 08:34:33,302 - INFO - step: 540,loss: 0.174 accuracy: 0.938\n",
      "2017-09-06 08:34:33,305 - INFO - \n",
      "train_epoch:26.000\n",
      "2017-09-06 08:34:33,307 - INFO - loss_total: 0.199 accuracy_total: 0.920\n",
      "2017-09-06 08:34:33,309 - INFO - \n",
      "Evaluation:26.000\n",
      "2017-09-06 08:34:33,853 - INFO - step: 540,loss: 0.288 accuracy: 0.888\n",
      "2017-09-06 08:34:33,854 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:34:35,054 - INFO - step: 541,loss: 0.164 accuracy: 0.953\n",
      "2017-09-06 08:34:36,262 - INFO - step: 542,loss: 0.267 accuracy: 0.883\n",
      "2017-09-06 08:34:37,514 - INFO - step: 543,loss: 0.236 accuracy: 0.867\n",
      "2017-09-06 08:34:38,738 - INFO - step: 544,loss: 0.215 accuracy: 0.906\n",
      "2017-09-06 08:34:39,953 - INFO - step: 545,loss: 0.185 accuracy: 0.938\n",
      "2017-09-06 08:34:41,185 - INFO - step: 546,loss: 0.194 accuracy: 0.898\n",
      "2017-09-06 08:34:42,403 - INFO - step: 547,loss: 0.187 accuracy: 0.938\n",
      "2017-09-06 08:34:43,599 - INFO - step: 548,loss: 0.190 accuracy: 0.930\n",
      "2017-09-06 08:34:44,807 - INFO - step: 549,loss: 0.196 accuracy: 0.914\n",
      "2017-09-06 08:34:46,018 - INFO - step: 550,loss: 0.204 accuracy: 0.906\n",
      "2017-09-06 08:34:47,224 - INFO - step: 551,loss: 0.199 accuracy: 0.969\n",
      "2017-09-06 08:34:48,432 - INFO - step: 552,loss: 0.186 accuracy: 0.945\n",
      "2017-09-06 08:34:49,655 - INFO - step: 553,loss: 0.177 accuracy: 0.945\n",
      "2017-09-06 08:34:50,878 - INFO - step: 554,loss: 0.224 accuracy: 0.898\n",
      "2017-09-06 08:34:52,033 - INFO - step: 555,loss: 0.214 accuracy: 0.914\n",
      "2017-09-06 08:34:53,239 - INFO - step: 556,loss: 0.266 accuracy: 0.906\n",
      "2017-09-06 08:34:54,446 - INFO - step: 557,loss: 0.236 accuracy: 0.906\n",
      "2017-09-06 08:34:55,651 - INFO - step: 558,loss: 0.230 accuracy: 0.891\n",
      "2017-09-06 08:34:56,849 - INFO - step: 559,loss: 0.158 accuracy: 0.930\n",
      "2017-09-06 08:34:57,965 - INFO - step: 560,loss: 0.125 accuracy: 0.969\n",
      "2017-09-06 08:34:57,968 - INFO - \n",
      "train_epoch:27.000\n",
      "2017-09-06 08:34:57,970 - INFO - loss_total: 0.203 accuracy_total: 0.920\n",
      "2017-09-06 08:34:59,206 - INFO - step: 561,loss: 0.214 accuracy: 0.906\n",
      "2017-09-06 08:35:00,421 - INFO - step: 562,loss: 0.224 accuracy: 0.914\n",
      "2017-09-06 08:35:01,631 - INFO - step: 563,loss: 0.173 accuracy: 0.938\n",
      "2017-09-06 08:35:02,847 - INFO - step: 564,loss: 0.252 accuracy: 0.867\n",
      "2017-09-06 08:35:04,073 - INFO - step: 565,loss: 0.156 accuracy: 0.938\n",
      "2017-09-06 08:35:05,295 - INFO - step: 566,loss: 0.216 accuracy: 0.914\n",
      "2017-09-06 08:35:06,515 - INFO - step: 567,loss: 0.265 accuracy: 0.906\n",
      "2017-09-06 08:35:07,723 - INFO - step: 568,loss: 0.145 accuracy: 0.977\n",
      "2017-09-06 08:35:08,942 - INFO - step: 569,loss: 0.156 accuracy: 0.930\n",
      "2017-09-06 08:35:10,151 - INFO - step: 570,loss: 0.134 accuracy: 0.961\n",
      "2017-09-06 08:35:11,357 - INFO - step: 571,loss: 0.255 accuracy: 0.891\n",
      "2017-09-06 08:35:12,577 - INFO - step: 572,loss: 0.162 accuracy: 0.930\n",
      "2017-09-06 08:35:13,795 - INFO - step: 573,loss: 0.237 accuracy: 0.898\n",
      "2017-09-06 08:35:15,031 - INFO - step: 574,loss: 0.109 accuracy: 0.984\n",
      "2017-09-06 08:35:16,257 - INFO - step: 575,loss: 0.186 accuracy: 0.914\n",
      "2017-09-06 08:35:17,473 - INFO - step: 576,loss: 0.227 accuracy: 0.898\n",
      "2017-09-06 08:35:18,689 - INFO - step: 577,loss: 0.159 accuracy: 0.945\n",
      "2017-09-06 08:35:19,896 - INFO - step: 578,loss: 0.183 accuracy: 0.898\n",
      "2017-09-06 08:35:21,114 - INFO - step: 579,loss: 0.238 accuracy: 0.891\n",
      "2017-09-06 08:35:22,231 - INFO - step: 580,loss: 0.189 accuracy: 0.938\n",
      "2017-09-06 08:35:22,234 - INFO - \n",
      "train_epoch:28.000\n",
      "2017-09-06 08:35:22,236 - INFO - loss_total: 0.194 accuracy_total: 0.922\n",
      "2017-09-06 08:35:22,237 - INFO - \n",
      "Evaluation:28.000\n",
      "2017-09-06 08:35:22,781 - INFO - step: 580,loss: 0.285 accuracy: 0.888\n",
      "2017-09-06 08:35:22,783 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:35:24,015 - INFO - step: 581,loss: 0.163 accuracy: 0.945\n",
      "2017-09-06 08:35:25,214 - INFO - step: 582,loss: 0.233 accuracy: 0.891\n",
      "2017-09-06 08:35:26,425 - INFO - step: 583,loss: 0.160 accuracy: 0.938\n",
      "2017-09-06 08:35:27,653 - INFO - step: 584,loss: 0.206 accuracy: 0.914\n",
      "2017-09-06 08:35:28,866 - INFO - step: 585,loss: 0.186 accuracy: 0.938\n",
      "2017-09-06 08:35:30,109 - INFO - step: 586,loss: 0.171 accuracy: 0.922\n",
      "2017-09-06 08:35:31,319 - INFO - step: 587,loss: 0.222 accuracy: 0.930\n",
      "2017-09-06 08:35:32,553 - INFO - step: 588,loss: 0.139 accuracy: 0.953\n",
      "2017-09-06 08:35:33,763 - INFO - step: 589,loss: 0.192 accuracy: 0.898\n",
      "2017-09-06 08:35:34,977 - INFO - step: 590,loss: 0.210 accuracy: 0.930\n",
      "2017-09-06 08:35:36,189 - INFO - step: 591,loss: 0.207 accuracy: 0.930\n",
      "2017-09-06 08:35:37,416 - INFO - step: 592,loss: 0.167 accuracy: 0.938\n",
      "2017-09-06 08:35:38,663 - INFO - step: 593,loss: 0.207 accuracy: 0.914\n",
      "2017-09-06 08:35:39,875 - INFO - step: 594,loss: 0.182 accuracy: 0.953\n",
      "2017-09-06 08:35:41,091 - INFO - step: 595,loss: 0.262 accuracy: 0.875\n",
      "2017-09-06 08:35:42,303 - INFO - step: 596,loss: 0.231 accuracy: 0.906\n",
      "2017-09-06 08:35:43,524 - INFO - step: 597,loss: 0.207 accuracy: 0.914\n",
      "2017-09-06 08:35:44,741 - INFO - step: 598,loss: 0.211 accuracy: 0.898\n",
      "2017-09-06 08:35:45,930 - INFO - step: 599,loss: 0.195 accuracy: 0.930\n",
      "2017-09-06 08:35:47,040 - INFO - step: 600,loss: 0.207 accuracy: 0.877\n",
      "2017-09-06 08:35:47,043 - INFO - \n",
      "train_epoch:29.000\n",
      "2017-09-06 08:35:47,045 - INFO - loss_total: 0.198 accuracy_total: 0.920\n",
      "2017-09-06 08:35:48,273 - INFO - step: 601,loss: 0.177 accuracy: 0.930\n",
      "2017-09-06 08:35:49,500 - INFO - step: 602,loss: 0.221 accuracy: 0.891\n",
      "2017-09-06 08:35:50,730 - INFO - step: 603,loss: 0.242 accuracy: 0.891\n",
      "2017-09-06 08:35:51,940 - INFO - step: 604,loss: 0.183 accuracy: 0.914\n",
      "2017-09-06 08:35:53,156 - INFO - step: 605,loss: 0.190 accuracy: 0.914\n",
      "2017-09-06 08:35:54,372 - INFO - step: 606,loss: 0.193 accuracy: 0.914\n",
      "2017-09-06 08:35:55,589 - INFO - step: 607,loss: 0.200 accuracy: 0.922\n",
      "2017-09-06 08:35:56,791 - INFO - step: 608,loss: 0.212 accuracy: 0.883\n",
      "2017-09-06 08:35:58,001 - INFO - step: 609,loss: 0.221 accuracy: 0.914\n",
      "2017-09-06 08:35:59,222 - INFO - step: 610,loss: 0.151 accuracy: 0.953\n",
      "2017-09-06 08:36:00,455 - INFO - step: 611,loss: 0.164 accuracy: 0.930\n",
      "2017-09-06 08:36:01,622 - INFO - step: 612,loss: 0.145 accuracy: 0.938\n",
      "2017-09-06 08:36:02,834 - INFO - step: 613,loss: 0.207 accuracy: 0.930\n",
      "2017-09-06 08:36:04,064 - INFO - step: 614,loss: 0.212 accuracy: 0.914\n",
      "2017-09-06 08:36:05,279 - INFO - step: 615,loss: 0.215 accuracy: 0.891\n",
      "2017-09-06 08:36:06,504 - INFO - step: 616,loss: 0.152 accuracy: 0.945\n",
      "2017-09-06 08:36:07,704 - INFO - step: 617,loss: 0.209 accuracy: 0.906\n",
      "2017-09-06 08:36:08,918 - INFO - step: 618,loss: 0.171 accuracy: 0.938\n",
      "2017-09-06 08:36:10,134 - INFO - step: 619,loss: 0.234 accuracy: 0.898\n",
      "2017-09-06 08:36:11,232 - INFO - step: 620,loss: 0.214 accuracy: 0.908\n",
      "2017-09-06 08:36:11,236 - INFO - \n",
      "train_epoch:30.000\n",
      "2017-09-06 08:36:11,237 - INFO - loss_total: 0.196 accuracy_total: 0.916\n",
      "2017-09-06 08:36:11,239 - INFO - \n",
      "Evaluation:30.000\n",
      "2017-09-06 08:36:11,782 - INFO - step: 620,loss: 0.308 accuracy: 0.896\n",
      "2017-09-06 08:36:11,783 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:36:13,007 - INFO - step: 621,loss: 0.295 accuracy: 0.906\n",
      "2017-09-06 08:36:14,214 - INFO - step: 622,loss: 0.183 accuracy: 0.898\n",
      "2017-09-06 08:36:15,430 - INFO - step: 623,loss: 0.160 accuracy: 0.930\n",
      "2017-09-06 08:36:16,647 - INFO - step: 624,loss: 0.139 accuracy: 0.969\n",
      "2017-09-06 08:36:17,860 - INFO - step: 625,loss: 0.222 accuracy: 0.922\n",
      "2017-09-06 08:36:19,050 - INFO - step: 626,loss: 0.179 accuracy: 0.930\n",
      "2017-09-06 08:36:20,309 - INFO - step: 627,loss: 0.192 accuracy: 0.930\n",
      "2017-09-06 08:36:21,550 - INFO - step: 628,loss: 0.187 accuracy: 0.930\n",
      "2017-09-06 08:36:22,766 - INFO - step: 629,loss: 0.162 accuracy: 0.945\n",
      "2017-09-06 08:36:23,978 - INFO - step: 630,loss: 0.217 accuracy: 0.891\n",
      "2017-09-06 08:36:25,183 - INFO - step: 631,loss: 0.171 accuracy: 0.930\n",
      "2017-09-06 08:36:26,396 - INFO - step: 632,loss: 0.134 accuracy: 0.938\n",
      "2017-09-06 08:36:27,608 - INFO - step: 633,loss: 0.208 accuracy: 0.906\n",
      "2017-09-06 08:36:28,794 - INFO - step: 634,loss: 0.232 accuracy: 0.891\n",
      "2017-09-06 08:36:30,008 - INFO - step: 635,loss: 0.142 accuracy: 0.984\n",
      "2017-09-06 08:36:31,249 - INFO - step: 636,loss: 0.200 accuracy: 0.906\n",
      "2017-09-06 08:36:32,457 - INFO - step: 637,loss: 0.189 accuracy: 0.938\n",
      "2017-09-06 08:36:33,663 - INFO - step: 638,loss: 0.168 accuracy: 0.930\n",
      "2017-09-06 08:36:34,881 - INFO - step: 639,loss: 0.192 accuracy: 0.898\n",
      "2017-09-06 08:36:35,995 - INFO - step: 640,loss: 0.124 accuracy: 0.954\n",
      "2017-09-06 08:36:35,999 - INFO - \n",
      "train_epoch:31.000\n",
      "2017-09-06 08:36:36,001 - INFO - loss_total: 0.185 accuracy_total: 0.926\n",
      "2017-09-06 08:36:37,235 - INFO - step: 641,loss: 0.197 accuracy: 0.906\n",
      "2017-09-06 08:36:38,472 - INFO - step: 642,loss: 0.177 accuracy: 0.930\n",
      "2017-09-06 08:36:39,682 - INFO - step: 643,loss: 0.224 accuracy: 0.891\n",
      "2017-09-06 08:36:40,887 - INFO - step: 644,loss: 0.211 accuracy: 0.898\n",
      "2017-09-06 08:36:42,092 - INFO - step: 645,loss: 0.151 accuracy: 0.938\n",
      "2017-09-06 08:36:43,300 - INFO - step: 646,loss: 0.126 accuracy: 0.961\n",
      "2017-09-06 08:36:44,507 - INFO - step: 647,loss: 0.125 accuracy: 0.953\n",
      "2017-09-06 08:36:45,715 - INFO - step: 648,loss: 0.183 accuracy: 0.922\n",
      "2017-09-06 08:36:46,926 - INFO - step: 649,loss: 0.152 accuracy: 0.953\n",
      "2017-09-06 08:36:48,115 - INFO - step: 650,loss: 0.176 accuracy: 0.930\n",
      "2017-09-06 08:36:49,349 - INFO - step: 651,loss: 0.116 accuracy: 0.977\n",
      "2017-09-06 08:36:50,546 - INFO - step: 652,loss: 0.195 accuracy: 0.938\n",
      "2017-09-06 08:36:51,696 - INFO - step: 653,loss: 0.147 accuracy: 0.930\n",
      "2017-09-06 08:36:52,892 - INFO - step: 654,loss: 0.136 accuracy: 0.953\n",
      "2017-09-06 08:36:54,112 - INFO - step: 655,loss: 0.249 accuracy: 0.891\n",
      "2017-09-06 08:36:55,323 - INFO - step: 656,loss: 0.188 accuracy: 0.914\n",
      "2017-09-06 08:36:56,515 - INFO - step: 657,loss: 0.161 accuracy: 0.922\n",
      "2017-09-06 08:36:57,719 - INFO - step: 658,loss: 0.163 accuracy: 0.938\n",
      "2017-09-06 08:36:58,933 - INFO - step: 659,loss: 0.252 accuracy: 0.906\n",
      "2017-09-06 08:37:00,041 - INFO - step: 660,loss: 0.216 accuracy: 0.892\n",
      "2017-09-06 08:37:00,045 - INFO - \n",
      "train_epoch:32.000\n",
      "2017-09-06 08:37:00,048 - INFO - loss_total: 0.177 accuracy_total: 0.927\n",
      "2017-09-06 08:37:00,049 - INFO - \n",
      "Evaluation:32.000\n",
      "2017-09-06 08:37:00,590 - INFO - step: 660,loss: 0.262 accuracy: 0.903\n",
      "2017-09-06 08:37:00,592 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:37:00,865 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-660 at epoch 32.\n",
      "2017-09-06 08:37:02,097 - INFO - step: 661,loss: 0.133 accuracy: 0.953\n",
      "2017-09-06 08:37:03,307 - INFO - step: 662,loss: 0.133 accuracy: 0.953\n",
      "2017-09-06 08:37:04,521 - INFO - step: 663,loss: 0.150 accuracy: 0.945\n",
      "2017-09-06 08:37:05,732 - INFO - step: 664,loss: 0.190 accuracy: 0.938\n",
      "2017-09-06 08:37:06,971 - INFO - step: 665,loss: 0.188 accuracy: 0.891\n",
      "2017-09-06 08:37:08,194 - INFO - step: 666,loss: 0.231 accuracy: 0.898\n",
      "2017-09-06 08:37:09,401 - INFO - step: 667,loss: 0.154 accuracy: 0.945\n",
      "2017-09-06 08:37:10,585 - INFO - step: 668,loss: 0.133 accuracy: 0.945\n",
      "2017-09-06 08:37:11,791 - INFO - step: 669,loss: 0.202 accuracy: 0.906\n",
      "2017-09-06 08:37:13,000 - INFO - step: 670,loss: 0.170 accuracy: 0.922\n",
      "2017-09-06 08:37:14,212 - INFO - step: 671,loss: 0.192 accuracy: 0.914\n",
      "2017-09-06 08:37:15,412 - INFO - step: 672,loss: 0.247 accuracy: 0.891\n",
      "2017-09-06 08:37:16,622 - INFO - step: 673,loss: 0.131 accuracy: 0.953\n",
      "2017-09-06 08:37:17,851 - INFO - step: 674,loss: 0.142 accuracy: 0.953\n",
      "2017-09-06 08:37:19,082 - INFO - step: 675,loss: 0.193 accuracy: 0.922\n",
      "2017-09-06 08:37:20,295 - INFO - step: 676,loss: 0.198 accuracy: 0.906\n",
      "2017-09-06 08:37:21,505 - INFO - step: 677,loss: 0.183 accuracy: 0.938\n",
      "2017-09-06 08:37:22,725 - INFO - step: 678,loss: 0.209 accuracy: 0.930\n",
      "2017-09-06 08:37:23,962 - INFO - step: 679,loss: 0.223 accuracy: 0.883\n",
      "2017-09-06 08:37:25,081 - INFO - step: 680,loss: 0.143 accuracy: 0.923\n",
      "2017-09-06 08:37:25,084 - INFO - \n",
      "train_epoch:33.000\n",
      "2017-09-06 08:37:25,086 - INFO - loss_total: 0.177 accuracy_total: 0.925\n",
      "2017-09-06 08:37:26,311 - INFO - step: 681,loss: 0.138 accuracy: 0.969\n",
      "2017-09-06 08:37:27,522 - INFO - step: 682,loss: 0.203 accuracy: 0.922\n",
      "2017-09-06 08:37:28,750 - INFO - step: 683,loss: 0.172 accuracy: 0.945\n",
      "2017-09-06 08:37:29,960 - INFO - step: 684,loss: 0.157 accuracy: 0.953\n",
      "2017-09-06 08:37:31,192 - INFO - step: 685,loss: 0.170 accuracy: 0.938\n",
      "2017-09-06 08:37:32,400 - INFO - step: 686,loss: 0.212 accuracy: 0.891\n",
      "2017-09-06 08:37:33,621 - INFO - step: 687,loss: 0.086 accuracy: 0.969\n",
      "2017-09-06 08:37:34,870 - INFO - step: 688,loss: 0.187 accuracy: 0.930\n",
      "2017-09-06 08:37:36,059 - INFO - step: 689,loss: 0.139 accuracy: 0.953\n",
      "2017-09-06 08:37:37,276 - INFO - step: 690,loss: 0.120 accuracy: 0.961\n",
      "2017-09-06 08:37:38,464 - INFO - step: 691,loss: 0.234 accuracy: 0.883\n",
      "2017-09-06 08:37:39,678 - INFO - step: 692,loss: 0.159 accuracy: 0.938\n",
      "2017-09-06 08:37:40,888 - INFO - step: 693,loss: 0.173 accuracy: 0.930\n",
      "2017-09-06 08:37:42,117 - INFO - step: 694,loss: 0.140 accuracy: 0.945\n",
      "2017-09-06 08:37:43,336 - INFO - step: 695,loss: 0.145 accuracy: 0.945\n",
      "2017-09-06 08:37:44,538 - INFO - step: 696,loss: 0.214 accuracy: 0.922\n",
      "2017-09-06 08:37:45,753 - INFO - step: 697,loss: 0.163 accuracy: 0.930\n",
      "2017-09-06 08:37:46,970 - INFO - step: 698,loss: 0.198 accuracy: 0.930\n",
      "2017-09-06 08:37:48,187 - INFO - step: 699,loss: 0.187 accuracy: 0.930\n",
      "2017-09-06 08:37:49,301 - INFO - step: 700,loss: 0.161 accuracy: 0.954\n",
      "2017-09-06 08:37:49,304 - INFO - \n",
      "train_epoch:34.000\n",
      "2017-09-06 08:37:49,306 - INFO - loss_total: 0.168 accuracy_total: 0.937\n",
      "2017-09-06 08:37:49,307 - INFO - \n",
      "Evaluation:34.000\n",
      "2017-09-06 08:37:49,854 - INFO - step: 700,loss: 0.275 accuracy: 0.899\n",
      "2017-09-06 08:37:49,856 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:37:51,088 - INFO - step: 701,loss: 0.144 accuracy: 0.961\n",
      "2017-09-06 08:37:52,293 - INFO - step: 702,loss: 0.188 accuracy: 0.922\n",
      "2017-09-06 08:37:53,435 - INFO - step: 703,loss: 0.143 accuracy: 0.961\n",
      "2017-09-06 08:37:54,635 - INFO - step: 704,loss: 0.229 accuracy: 0.906\n",
      "2017-09-06 08:37:55,849 - INFO - step: 705,loss: 0.206 accuracy: 0.922\n",
      "2017-09-06 08:37:57,062 - INFO - step: 706,loss: 0.179 accuracy: 0.906\n",
      "2017-09-06 08:37:58,274 - INFO - step: 707,loss: 0.211 accuracy: 0.898\n",
      "2017-09-06 08:37:59,479 - INFO - step: 708,loss: 0.193 accuracy: 0.922\n",
      "2017-09-06 08:38:00,725 - INFO - step: 709,loss: 0.160 accuracy: 0.953\n",
      "2017-09-06 08:38:01,943 - INFO - step: 710,loss: 0.169 accuracy: 0.930\n",
      "2017-09-06 08:38:03,129 - INFO - step: 711,loss: 0.152 accuracy: 0.922\n",
      "2017-09-06 08:38:04,341 - INFO - step: 712,loss: 0.222 accuracy: 0.883\n",
      "2017-09-06 08:38:05,508 - INFO - step: 713,loss: 0.182 accuracy: 0.930\n",
      "2017-09-06 08:38:06,728 - INFO - step: 714,loss: 0.221 accuracy: 0.875\n",
      "2017-09-06 08:38:07,936 - INFO - step: 715,loss: 0.194 accuracy: 0.938\n",
      "2017-09-06 08:38:09,188 - INFO - step: 716,loss: 0.179 accuracy: 0.938\n",
      "2017-09-06 08:38:10,390 - INFO - step: 717,loss: 0.169 accuracy: 0.922\n",
      "2017-09-06 08:38:11,613 - INFO - step: 718,loss: 0.256 accuracy: 0.891\n",
      "2017-09-06 08:38:12,819 - INFO - step: 719,loss: 0.165 accuracy: 0.938\n",
      "2017-09-06 08:38:13,955 - INFO - step: 720,loss: 0.142 accuracy: 0.969\n",
      "2017-09-06 08:38:13,958 - INFO - \n",
      "train_epoch:35.000\n",
      "2017-09-06 08:38:13,961 - INFO - loss_total: 0.185 accuracy_total: 0.924\n",
      "2017-09-06 08:38:15,194 - INFO - step: 721,loss: 0.113 accuracy: 0.961\n",
      "2017-09-06 08:38:16,415 - INFO - step: 722,loss: 0.220 accuracy: 0.914\n",
      "2017-09-06 08:38:17,620 - INFO - step: 723,loss: 0.146 accuracy: 0.945\n",
      "2017-09-06 08:38:18,874 - INFO - step: 724,loss: 0.222 accuracy: 0.938\n",
      "2017-09-06 08:38:20,070 - INFO - step: 725,loss: 0.137 accuracy: 0.938\n",
      "2017-09-06 08:38:21,290 - INFO - step: 726,loss: 0.127 accuracy: 0.984\n",
      "2017-09-06 08:38:22,522 - INFO - step: 727,loss: 0.124 accuracy: 0.938\n",
      "2017-09-06 08:38:23,737 - INFO - step: 728,loss: 0.192 accuracy: 0.922\n",
      "2017-09-06 08:38:24,898 - INFO - step: 729,loss: 0.202 accuracy: 0.898\n",
      "2017-09-06 08:38:26,129 - INFO - step: 730,loss: 0.191 accuracy: 0.922\n",
      "2017-09-06 08:38:27,375 - INFO - step: 731,loss: 0.189 accuracy: 0.922\n",
      "2017-09-06 08:38:28,591 - INFO - step: 732,loss: 0.137 accuracy: 0.961\n",
      "2017-09-06 08:38:29,811 - INFO - step: 733,loss: 0.179 accuracy: 0.938\n",
      "2017-09-06 08:38:31,003 - INFO - step: 734,loss: 0.133 accuracy: 0.961\n",
      "2017-09-06 08:38:32,209 - INFO - step: 735,loss: 0.167 accuracy: 0.914\n",
      "2017-09-06 08:38:33,440 - INFO - step: 736,loss: 0.268 accuracy: 0.859\n",
      "2017-09-06 08:38:34,673 - INFO - step: 737,loss: 0.179 accuracy: 0.914\n",
      "2017-09-06 08:38:35,887 - INFO - step: 738,loss: 0.232 accuracy: 0.898\n",
      "2017-09-06 08:38:37,092 - INFO - step: 739,loss: 0.172 accuracy: 0.938\n",
      "2017-09-06 08:38:38,213 - INFO - step: 740,loss: 0.205 accuracy: 0.908\n",
      "2017-09-06 08:38:38,217 - INFO - \n",
      "train_epoch:36.000\n",
      "2017-09-06 08:38:38,219 - INFO - loss_total: 0.177 accuracy_total: 0.929\n",
      "2017-09-06 08:38:38,221 - INFO - \n",
      "Evaluation:36.000\n",
      "2017-09-06 08:38:38,763 - INFO - step: 740,loss: 0.231 accuracy: 0.910\n",
      "2017-09-06 08:38:38,764 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:38:39,042 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-740 at epoch 36.\n",
      "2017-09-06 08:38:40,255 - INFO - step: 741,loss: 0.155 accuracy: 0.945\n",
      "2017-09-06 08:38:41,455 - INFO - step: 742,loss: 0.137 accuracy: 0.938\n",
      "2017-09-06 08:38:42,669 - INFO - step: 743,loss: 0.120 accuracy: 0.977\n",
      "2017-09-06 08:38:43,876 - INFO - step: 744,loss: 0.150 accuracy: 0.945\n",
      "2017-09-06 08:38:45,121 - INFO - step: 745,loss: 0.173 accuracy: 0.938\n",
      "2017-09-06 08:38:46,368 - INFO - step: 746,loss: 0.179 accuracy: 0.914\n",
      "2017-09-06 08:38:47,575 - INFO - step: 747,loss: 0.162 accuracy: 0.922\n",
      "2017-09-06 08:38:48,776 - INFO - step: 748,loss: 0.198 accuracy: 0.938\n",
      "2017-09-06 08:38:50,020 - INFO - step: 749,loss: 0.114 accuracy: 0.953\n",
      "2017-09-06 08:38:51,230 - INFO - step: 750,loss: 0.124 accuracy: 0.938\n",
      "2017-09-06 08:38:52,433 - INFO - step: 751,loss: 0.141 accuracy: 0.922\n",
      "2017-09-06 08:38:53,650 - INFO - step: 752,loss: 0.118 accuracy: 0.969\n",
      "2017-09-06 08:38:54,873 - INFO - step: 753,loss: 0.202 accuracy: 0.898\n",
      "2017-09-06 08:38:56,060 - INFO - step: 754,loss: 0.234 accuracy: 0.906\n",
      "2017-09-06 08:38:57,270 - INFO - step: 755,loss: 0.179 accuracy: 0.922\n",
      "2017-09-06 08:38:58,494 - INFO - step: 756,loss: 0.207 accuracy: 0.930\n",
      "2017-09-06 08:38:59,715 - INFO - step: 757,loss: 0.165 accuracy: 0.945\n",
      "2017-09-06 08:39:00,901 - INFO - step: 758,loss: 0.196 accuracy: 0.906\n",
      "2017-09-06 08:39:02,111 - INFO - step: 759,loss: 0.224 accuracy: 0.938\n",
      "2017-09-06 08:39:03,148 - INFO - step: 760,loss: 0.194 accuracy: 0.938\n",
      "2017-09-06 08:39:03,151 - INFO - \n",
      "train_epoch:37.000\n",
      "2017-09-06 08:39:03,153 - INFO - loss_total: 0.169 accuracy_total: 0.934\n",
      "2017-09-06 08:39:04,364 - INFO - step: 761,loss: 0.139 accuracy: 0.938\n",
      "2017-09-06 08:39:05,580 - INFO - step: 762,loss: 0.152 accuracy: 0.945\n",
      "2017-09-06 08:39:06,799 - INFO - step: 763,loss: 0.220 accuracy: 0.891\n",
      "2017-09-06 08:39:08,040 - INFO - step: 764,loss: 0.149 accuracy: 0.953\n",
      "2017-09-06 08:39:09,310 - INFO - step: 765,loss: 0.253 accuracy: 0.922\n",
      "2017-09-06 08:39:10,506 - INFO - step: 766,loss: 0.178 accuracy: 0.930\n",
      "2017-09-06 08:39:11,721 - INFO - step: 767,loss: 0.167 accuracy: 0.945\n",
      "2017-09-06 08:39:12,939 - INFO - step: 768,loss: 0.155 accuracy: 0.938\n",
      "2017-09-06 08:39:14,154 - INFO - step: 769,loss: 0.212 accuracy: 0.930\n",
      "2017-09-06 08:39:15,367 - INFO - step: 770,loss: 0.165 accuracy: 0.922\n",
      "2017-09-06 08:39:16,577 - INFO - step: 771,loss: 0.150 accuracy: 0.938\n",
      "2017-09-06 08:39:17,801 - INFO - step: 772,loss: 0.149 accuracy: 0.938\n",
      "2017-09-06 08:39:19,037 - INFO - step: 773,loss: 0.240 accuracy: 0.898\n",
      "2017-09-06 08:39:20,288 - INFO - step: 774,loss: 0.138 accuracy: 0.938\n",
      "2017-09-06 08:39:21,535 - INFO - step: 775,loss: 0.142 accuracy: 0.930\n",
      "2017-09-06 08:39:22,761 - INFO - step: 776,loss: 0.186 accuracy: 0.914\n",
      "2017-09-06 08:39:23,971 - INFO - step: 777,loss: 0.156 accuracy: 0.930\n",
      "2017-09-06 08:39:25,142 - INFO - step: 778,loss: 0.128 accuracy: 0.953\n",
      "2017-09-06 08:39:26,367 - INFO - step: 779,loss: 0.192 accuracy: 0.883\n",
      "2017-09-06 08:39:27,517 - INFO - step: 780,loss: 0.234 accuracy: 0.877\n",
      "2017-09-06 08:39:27,520 - INFO - \n",
      "train_epoch:38.000\n",
      "2017-09-06 08:39:27,522 - INFO - loss_total: 0.175 accuracy_total: 0.925\n",
      "2017-09-06 08:39:27,524 - INFO - \n",
      "Evaluation:38.000\n",
      "2017-09-06 08:39:28,069 - INFO - step: 780,loss: 0.293 accuracy: 0.892\n",
      "2017-09-06 08:39:28,070 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:39:29,304 - INFO - step: 781,loss: 0.167 accuracy: 0.922\n",
      "2017-09-06 08:39:30,525 - INFO - step: 782,loss: 0.167 accuracy: 0.914\n",
      "2017-09-06 08:39:31,756 - INFO - step: 783,loss: 0.225 accuracy: 0.930\n",
      "2017-09-06 08:39:32,985 - INFO - step: 784,loss: 0.190 accuracy: 0.898\n",
      "2017-09-06 08:39:34,200 - INFO - step: 785,loss: 0.145 accuracy: 0.930\n",
      "2017-09-06 08:39:35,368 - INFO - step: 786,loss: 0.166 accuracy: 0.945\n",
      "2017-09-06 08:39:36,573 - INFO - step: 787,loss: 0.148 accuracy: 0.938\n",
      "2017-09-06 08:39:37,773 - INFO - step: 788,loss: 0.200 accuracy: 0.922\n",
      "2017-09-06 08:39:38,991 - INFO - step: 789,loss: 0.137 accuracy: 0.945\n",
      "2017-09-06 08:39:40,195 - INFO - step: 790,loss: 0.231 accuracy: 0.891\n",
      "2017-09-06 08:39:41,412 - INFO - step: 791,loss: 0.125 accuracy: 0.945\n",
      "2017-09-06 08:39:42,640 - INFO - step: 792,loss: 0.192 accuracy: 0.914\n",
      "2017-09-06 08:39:43,849 - INFO - step: 793,loss: 0.189 accuracy: 0.922\n",
      "2017-09-06 08:39:45,088 - INFO - step: 794,loss: 0.150 accuracy: 0.953\n",
      "2017-09-06 08:39:46,314 - INFO - step: 795,loss: 0.176 accuracy: 0.930\n",
      "2017-09-06 08:39:47,518 - INFO - step: 796,loss: 0.144 accuracy: 0.953\n",
      "2017-09-06 08:39:48,738 - INFO - step: 797,loss: 0.157 accuracy: 0.938\n",
      "2017-09-06 08:39:49,962 - INFO - step: 798,loss: 0.140 accuracy: 0.938\n",
      "2017-09-06 08:39:51,187 - INFO - step: 799,loss: 0.133 accuracy: 0.945\n",
      "2017-09-06 08:39:52,294 - INFO - step: 800,loss: 0.147 accuracy: 0.923\n",
      "2017-09-06 08:39:52,296 - INFO - \n",
      "train_epoch:39.000\n",
      "2017-09-06 08:39:52,298 - INFO - loss_total: 0.166 accuracy_total: 0.930\n",
      "2017-09-06 08:39:53,543 - INFO - step: 801,loss: 0.118 accuracy: 0.977\n",
      "2017-09-06 08:39:54,712 - INFO - step: 802,loss: 0.149 accuracy: 0.945\n",
      "2017-09-06 08:39:55,918 - INFO - step: 803,loss: 0.141 accuracy: 0.945\n",
      "2017-09-06 08:39:57,128 - INFO - step: 804,loss: 0.146 accuracy: 0.938\n",
      "2017-09-06 08:39:58,325 - INFO - step: 805,loss: 0.222 accuracy: 0.906\n",
      "2017-09-06 08:39:59,527 - INFO - step: 806,loss: 0.212 accuracy: 0.898\n",
      "2017-09-06 08:40:00,732 - INFO - step: 807,loss: 0.182 accuracy: 0.945\n",
      "2017-09-06 08:40:01,940 - INFO - step: 808,loss: 0.144 accuracy: 0.938\n",
      "2017-09-06 08:40:03,162 - INFO - step: 809,loss: 0.213 accuracy: 0.906\n",
      "2017-09-06 08:40:04,344 - INFO - step: 810,loss: 0.168 accuracy: 0.930\n",
      "2017-09-06 08:40:05,547 - INFO - step: 811,loss: 0.129 accuracy: 0.938\n",
      "2017-09-06 08:40:06,761 - INFO - step: 812,loss: 0.176 accuracy: 0.898\n",
      "2017-09-06 08:40:07,993 - INFO - step: 813,loss: 0.146 accuracy: 0.945\n",
      "2017-09-06 08:40:09,218 - INFO - step: 814,loss: 0.239 accuracy: 0.875\n",
      "2017-09-06 08:40:10,431 - INFO - step: 815,loss: 0.159 accuracy: 0.930\n",
      "2017-09-06 08:40:11,641 - INFO - step: 816,loss: 0.182 accuracy: 0.938\n",
      "2017-09-06 08:40:12,870 - INFO - step: 817,loss: 0.171 accuracy: 0.945\n",
      "2017-09-06 08:40:14,092 - INFO - step: 818,loss: 0.165 accuracy: 0.930\n",
      "2017-09-06 08:40:15,305 - INFO - step: 819,loss: 0.150 accuracy: 0.945\n",
      "2017-09-06 08:40:16,417 - INFO - step: 820,loss: 0.188 accuracy: 0.877\n",
      "2017-09-06 08:40:16,419 - INFO - \n",
      "train_epoch:40.000\n",
      "2017-09-06 08:40:16,421 - INFO - loss_total: 0.170 accuracy_total: 0.927\n",
      "2017-09-06 08:40:16,423 - INFO - \n",
      "Evaluation:40.000\n",
      "2017-09-06 08:40:16,967 - INFO - step: 820,loss: 0.281 accuracy: 0.906\n",
      "2017-09-06 08:40:16,969 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:40:18,211 - INFO - step: 821,loss: 0.208 accuracy: 0.906\n",
      "2017-09-06 08:40:19,416 - INFO - step: 822,loss: 0.215 accuracy: 0.898\n",
      "2017-09-06 08:40:20,635 - INFO - step: 823,loss: 0.139 accuracy: 0.938\n",
      "2017-09-06 08:40:21,836 - INFO - step: 824,loss: 0.189 accuracy: 0.922\n",
      "2017-09-06 08:40:23,075 - INFO - step: 825,loss: 0.143 accuracy: 0.961\n",
      "2017-09-06 08:40:24,295 - INFO - step: 826,loss: 0.129 accuracy: 0.953\n",
      "2017-09-06 08:40:25,506 - INFO - step: 827,loss: 0.174 accuracy: 0.930\n",
      "2017-09-06 08:40:26,718 - INFO - step: 828,loss: 0.150 accuracy: 0.953\n",
      "2017-09-06 08:40:27,908 - INFO - step: 829,loss: 0.182 accuracy: 0.906\n",
      "2017-09-06 08:40:29,111 - INFO - step: 830,loss: 0.189 accuracy: 0.906\n",
      "2017-09-06 08:40:30,342 - INFO - step: 831,loss: 0.170 accuracy: 0.930\n",
      "2017-09-06 08:40:31,561 - INFO - step: 832,loss: 0.089 accuracy: 0.977\n",
      "2017-09-06 08:40:32,767 - INFO - step: 833,loss: 0.111 accuracy: 0.969\n",
      "2017-09-06 08:40:33,982 - INFO - step: 834,loss: 0.275 accuracy: 0.922\n",
      "2017-09-06 08:40:35,233 - INFO - step: 835,loss: 0.153 accuracy: 0.945\n",
      "2017-09-06 08:40:36,436 - INFO - step: 836,loss: 0.188 accuracy: 0.922\n",
      "2017-09-06 08:40:37,666 - INFO - step: 837,loss: 0.186 accuracy: 0.914\n",
      "2017-09-06 08:40:38,917 - INFO - step: 838,loss: 0.114 accuracy: 0.961\n",
      "2017-09-06 08:40:40,164 - INFO - step: 839,loss: 0.146 accuracy: 0.945\n",
      "2017-09-06 08:40:41,287 - INFO - step: 840,loss: 0.192 accuracy: 0.923\n",
      "2017-09-06 08:40:41,289 - INFO - \n",
      "train_epoch:41.000\n",
      "2017-09-06 08:40:41,291 - INFO - loss_total: 0.167 accuracy_total: 0.934\n",
      "2017-09-06 08:40:42,523 - INFO - step: 841,loss: 0.141 accuracy: 0.930\n",
      "2017-09-06 08:40:43,729 - INFO - step: 842,loss: 0.135 accuracy: 0.961\n",
      "2017-09-06 08:40:44,941 - INFO - step: 843,loss: 0.111 accuracy: 0.961\n",
      "2017-09-06 08:40:46,137 - INFO - step: 844,loss: 0.138 accuracy: 0.953\n",
      "2017-09-06 08:40:47,353 - INFO - step: 845,loss: 0.154 accuracy: 0.945\n",
      "2017-09-06 08:40:48,572 - INFO - step: 846,loss: 0.204 accuracy: 0.922\n",
      "2017-09-06 08:40:49,779 - INFO - step: 847,loss: 0.118 accuracy: 0.961\n",
      "2017-09-06 08:40:50,983 - INFO - step: 848,loss: 0.180 accuracy: 0.922\n",
      "2017-09-06 08:40:52,190 - INFO - step: 849,loss: 0.156 accuracy: 0.922\n",
      "2017-09-06 08:40:53,389 - INFO - step: 850,loss: 0.141 accuracy: 0.945\n",
      "2017-09-06 08:40:54,640 - INFO - step: 851,loss: 0.143 accuracy: 0.938\n",
      "2017-09-06 08:40:55,857 - INFO - step: 852,loss: 0.167 accuracy: 0.922\n",
      "2017-09-06 08:40:57,081 - INFO - step: 853,loss: 0.116 accuracy: 0.953\n",
      "2017-09-06 08:40:58,288 - INFO - step: 854,loss: 0.203 accuracy: 0.930\n",
      "2017-09-06 08:40:59,499 - INFO - step: 855,loss: 0.201 accuracy: 0.914\n",
      "2017-09-06 08:41:00,713 - INFO - step: 856,loss: 0.116 accuracy: 0.969\n",
      "2017-09-06 08:41:01,987 - INFO - step: 857,loss: 0.161 accuracy: 0.945\n",
      "2017-09-06 08:41:03,201 - INFO - step: 858,loss: 0.138 accuracy: 0.945\n",
      "2017-09-06 08:41:04,415 - INFO - step: 859,loss: 0.153 accuracy: 0.945\n",
      "2017-09-06 08:41:05,520 - INFO - step: 860,loss: 0.191 accuracy: 0.938\n",
      "2017-09-06 08:41:05,522 - INFO - \n",
      "train_epoch:42.000\n",
      "2017-09-06 08:41:05,524 - INFO - loss_total: 0.153 accuracy_total: 0.941\n",
      "2017-09-06 08:41:05,525 - INFO - \n",
      "Evaluation:42.000\n",
      "2017-09-06 08:41:06,058 - INFO - step: 860,loss: 0.294 accuracy: 0.896\n",
      "2017-09-06 08:41:06,060 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:41:07,275 - INFO - step: 861,loss: 0.132 accuracy: 0.953\n",
      "2017-09-06 08:41:08,493 - INFO - step: 862,loss: 0.175 accuracy: 0.930\n",
      "2017-09-06 08:41:09,716 - INFO - step: 863,loss: 0.155 accuracy: 0.945\n",
      "2017-09-06 08:41:10,930 - INFO - step: 864,loss: 0.127 accuracy: 0.953\n",
      "2017-09-06 08:41:12,146 - INFO - step: 865,loss: 0.146 accuracy: 0.914\n",
      "2017-09-06 08:41:13,404 - INFO - step: 866,loss: 0.143 accuracy: 0.953\n",
      "2017-09-06 08:41:14,620 - INFO - step: 867,loss: 0.138 accuracy: 0.945\n",
      "2017-09-06 08:41:15,826 - INFO - step: 868,loss: 0.129 accuracy: 0.953\n",
      "2017-09-06 08:41:17,042 - INFO - step: 869,loss: 0.232 accuracy: 0.906\n",
      "2017-09-06 08:41:18,257 - INFO - step: 870,loss: 0.181 accuracy: 0.945\n",
      "2017-09-06 08:41:19,496 - INFO - step: 871,loss: 0.160 accuracy: 0.938\n",
      "2017-09-06 08:41:20,715 - INFO - step: 872,loss: 0.184 accuracy: 0.930\n",
      "2017-09-06 08:41:21,921 - INFO - step: 873,loss: 0.126 accuracy: 0.961\n",
      "2017-09-06 08:41:23,139 - INFO - step: 874,loss: 0.201 accuracy: 0.906\n",
      "2017-09-06 08:41:24,367 - INFO - step: 875,loss: 0.172 accuracy: 0.922\n",
      "2017-09-06 08:41:25,586 - INFO - step: 876,loss: 0.090 accuracy: 0.977\n",
      "2017-09-06 08:41:26,804 - INFO - step: 877,loss: 0.193 accuracy: 0.914\n",
      "2017-09-06 08:41:28,032 - INFO - step: 878,loss: 0.162 accuracy: 0.930\n",
      "2017-09-06 08:41:29,260 - INFO - step: 879,loss: 0.125 accuracy: 0.953\n",
      "2017-09-06 08:41:30,404 - INFO - step: 880,loss: 0.160 accuracy: 0.969\n",
      "2017-09-06 08:41:30,407 - INFO - \n",
      "train_epoch:43.000\n",
      "2017-09-06 08:41:30,409 - INFO - loss_total: 0.157 accuracy_total: 0.940\n",
      "2017-09-06 08:41:31,641 - INFO - step: 881,loss: 0.205 accuracy: 0.906\n",
      "2017-09-06 08:41:32,867 - INFO - step: 882,loss: 0.149 accuracy: 0.945\n",
      "2017-09-06 08:41:34,079 - INFO - step: 883,loss: 0.108 accuracy: 0.961\n",
      "2017-09-06 08:41:35,318 - INFO - step: 884,loss: 0.141 accuracy: 0.953\n",
      "2017-09-06 08:41:36,529 - INFO - step: 885,loss: 0.162 accuracy: 0.930\n",
      "2017-09-06 08:41:37,748 - INFO - step: 886,loss: 0.133 accuracy: 0.938\n",
      "2017-09-06 08:41:38,902 - INFO - step: 887,loss: 0.115 accuracy: 0.938\n",
      "2017-09-06 08:41:40,126 - INFO - step: 888,loss: 0.151 accuracy: 0.945\n",
      "2017-09-06 08:41:41,356 - INFO - step: 889,loss: 0.205 accuracy: 0.898\n",
      "2017-09-06 08:41:42,569 - INFO - step: 890,loss: 0.141 accuracy: 0.945\n",
      "2017-09-06 08:41:43,781 - INFO - step: 891,loss: 0.196 accuracy: 0.930\n",
      "2017-09-06 08:41:45,008 - INFO - step: 892,loss: 0.339 accuracy: 0.852\n",
      "2017-09-06 08:41:46,230 - INFO - step: 893,loss: 0.189 accuracy: 0.930\n",
      "2017-09-06 08:41:47,448 - INFO - step: 894,loss: 0.181 accuracy: 0.930\n",
      "2017-09-06 08:41:48,674 - INFO - step: 895,loss: 0.177 accuracy: 0.938\n",
      "2017-09-06 08:41:49,857 - INFO - step: 896,loss: 0.099 accuracy: 0.969\n",
      "2017-09-06 08:41:51,076 - INFO - step: 897,loss: 0.088 accuracy: 0.961\n",
      "2017-09-06 08:41:52,293 - INFO - step: 898,loss: 0.128 accuracy: 0.945\n",
      "2017-09-06 08:41:53,523 - INFO - step: 899,loss: 0.170 accuracy: 0.930\n",
      "2017-09-06 08:41:54,616 - INFO - step: 900,loss: 0.147 accuracy: 0.969\n",
      "2017-09-06 08:41:54,619 - INFO - \n",
      "train_epoch:44.000\n",
      "2017-09-06 08:41:54,621 - INFO - loss_total: 0.161 accuracy_total: 0.936\n",
      "2017-09-06 08:41:54,622 - INFO - \n",
      "Evaluation:44.000\n",
      "2017-09-06 08:41:55,166 - INFO - step: 900,loss: 0.282 accuracy: 0.896\n",
      "2017-09-06 08:41:55,167 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:41:56,404 - INFO - step: 901,loss: 0.097 accuracy: 0.961\n",
      "2017-09-06 08:41:57,617 - INFO - step: 902,loss: 0.159 accuracy: 0.945\n",
      "2017-09-06 08:41:58,835 - INFO - step: 903,loss: 0.139 accuracy: 0.938\n",
      "2017-09-06 08:42:00,044 - INFO - step: 904,loss: 0.181 accuracy: 0.914\n",
      "2017-09-06 08:42:01,256 - INFO - step: 905,loss: 0.238 accuracy: 0.883\n",
      "2017-09-06 08:42:02,459 - INFO - step: 906,loss: 0.130 accuracy: 0.945\n",
      "2017-09-06 08:42:03,684 - INFO - step: 907,loss: 0.142 accuracy: 0.938\n",
      "2017-09-06 08:42:04,893 - INFO - step: 908,loss: 0.102 accuracy: 0.961\n",
      "2017-09-06 08:42:06,040 - INFO - step: 909,loss: 0.142 accuracy: 0.914\n",
      "2017-09-06 08:42:07,255 - INFO - step: 910,loss: 0.177 accuracy: 0.930\n",
      "2017-09-06 08:42:08,489 - INFO - step: 911,loss: 0.216 accuracy: 0.875\n",
      "2017-09-06 08:42:09,723 - INFO - step: 912,loss: 0.122 accuracy: 0.953\n",
      "2017-09-06 08:42:10,946 - INFO - step: 913,loss: 0.158 accuracy: 0.945\n",
      "2017-09-06 08:42:12,163 - INFO - step: 914,loss: 0.115 accuracy: 0.945\n",
      "2017-09-06 08:42:13,377 - INFO - step: 915,loss: 0.215 accuracy: 0.867\n",
      "2017-09-06 08:42:14,616 - INFO - step: 916,loss: 0.159 accuracy: 0.945\n",
      "2017-09-06 08:42:15,836 - INFO - step: 917,loss: 0.217 accuracy: 0.898\n",
      "2017-09-06 08:42:17,052 - INFO - step: 918,loss: 0.130 accuracy: 0.930\n",
      "2017-09-06 08:42:18,269 - INFO - step: 919,loss: 0.125 accuracy: 0.977\n",
      "2017-09-06 08:42:19,368 - INFO - step: 920,loss: 0.182 accuracy: 0.908\n",
      "2017-09-06 08:42:19,371 - INFO - \n",
      "train_epoch:45.000\n",
      "2017-09-06 08:42:19,373 - INFO - loss_total: 0.157 accuracy_total: 0.929\n",
      "2017-09-06 08:42:20,607 - INFO - step: 921,loss: 0.111 accuracy: 0.938\n",
      "2017-09-06 08:42:21,822 - INFO - step: 922,loss: 0.193 accuracy: 0.867\n",
      "2017-09-06 08:42:23,061 - INFO - step: 923,loss: 0.165 accuracy: 0.938\n",
      "2017-09-06 08:42:24,270 - INFO - step: 924,loss: 0.143 accuracy: 0.938\n",
      "2017-09-06 08:42:25,465 - INFO - step: 925,loss: 0.165 accuracy: 0.922\n",
      "2017-09-06 08:42:26,659 - INFO - step: 926,loss: 0.138 accuracy: 0.930\n",
      "2017-09-06 08:42:27,872 - INFO - step: 927,loss: 0.133 accuracy: 0.969\n",
      "2017-09-06 08:42:29,083 - INFO - step: 928,loss: 0.236 accuracy: 0.914\n",
      "2017-09-06 08:42:30,322 - INFO - step: 929,loss: 0.274 accuracy: 0.875\n",
      "2017-09-06 08:42:31,514 - INFO - step: 930,loss: 0.129 accuracy: 0.945\n",
      "2017-09-06 08:42:32,727 - INFO - step: 931,loss: 0.119 accuracy: 0.953\n",
      "2017-09-06 08:42:33,936 - INFO - step: 932,loss: 0.155 accuracy: 0.953\n",
      "2017-09-06 08:42:35,153 - INFO - step: 933,loss: 0.215 accuracy: 0.891\n",
      "2017-09-06 08:42:36,364 - INFO - step: 934,loss: 0.196 accuracy: 0.945\n",
      "2017-09-06 08:42:37,576 - INFO - step: 935,loss: 0.146 accuracy: 0.930\n",
      "2017-09-06 08:42:38,798 - INFO - step: 936,loss: 0.117 accuracy: 0.961\n",
      "2017-09-06 08:42:39,990 - INFO - step: 937,loss: 0.170 accuracy: 0.906\n",
      "2017-09-06 08:42:41,206 - INFO - step: 938,loss: 0.095 accuracy: 0.977\n",
      "2017-09-06 08:42:42,427 - INFO - step: 939,loss: 0.095 accuracy: 0.977\n",
      "2017-09-06 08:42:43,547 - INFO - step: 940,loss: 0.304 accuracy: 0.846\n",
      "2017-09-06 08:42:43,549 - INFO - \n",
      "train_epoch:46.000\n",
      "2017-09-06 08:42:43,551 - INFO - loss_total: 0.165 accuracy_total: 0.929\n",
      "2017-09-06 08:42:43,553 - INFO - \n",
      "Evaluation:46.000\n",
      "2017-09-06 08:42:44,096 - INFO - step: 940,loss: 0.259 accuracy: 0.914\n",
      "2017-09-06 08:42:44,097 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:42:44,340 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-940 at epoch 46.\n",
      "2017-09-06 08:42:45,542 - INFO - step: 941,loss: 0.138 accuracy: 0.953\n",
      "2017-09-06 08:42:46,758 - INFO - step: 942,loss: 0.181 accuracy: 0.922\n",
      "2017-09-06 08:42:47,914 - INFO - step: 943,loss: 0.218 accuracy: 0.914\n",
      "2017-09-06 08:42:49,085 - INFO - step: 944,loss: 0.146 accuracy: 0.945\n",
      "2017-09-06 08:42:50,302 - INFO - step: 945,loss: 0.207 accuracy: 0.898\n",
      "2017-09-06 08:42:51,518 - INFO - step: 946,loss: 0.156 accuracy: 0.930\n",
      "2017-09-06 08:42:52,748 - INFO - step: 947,loss: 0.131 accuracy: 0.953\n",
      "2017-09-06 08:42:53,969 - INFO - step: 948,loss: 0.133 accuracy: 0.969\n",
      "2017-09-06 08:42:55,192 - INFO - step: 949,loss: 0.158 accuracy: 0.945\n",
      "2017-09-06 08:42:56,435 - INFO - step: 950,loss: 0.131 accuracy: 0.961\n",
      "2017-09-06 08:42:57,621 - INFO - step: 951,loss: 0.217 accuracy: 0.914\n",
      "2017-09-06 08:42:58,844 - INFO - step: 952,loss: 0.266 accuracy: 0.891\n",
      "2017-09-06 08:43:00,050 - INFO - step: 953,loss: 0.179 accuracy: 0.922\n",
      "2017-09-06 08:43:01,263 - INFO - step: 954,loss: 0.129 accuracy: 0.945\n",
      "2017-09-06 08:43:02,496 - INFO - step: 955,loss: 0.226 accuracy: 0.922\n",
      "2017-09-06 08:43:03,712 - INFO - step: 956,loss: 0.130 accuracy: 0.953\n",
      "2017-09-06 08:43:04,935 - INFO - step: 957,loss: 0.111 accuracy: 0.961\n",
      "2017-09-06 08:43:06,157 - INFO - step: 958,loss: 0.151 accuracy: 0.953\n",
      "2017-09-06 08:43:07,370 - INFO - step: 959,loss: 0.168 accuracy: 0.922\n",
      "2017-09-06 08:43:08,487 - INFO - step: 960,loss: 0.083 accuracy: 0.954\n",
      "2017-09-06 08:43:08,492 - INFO - \n",
      "train_epoch:47.000\n",
      "2017-09-06 08:43:08,494 - INFO - loss_total: 0.163 accuracy_total: 0.936\n",
      "2017-09-06 08:43:09,729 - INFO - step: 961,loss: 0.139 accuracy: 0.938\n",
      "2017-09-06 08:43:10,923 - INFO - step: 962,loss: 0.141 accuracy: 0.945\n",
      "2017-09-06 08:43:12,133 - INFO - step: 963,loss: 0.153 accuracy: 0.953\n",
      "2017-09-06 08:43:13,358 - INFO - step: 964,loss: 0.209 accuracy: 0.898\n",
      "2017-09-06 08:43:14,601 - INFO - step: 965,loss: 0.246 accuracy: 0.883\n",
      "2017-09-06 08:43:15,815 - INFO - step: 966,loss: 0.147 accuracy: 0.938\n",
      "2017-09-06 08:43:17,035 - INFO - step: 967,loss: 0.146 accuracy: 0.945\n",
      "2017-09-06 08:43:18,281 - INFO - step: 968,loss: 0.144 accuracy: 0.938\n",
      "2017-09-06 08:43:19,498 - INFO - step: 969,loss: 0.106 accuracy: 0.969\n",
      "2017-09-06 08:43:20,728 - INFO - step: 970,loss: 0.179 accuracy: 0.922\n",
      "2017-09-06 08:43:21,936 - INFO - step: 971,loss: 0.156 accuracy: 0.953\n",
      "2017-09-06 08:43:23,088 - INFO - step: 972,loss: 0.122 accuracy: 0.953\n",
      "2017-09-06 08:43:24,298 - INFO - step: 973,loss: 0.136 accuracy: 0.930\n",
      "2017-09-06 08:43:25,517 - INFO - step: 974,loss: 0.141 accuracy: 0.945\n",
      "2017-09-06 08:43:26,703 - INFO - step: 975,loss: 0.194 accuracy: 0.914\n",
      "2017-09-06 08:43:27,894 - INFO - step: 976,loss: 0.153 accuracy: 0.953\n",
      "2017-09-06 08:43:29,135 - INFO - step: 977,loss: 0.179 accuracy: 0.914\n",
      "2017-09-06 08:43:30,347 - INFO - step: 978,loss: 0.166 accuracy: 0.930\n",
      "2017-09-06 08:43:31,557 - INFO - step: 979,loss: 0.124 accuracy: 0.969\n",
      "2017-09-06 08:43:32,667 - INFO - step: 980,loss: 0.107 accuracy: 0.954\n",
      "2017-09-06 08:43:32,670 - INFO - \n",
      "train_epoch:48.000\n",
      "2017-09-06 08:43:32,672 - INFO - loss_total: 0.154 accuracy_total: 0.937\n",
      "2017-09-06 08:43:32,673 - INFO - \n",
      "Evaluation:48.000\n",
      "2017-09-06 08:43:33,204 - INFO - step: 980,loss: 0.238 accuracy: 0.924\n",
      "2017-09-06 08:43:33,205 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:43:33,588 - INFO - Saving model to /home/zx/cuckoo_1000/session_save/checkpoints/model-980 at epoch 48.\n",
      "2017-09-06 08:43:34,782 - INFO - step: 981,loss: 0.139 accuracy: 0.945\n",
      "2017-09-06 08:43:35,998 - INFO - step: 982,loss: 0.115 accuracy: 0.953\n",
      "2017-09-06 08:43:37,213 - INFO - step: 983,loss: 0.194 accuracy: 0.914\n",
      "2017-09-06 08:43:38,430 - INFO - step: 984,loss: 0.115 accuracy: 0.953\n",
      "2017-09-06 08:43:39,645 - INFO - step: 985,loss: 0.179 accuracy: 0.938\n",
      "2017-09-06 08:43:40,892 - INFO - step: 986,loss: 0.159 accuracy: 0.914\n",
      "2017-09-06 08:43:42,075 - INFO - step: 987,loss: 0.111 accuracy: 0.945\n",
      "2017-09-06 08:43:43,300 - INFO - step: 988,loss: 0.171 accuracy: 0.938\n",
      "2017-09-06 08:43:44,502 - INFO - step: 989,loss: 0.243 accuracy: 0.898\n",
      "2017-09-06 08:43:45,793 - INFO - step: 990,loss: 0.172 accuracy: 0.930\n",
      "2017-09-06 08:43:47,035 - INFO - step: 991,loss: 0.143 accuracy: 0.938\n",
      "2017-09-06 08:43:48,239 - INFO - step: 992,loss: 0.163 accuracy: 0.953\n",
      "2017-09-06 08:43:49,441 - INFO - step: 993,loss: 0.127 accuracy: 0.945\n",
      "2017-09-06 08:43:50,652 - INFO - step: 994,loss: 0.181 accuracy: 0.930\n",
      "2017-09-06 08:43:51,862 - INFO - step: 995,loss: 0.142 accuracy: 0.953\n",
      "2017-09-06 08:43:53,457 - INFO - step: 996,loss: 0.193 accuracy: 0.922\n",
      "2017-09-06 08:43:54,711 - INFO - step: 997,loss: 0.171 accuracy: 0.914\n",
      "2017-09-06 08:43:57,722 - INFO - step: 998,loss: 0.171 accuracy: 0.922\n",
      "2017-09-06 08:44:01,127 - INFO - step: 999,loss: 0.177 accuracy: 0.922\n",
      "2017-09-06 08:44:02,839 - INFO - step: 1000,loss: 0.144 accuracy: 0.938\n",
      "2017-09-06 08:44:02,842 - INFO - \n",
      "train_epoch:49.000\n",
      "2017-09-06 08:44:02,844 - INFO - loss_total: 0.161 accuracy_total: 0.933\n",
      "2017-09-06 08:44:04,952 - INFO - step: 1001,loss: 0.141 accuracy: 0.938\n",
      "2017-09-06 08:44:06,901 - INFO - step: 1002,loss: 0.090 accuracy: 0.969\n",
      "2017-09-06 08:44:08,801 - INFO - step: 1003,loss: 0.154 accuracy: 0.930\n",
      "2017-09-06 08:44:10,546 - INFO - step: 1004,loss: 0.212 accuracy: 0.906\n",
      "2017-09-06 08:44:12,542 - INFO - step: 1005,loss: 0.137 accuracy: 0.945\n",
      "2017-09-06 08:44:14,525 - INFO - step: 1006,loss: 0.182 accuracy: 0.922\n",
      "2017-09-06 08:44:16,451 - INFO - step: 1007,loss: 0.140 accuracy: 0.914\n",
      "2017-09-06 08:44:18,460 - INFO - step: 1008,loss: 0.121 accuracy: 0.953\n",
      "2017-09-06 08:44:20,510 - INFO - step: 1009,loss: 0.106 accuracy: 0.977\n",
      "2017-09-06 08:44:22,397 - INFO - step: 1010,loss: 0.133 accuracy: 0.945\n",
      "2017-09-06 08:44:24,358 - INFO - step: 1011,loss: 0.195 accuracy: 0.930\n",
      "2017-09-06 08:44:26,348 - INFO - step: 1012,loss: 0.119 accuracy: 0.961\n",
      "2017-09-06 08:44:28,297 - INFO - step: 1013,loss: 0.158 accuracy: 0.914\n",
      "2017-09-06 08:44:30,261 - INFO - step: 1014,loss: 0.119 accuracy: 0.945\n",
      "2017-09-06 08:44:32,276 - INFO - step: 1015,loss: 0.132 accuracy: 0.961\n",
      "2017-09-06 08:44:34,196 - INFO - step: 1016,loss: 0.152 accuracy: 0.922\n",
      "2017-09-06 08:44:36,019 - INFO - step: 1017,loss: 0.155 accuracy: 0.930\n",
      "2017-09-06 08:44:37,947 - INFO - step: 1018,loss: 0.153 accuracy: 0.938\n",
      "2017-09-06 08:44:39,888 - INFO - step: 1019,loss: 0.135 accuracy: 0.961\n",
      "2017-09-06 08:44:41,530 - INFO - step: 1020,loss: 0.237 accuracy: 0.877\n",
      "2017-09-06 08:44:41,532 - INFO - \n",
      "train_epoch:50.000\n",
      "2017-09-06 08:44:41,534 - INFO - loss_total: 0.149 accuracy_total: 0.937\n",
      "2017-09-06 08:44:41,536 - INFO - \n",
      "Evaluation:50.000\n",
      "2017-09-06 08:44:42,439 - INFO - step: 1020,loss: 0.242 accuracy: 0.914\n",
      "2017-09-06 08:44:42,440 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:44:44,414 - INFO - step: 1021,loss: 0.150 accuracy: 0.938\n",
      "2017-09-06 08:44:46,398 - INFO - step: 1022,loss: 0.221 accuracy: 0.883\n",
      "2017-09-06 08:44:48,281 - INFO - step: 1023,loss: 0.141 accuracy: 0.938\n",
      "2017-09-06 08:44:50,251 - INFO - step: 1024,loss: 0.080 accuracy: 1.000\n",
      "2017-09-06 08:44:52,211 - INFO - step: 1025,loss: 0.154 accuracy: 0.953\n",
      "2017-09-06 08:44:53,988 - INFO - step: 1026,loss: 0.133 accuracy: 0.961\n",
      "2017-09-06 08:44:55,961 - INFO - step: 1027,loss: 0.141 accuracy: 0.930\n",
      "2017-09-06 08:44:57,920 - INFO - step: 1028,loss: 0.123 accuracy: 0.961\n",
      "2017-09-06 08:44:59,722 - INFO - step: 1029,loss: 0.179 accuracy: 0.922\n",
      "2017-09-06 08:45:01,711 - INFO - step: 1030,loss: 0.147 accuracy: 0.938\n",
      "2017-09-06 08:45:03,704 - INFO - step: 1031,loss: 0.109 accuracy: 0.969\n",
      "2017-09-06 08:45:05,553 - INFO - step: 1032,loss: 0.132 accuracy: 0.930\n",
      "2017-09-06 08:45:07,560 - INFO - step: 1033,loss: 0.132 accuracy: 0.961\n",
      "2017-09-06 08:45:09,546 - INFO - step: 1034,loss: 0.094 accuracy: 0.961\n",
      "2017-09-06 08:45:11,348 - INFO - step: 1035,loss: 0.213 accuracy: 0.898\n",
      "2017-09-06 08:45:13,334 - INFO - step: 1036,loss: 0.162 accuracy: 0.922\n",
      "2017-09-06 08:45:15,277 - INFO - step: 1037,loss: 0.184 accuracy: 0.922\n",
      "2017-09-06 08:45:17,135 - INFO - step: 1038,loss: 0.112 accuracy: 0.961\n",
      "2017-09-06 08:45:19,102 - INFO - step: 1039,loss: 0.136 accuracy: 0.938\n",
      "2017-09-06 08:45:20,903 - INFO - step: 1040,loss: 0.119 accuracy: 0.969\n",
      "2017-09-06 08:45:20,905 - INFO - \n",
      "train_epoch:51.000\n",
      "2017-09-06 08:45:20,908 - INFO - loss_total: 0.143 accuracy_total: 0.943\n",
      "2017-09-06 08:45:22,894 - INFO - step: 1041,loss: 0.127 accuracy: 0.953\n",
      "2017-09-06 08:45:24,900 - INFO - step: 1042,loss: 0.137 accuracy: 0.961\n",
      "2017-09-06 08:45:26,869 - INFO - step: 1043,loss: 0.115 accuracy: 0.953\n",
      "2017-09-06 08:45:28,650 - INFO - step: 1044,loss: 0.155 accuracy: 0.914\n",
      "2017-09-06 08:45:30,616 - INFO - step: 1045,loss: 0.099 accuracy: 0.953\n",
      "2017-09-06 08:45:32,615 - INFO - step: 1046,loss: 0.129 accuracy: 0.953\n",
      "2017-09-06 08:45:34,475 - INFO - step: 1047,loss: 0.155 accuracy: 0.953\n",
      "2017-09-06 08:45:36,433 - INFO - step: 1048,loss: 0.149 accuracy: 0.930\n",
      "2017-09-06 08:45:38,415 - INFO - step: 1049,loss: 0.161 accuracy: 0.938\n",
      "2017-09-06 08:45:40,344 - INFO - step: 1050,loss: 0.163 accuracy: 0.914\n",
      "2017-09-06 08:45:42,311 - INFO - step: 1051,loss: 0.154 accuracy: 0.922\n",
      "2017-09-06 08:45:44,288 - INFO - step: 1052,loss: 0.121 accuracy: 0.945\n",
      "2017-09-06 08:45:46,164 - INFO - step: 1053,loss: 0.133 accuracy: 0.938\n",
      "2017-09-06 08:45:48,137 - INFO - step: 1054,loss: 0.138 accuracy: 0.945\n",
      "2017-09-06 08:45:50,086 - INFO - step: 1055,loss: 0.168 accuracy: 0.922\n",
      "2017-09-06 08:45:52,011 - INFO - step: 1056,loss: 0.126 accuracy: 0.953\n",
      "2017-09-06 08:45:53,981 - INFO - step: 1057,loss: 0.227 accuracy: 0.914\n",
      "2017-09-06 08:45:55,950 - INFO - step: 1058,loss: 0.127 accuracy: 0.953\n",
      "2017-09-06 08:45:57,911 - INFO - step: 1059,loss: 0.210 accuracy: 0.883\n",
      "2017-09-06 08:45:59,705 - INFO - step: 1060,loss: 0.137 accuracy: 0.954\n",
      "2017-09-06 08:45:59,708 - INFO - \n",
      "train_epoch:52.000\n",
      "2017-09-06 08:45:59,710 - INFO - loss_total: 0.147 accuracy_total: 0.938\n",
      "2017-09-06 08:45:59,711 - INFO - \n",
      "Evaluation:52.000\n",
      "2017-09-06 08:46:00,583 - INFO - step: 1060,loss: 0.309 accuracy: 0.899\n",
      "2017-09-06 08:46:00,585 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:46:02,592 - INFO - step: 1061,loss: 0.122 accuracy: 0.938\n",
      "2017-09-06 08:46:04,409 - INFO - step: 1062,loss: 0.156 accuracy: 0.930\n",
      "2017-09-06 08:46:06,394 - INFO - step: 1063,loss: 0.125 accuracy: 0.961\n",
      "2017-09-06 08:46:08,383 - INFO - step: 1064,loss: 0.107 accuracy: 0.969\n",
      "2017-09-06 08:46:10,171 - INFO - step: 1065,loss: 0.172 accuracy: 0.930\n",
      "2017-09-06 08:46:12,147 - INFO - step: 1066,loss: 0.177 accuracy: 0.938\n",
      "2017-09-06 08:46:14,093 - INFO - step: 1067,loss: 0.160 accuracy: 0.930\n",
      "2017-09-06 08:46:16,092 - INFO - step: 1068,loss: 0.139 accuracy: 0.953\n",
      "2017-09-06 08:46:18,049 - INFO - step: 1069,loss: 0.163 accuracy: 0.914\n",
      "2017-09-06 08:46:20,019 - INFO - step: 1070,loss: 0.232 accuracy: 0.898\n",
      "2017-09-06 08:46:21,977 - INFO - step: 1071,loss: 0.104 accuracy: 0.961\n",
      "2017-09-06 08:46:23,946 - INFO - step: 1072,loss: 0.149 accuracy: 0.953\n",
      "2017-09-06 08:46:25,887 - INFO - step: 1073,loss: 0.113 accuracy: 0.961\n",
      "2017-09-06 08:46:27,721 - INFO - step: 1074,loss: 0.223 accuracy: 0.898\n",
      "2017-09-06 08:46:29,700 - INFO - step: 1075,loss: 0.166 accuracy: 0.930\n",
      "2017-09-06 08:46:31,675 - INFO - step: 1076,loss: 0.137 accuracy: 0.922\n",
      "2017-09-06 08:46:33,533 - INFO - step: 1077,loss: 0.201 accuracy: 0.922\n",
      "2017-09-06 08:46:35,521 - INFO - step: 1078,loss: 0.164 accuracy: 0.945\n",
      "2017-09-06 08:46:37,480 - INFO - step: 1079,loss: 0.100 accuracy: 0.953\n",
      "2017-09-06 08:46:39,235 - INFO - step: 1080,loss: 0.188 accuracy: 0.923\n",
      "2017-09-06 08:46:39,238 - INFO - \n",
      "train_epoch:53.000\n",
      "2017-09-06 08:46:39,252 - INFO - loss_total: 0.155 accuracy_total: 0.936\n",
      "2017-09-06 08:46:41,241 - INFO - step: 1081,loss: 0.111 accuracy: 0.969\n",
      "2017-09-06 08:46:43,198 - INFO - step: 1082,loss: 0.129 accuracy: 0.938\n",
      "2017-09-06 08:46:45,039 - INFO - step: 1083,loss: 0.182 accuracy: 0.922\n",
      "2017-09-06 08:46:46,987 - INFO - step: 1084,loss: 0.145 accuracy: 0.945\n",
      "2017-09-06 08:46:48,961 - INFO - step: 1085,loss: 0.153 accuracy: 0.938\n",
      "2017-09-06 08:46:50,842 - INFO - step: 1086,loss: 0.111 accuracy: 0.945\n",
      "2017-09-06 08:46:52,834 - INFO - step: 1087,loss: 0.127 accuracy: 0.953\n",
      "2017-09-06 08:46:54,788 - INFO - step: 1088,loss: 0.187 accuracy: 0.914\n",
      "2017-09-06 08:46:56,767 - INFO - step: 1089,loss: 0.149 accuracy: 0.930\n",
      "2017-09-06 08:46:58,762 - INFO - step: 1090,loss: 0.116 accuracy: 0.953\n",
      "2017-09-06 08:47:00,768 - INFO - step: 1091,loss: 0.179 accuracy: 0.922\n",
      "2017-09-06 08:47:02,706 - INFO - step: 1092,loss: 0.113 accuracy: 0.953\n",
      "2017-09-06 08:47:04,676 - INFO - step: 1093,loss: 0.131 accuracy: 0.953\n",
      "2017-09-06 08:47:06,622 - INFO - step: 1094,loss: 0.137 accuracy: 0.945\n",
      "2017-09-06 08:47:08,492 - INFO - step: 1095,loss: 0.162 accuracy: 0.922\n",
      "2017-09-06 08:47:10,492 - INFO - step: 1096,loss: 0.108 accuracy: 0.969\n",
      "2017-09-06 08:47:12,423 - INFO - step: 1097,loss: 0.135 accuracy: 0.945\n",
      "2017-09-06 08:47:14,354 - INFO - step: 1098,loss: 0.164 accuracy: 0.938\n",
      "2017-09-06 08:47:16,344 - INFO - step: 1099,loss: 0.135 accuracy: 0.953\n",
      "2017-09-06 08:47:18,142 - INFO - step: 1100,loss: 0.102 accuracy: 0.969\n",
      "2017-09-06 08:47:18,145 - INFO - \n",
      "train_epoch:54.000\n",
      "2017-09-06 08:47:18,147 - INFO - loss_total: 0.139 accuracy_total: 0.944\n",
      "2017-09-06 08:47:18,149 - INFO - \n",
      "Evaluation:54.000\n",
      "2017-09-06 08:47:19,049 - INFO - step: 1100,loss: 0.262 accuracy: 0.914\n",
      "2017-09-06 08:47:19,052 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:47:20,909 - INFO - step: 1101,loss: 0.133 accuracy: 0.930\n",
      "2017-09-06 08:47:22,907 - INFO - step: 1102,loss: 0.120 accuracy: 0.945\n",
      "2017-09-06 08:47:24,863 - INFO - step: 1103,loss: 0.125 accuracy: 0.938\n",
      "2017-09-06 08:47:26,789 - INFO - step: 1104,loss: 0.121 accuracy: 0.945\n",
      "2017-09-06 08:47:28,752 - INFO - step: 1105,loss: 0.125 accuracy: 0.953\n",
      "2017-09-06 08:47:30,719 - INFO - step: 1106,loss: 0.180 accuracy: 0.930\n",
      "2017-09-06 08:47:32,653 - INFO - step: 1107,loss: 0.157 accuracy: 0.961\n",
      "2017-09-06 08:47:34,628 - INFO - step: 1108,loss: 0.153 accuracy: 0.930\n",
      "2017-09-06 08:47:36,593 - INFO - step: 1109,loss: 0.093 accuracy: 0.961\n",
      "2017-09-06 08:47:38,447 - INFO - step: 1110,loss: 0.193 accuracy: 0.953\n",
      "2017-09-06 08:47:40,396 - INFO - step: 1111,loss: 0.141 accuracy: 0.938\n",
      "2017-09-06 08:47:42,377 - INFO - step: 1112,loss: 0.203 accuracy: 0.906\n",
      "2017-09-06 08:47:44,325 - INFO - step: 1113,loss: 0.155 accuracy: 0.930\n",
      "2017-09-06 08:47:46,321 - INFO - step: 1114,loss: 0.167 accuracy: 0.938\n",
      "2017-09-06 08:47:48,281 - INFO - step: 1115,loss: 0.123 accuracy: 0.953\n",
      "2017-09-06 08:47:50,230 - INFO - step: 1116,loss: 0.130 accuracy: 0.953\n",
      "2017-09-06 08:47:52,175 - INFO - step: 1117,loss: 0.216 accuracy: 0.906\n",
      "2017-09-06 08:47:54,155 - INFO - step: 1118,loss: 0.136 accuracy: 0.961\n",
      "2017-09-06 08:47:56,059 - INFO - step: 1119,loss: 0.146 accuracy: 0.938\n",
      "2017-09-06 08:47:57,868 - INFO - step: 1120,loss: 0.099 accuracy: 0.985\n",
      "2017-09-06 08:47:57,871 - INFO - \n",
      "train_epoch:55.000\n",
      "2017-09-06 08:47:57,873 - INFO - loss_total: 0.146 accuracy_total: 0.943\n",
      "2017-09-06 08:47:59,826 - INFO - step: 1121,loss: 0.148 accuracy: 0.930\n",
      "2017-09-06 08:48:01,753 - INFO - step: 1122,loss: 0.179 accuracy: 0.930\n",
      "2017-09-06 08:48:03,778 - INFO - step: 1123,loss: 0.142 accuracy: 0.961\n",
      "2017-09-06 08:48:05,800 - INFO - step: 1124,loss: 0.136 accuracy: 0.945\n",
      "2017-09-06 08:48:07,738 - INFO - step: 1125,loss: 0.140 accuracy: 0.961\n",
      "2017-09-06 08:48:09,727 - INFO - step: 1126,loss: 0.206 accuracy: 0.891\n",
      "2017-09-06 08:48:11,700 - INFO - step: 1127,loss: 0.154 accuracy: 0.938\n",
      "2017-09-06 08:48:13,668 - INFO - step: 1128,loss: 0.179 accuracy: 0.922\n",
      "2017-09-06 08:48:15,642 - INFO - step: 1129,loss: 0.101 accuracy: 0.984\n",
      "2017-09-06 08:48:17,598 - INFO - step: 1130,loss: 0.175 accuracy: 0.914\n",
      "2017-09-06 08:48:19,527 - INFO - step: 1131,loss: 0.081 accuracy: 0.977\n",
      "2017-09-06 08:48:21,470 - INFO - step: 1132,loss: 0.161 accuracy: 0.938\n",
      "2017-09-06 08:48:23,460 - INFO - step: 1133,loss: 0.137 accuracy: 0.961\n",
      "2017-09-06 08:48:25,067 - INFO - step: 1134,loss: 0.132 accuracy: 0.953\n",
      "2017-09-06 08:48:27,004 - INFO - step: 1135,loss: 0.140 accuracy: 0.930\n",
      "2017-09-06 08:48:29,005 - INFO - step: 1136,loss: 0.141 accuracy: 0.938\n",
      "2017-09-06 08:48:30,939 - INFO - step: 1137,loss: 0.148 accuracy: 0.930\n",
      "2017-09-06 08:48:32,918 - INFO - step: 1138,loss: 0.161 accuracy: 0.930\n",
      "2017-09-06 08:48:34,869 - INFO - step: 1139,loss: 0.127 accuracy: 0.961\n",
      "2017-09-06 08:48:36,702 - INFO - step: 1140,loss: 0.164 accuracy: 0.938\n",
      "2017-09-06 08:48:36,707 - INFO - \n",
      "train_epoch:56.000\n",
      "2017-09-06 08:48:36,711 - INFO - loss_total: 0.148 accuracy_total: 0.941\n",
      "2017-09-06 08:48:36,715 - INFO - \n",
      "Evaluation:56.000\n",
      "2017-09-06 08:48:37,280 - INFO - step: 1140,loss: 0.284 accuracy: 0.903\n",
      "2017-09-06 08:48:37,281 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:48:39,279 - INFO - step: 1141,loss: 0.165 accuracy: 0.930\n",
      "2017-09-06 08:48:41,309 - INFO - step: 1142,loss: 0.185 accuracy: 0.930\n",
      "2017-09-06 08:48:43,324 - INFO - step: 1143,loss: 0.138 accuracy: 0.922\n",
      "2017-09-06 08:48:45,304 - INFO - step: 1144,loss: 0.104 accuracy: 0.977\n",
      "2017-09-06 08:48:47,273 - INFO - step: 1145,loss: 0.090 accuracy: 0.969\n",
      "2017-09-06 08:48:49,146 - INFO - step: 1146,loss: 0.142 accuracy: 0.938\n",
      "2017-09-06 08:48:51,088 - INFO - step: 1147,loss: 0.096 accuracy: 0.977\n",
      "2017-09-06 08:48:53,052 - INFO - step: 1148,loss: 0.106 accuracy: 0.953\n",
      "2017-09-06 08:48:54,994 - INFO - step: 1149,loss: 0.178 accuracy: 0.922\n",
      "2017-09-06 08:48:56,959 - INFO - step: 1150,loss: 0.156 accuracy: 0.938\n",
      "2017-09-06 08:48:58,461 - INFO - step: 1151,loss: 0.175 accuracy: 0.914\n",
      "2017-09-06 08:48:59,671 - INFO - step: 1152,loss: 0.098 accuracy: 0.969\n",
      "2017-09-06 08:49:00,900 - INFO - step: 1153,loss: 0.135 accuracy: 0.945\n",
      "2017-09-06 08:49:02,114 - INFO - step: 1154,loss: 0.143 accuracy: 0.930\n",
      "2017-09-06 08:49:03,358 - INFO - step: 1155,loss: 0.107 accuracy: 0.969\n",
      "2017-09-06 08:49:04,581 - INFO - step: 1156,loss: 0.158 accuracy: 0.930\n",
      "2017-09-06 08:49:05,797 - INFO - step: 1157,loss: 0.220 accuracy: 0.914\n",
      "2017-09-06 08:49:07,051 - INFO - step: 1158,loss: 0.084 accuracy: 0.977\n",
      "2017-09-06 08:49:08,266 - INFO - step: 1159,loss: 0.149 accuracy: 0.938\n",
      "2017-09-06 08:49:09,364 - INFO - step: 1160,loss: 0.127 accuracy: 0.969\n",
      "2017-09-06 08:49:09,367 - INFO - \n",
      "train_epoch:57.000\n",
      "2017-09-06 08:49:09,369 - INFO - loss_total: 0.138 accuracy_total: 0.945\n",
      "2017-09-06 08:49:10,652 - INFO - step: 1161,loss: 0.132 accuracy: 0.953\n",
      "2017-09-06 08:49:11,859 - INFO - step: 1162,loss: 0.148 accuracy: 0.945\n",
      "2017-09-06 08:49:13,080 - INFO - step: 1163,loss: 0.172 accuracy: 0.930\n",
      "2017-09-06 08:49:14,293 - INFO - step: 1164,loss: 0.159 accuracy: 0.938\n",
      "2017-09-06 08:49:15,588 - INFO - step: 1165,loss: 0.188 accuracy: 0.930\n",
      "2017-09-06 08:49:16,849 - INFO - step: 1166,loss: 0.127 accuracy: 0.961\n",
      "2017-09-06 08:49:18,081 - INFO - step: 1167,loss: 0.134 accuracy: 0.922\n",
      "2017-09-06 08:49:19,321 - INFO - step: 1168,loss: 0.131 accuracy: 0.938\n",
      "2017-09-06 08:49:20,577 - INFO - step: 1169,loss: 0.179 accuracy: 0.930\n",
      "2017-09-06 08:49:21,792 - INFO - step: 1170,loss: 0.098 accuracy: 0.953\n",
      "2017-09-06 08:49:23,048 - INFO - step: 1171,loss: 0.166 accuracy: 0.922\n",
      "2017-09-06 08:49:24,272 - INFO - step: 1172,loss: 0.200 accuracy: 0.922\n",
      "2017-09-06 08:49:25,520 - INFO - step: 1173,loss: 0.106 accuracy: 0.953\n",
      "2017-09-06 08:49:26,731 - INFO - step: 1174,loss: 0.195 accuracy: 0.938\n",
      "2017-09-06 08:49:27,957 - INFO - step: 1175,loss: 0.142 accuracy: 0.938\n",
      "2017-09-06 08:49:29,185 - INFO - step: 1176,loss: 0.137 accuracy: 0.945\n",
      "2017-09-06 08:49:30,412 - INFO - step: 1177,loss: 0.155 accuracy: 0.945\n",
      "2017-09-06 08:49:31,650 - INFO - step: 1178,loss: 0.101 accuracy: 0.969\n",
      "2017-09-06 08:49:32,905 - INFO - step: 1179,loss: 0.202 accuracy: 0.914\n",
      "2017-09-06 08:49:34,019 - INFO - step: 1180,loss: 0.142 accuracy: 0.923\n",
      "2017-09-06 08:49:34,022 - INFO - \n",
      "train_epoch:58.000\n",
      "2017-09-06 08:49:34,024 - INFO - loss_total: 0.151 accuracy_total: 0.938\n",
      "2017-09-06 08:49:34,025 - INFO - \n",
      "Evaluation:58.000\n",
      "2017-09-06 08:49:34,569 - INFO - step: 1180,loss: 0.299 accuracy: 0.903\n",
      "2017-09-06 08:49:34,570 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:49:35,798 - INFO - step: 1181,loss: 0.209 accuracy: 0.906\n",
      "2017-09-06 08:49:37,032 - INFO - step: 1182,loss: 0.131 accuracy: 0.930\n",
      "2017-09-06 08:49:38,250 - INFO - step: 1183,loss: 0.153 accuracy: 0.922\n",
      "2017-09-06 08:49:39,469 - INFO - step: 1184,loss: 0.130 accuracy: 0.969\n",
      "2017-09-06 08:49:40,693 - INFO - step: 1185,loss: 0.170 accuracy: 0.930\n",
      "2017-09-06 08:49:41,953 - INFO - step: 1186,loss: 0.124 accuracy: 0.953\n",
      "2017-09-06 08:49:43,206 - INFO - step: 1187,loss: 0.130 accuracy: 0.953\n",
      "2017-09-06 08:49:44,430 - INFO - step: 1188,loss: 0.151 accuracy: 0.945\n",
      "2017-09-06 08:49:45,652 - INFO - step: 1189,loss: 0.135 accuracy: 0.938\n",
      "2017-09-06 08:49:46,877 - INFO - step: 1190,loss: 0.209 accuracy: 0.906\n",
      "2017-09-06 08:49:48,089 - INFO - step: 1191,loss: 0.137 accuracy: 0.953\n",
      "2017-09-06 08:49:49,320 - INFO - step: 1192,loss: 0.085 accuracy: 0.977\n",
      "2017-09-06 08:49:50,558 - INFO - step: 1193,loss: 0.114 accuracy: 0.969\n",
      "2017-09-06 08:49:51,771 - INFO - step: 1194,loss: 0.119 accuracy: 0.961\n",
      "2017-09-06 08:49:53,003 - INFO - step: 1195,loss: 0.159 accuracy: 0.922\n",
      "2017-09-06 08:49:54,239 - INFO - step: 1196,loss: 0.163 accuracy: 0.922\n",
      "2017-09-06 08:49:55,451 - INFO - step: 1197,loss: 0.143 accuracy: 0.930\n",
      "2017-09-06 08:49:56,677 - INFO - step: 1198,loss: 0.155 accuracy: 0.938\n",
      "2017-09-06 08:49:57,905 - INFO - step: 1199,loss: 0.142 accuracy: 0.945\n",
      "2017-09-06 08:49:59,032 - INFO - step: 1200,loss: 0.156 accuracy: 0.954\n",
      "2017-09-06 08:49:59,035 - INFO - \n",
      "train_epoch:59.000\n",
      "2017-09-06 08:49:59,037 - INFO - loss_total: 0.146 accuracy_total: 0.941\n",
      "2017-09-06 08:50:00,290 - INFO - step: 1201,loss: 0.127 accuracy: 0.945\n",
      "2017-09-06 08:50:01,524 - INFO - step: 1202,loss: 0.182 accuracy: 0.930\n",
      "2017-09-06 08:50:02,753 - INFO - step: 1203,loss: 0.114 accuracy: 0.961\n",
      "2017-09-06 08:50:03,975 - INFO - step: 1204,loss: 0.157 accuracy: 0.930\n",
      "2017-09-06 08:50:05,193 - INFO - step: 1205,loss: 0.164 accuracy: 0.945\n",
      "2017-09-06 08:50:06,394 - INFO - step: 1206,loss: 0.122 accuracy: 0.953\n",
      "2017-09-06 08:50:07,623 - INFO - step: 1207,loss: 0.179 accuracy: 0.930\n",
      "2017-09-06 08:50:08,859 - INFO - step: 1208,loss: 0.114 accuracy: 0.969\n",
      "2017-09-06 08:50:10,087 - INFO - step: 1209,loss: 0.143 accuracy: 0.945\n",
      "2017-09-06 08:50:11,278 - INFO - step: 1210,loss: 0.132 accuracy: 0.945\n",
      "2017-09-06 08:50:12,541 - INFO - step: 1211,loss: 0.154 accuracy: 0.938\n",
      "2017-09-06 08:50:13,763 - INFO - step: 1212,loss: 0.151 accuracy: 0.961\n",
      "2017-09-06 08:50:14,977 - INFO - step: 1213,loss: 0.164 accuracy: 0.922\n",
      "2017-09-06 08:50:16,187 - INFO - step: 1214,loss: 0.120 accuracy: 0.945\n",
      "2017-09-06 08:50:17,419 - INFO - step: 1215,loss: 0.100 accuracy: 0.969\n",
      "2017-09-06 08:50:18,585 - INFO - step: 1216,loss: 0.120 accuracy: 0.953\n",
      "2017-09-06 08:50:19,767 - INFO - step: 1217,loss: 0.116 accuracy: 0.953\n",
      "2017-09-06 08:50:20,932 - INFO - step: 1218,loss: 0.194 accuracy: 0.898\n",
      "2017-09-06 08:50:22,153 - INFO - step: 1219,loss: 0.153 accuracy: 0.945\n",
      "2017-09-06 08:50:23,261 - INFO - step: 1220,loss: 0.116 accuracy: 0.954\n",
      "2017-09-06 08:50:23,263 - INFO - \n",
      "train_epoch:60.000\n",
      "2017-09-06 08:50:23,265 - INFO - loss_total: 0.141 accuracy_total: 0.945\n",
      "2017-09-06 08:50:23,267 - INFO - \n",
      "Evaluation:60.000\n",
      "2017-09-06 08:50:23,811 - INFO - step: 1220,loss: 0.268 accuracy: 0.910\n",
      "2017-09-06 08:50:23,812 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:50:25,054 - INFO - step: 1221,loss: 0.085 accuracy: 0.984\n",
      "2017-09-06 08:50:26,263 - INFO - step: 1222,loss: 0.131 accuracy: 0.938\n",
      "2017-09-06 08:50:27,492 - INFO - step: 1223,loss: 0.104 accuracy: 0.969\n",
      "2017-09-06 08:50:28,729 - INFO - step: 1224,loss: 0.100 accuracy: 0.969\n",
      "2017-09-06 08:50:30,052 - INFO - step: 1225,loss: 0.146 accuracy: 0.938\n",
      "2017-09-06 08:50:31,270 - INFO - step: 1226,loss: 0.119 accuracy: 0.961\n",
      "2017-09-06 08:50:32,468 - INFO - step: 1227,loss: 0.157 accuracy: 0.930\n",
      "2017-09-06 08:50:33,748 - INFO - step: 1228,loss: 0.154 accuracy: 0.914\n",
      "2017-09-06 08:50:35,024 - INFO - step: 1229,loss: 0.140 accuracy: 0.930\n",
      "2017-09-06 08:50:36,252 - INFO - step: 1230,loss: 0.137 accuracy: 0.922\n",
      "2017-09-06 08:50:37,463 - INFO - step: 1231,loss: 0.150 accuracy: 0.938\n",
      "2017-09-06 08:50:38,659 - INFO - step: 1232,loss: 0.107 accuracy: 0.945\n",
      "2017-09-06 08:50:39,858 - INFO - step: 1233,loss: 0.177 accuracy: 0.914\n",
      "2017-09-06 08:50:41,096 - INFO - step: 1234,loss: 0.136 accuracy: 0.930\n",
      "2017-09-06 08:50:42,329 - INFO - step: 1235,loss: 0.115 accuracy: 0.953\n",
      "2017-09-06 08:50:43,531 - INFO - step: 1236,loss: 0.158 accuracy: 0.953\n",
      "2017-09-06 08:50:44,753 - INFO - step: 1237,loss: 0.120 accuracy: 0.953\n",
      "2017-09-06 08:50:45,980 - INFO - step: 1238,loss: 0.134 accuracy: 0.938\n",
      "2017-09-06 08:50:47,182 - INFO - step: 1239,loss: 0.130 accuracy: 0.938\n",
      "2017-09-06 08:50:48,309 - INFO - step: 1240,loss: 0.119 accuracy: 0.954\n",
      "2017-09-06 08:50:48,312 - INFO - \n",
      "train_epoch:61.000\n",
      "2017-09-06 08:50:48,314 - INFO - loss_total: 0.131 accuracy_total: 0.943\n",
      "2017-09-06 08:50:49,596 - INFO - step: 1241,loss: 0.119 accuracy: 0.945\n",
      "2017-09-06 08:50:50,814 - INFO - step: 1242,loss: 0.171 accuracy: 0.945\n",
      "2017-09-06 08:50:52,112 - INFO - step: 1243,loss: 0.105 accuracy: 0.961\n",
      "2017-09-06 08:50:53,319 - INFO - step: 1244,loss: 0.111 accuracy: 0.961\n",
      "2017-09-06 08:50:54,543 - INFO - step: 1245,loss: 0.112 accuracy: 0.945\n",
      "2017-09-06 08:50:55,747 - INFO - step: 1246,loss: 0.194 accuracy: 0.906\n",
      "2017-09-06 08:50:56,966 - INFO - step: 1247,loss: 0.122 accuracy: 0.953\n",
      "2017-09-06 08:50:58,233 - INFO - step: 1248,loss: 0.092 accuracy: 0.977\n",
      "2017-09-06 08:50:59,511 - INFO - step: 1249,loss: 0.145 accuracy: 0.938\n",
      "2017-09-06 08:51:00,731 - INFO - step: 1250,loss: 0.114 accuracy: 0.953\n",
      "2017-09-06 08:51:01,955 - INFO - step: 1251,loss: 0.127 accuracy: 0.953\n",
      "2017-09-06 08:51:03,168 - INFO - step: 1252,loss: 0.170 accuracy: 0.914\n",
      "2017-09-06 08:51:04,386 - INFO - step: 1253,loss: 0.197 accuracy: 0.914\n",
      "2017-09-06 08:51:05,636 - INFO - step: 1254,loss: 0.150 accuracy: 0.938\n",
      "2017-09-06 08:51:06,830 - INFO - step: 1255,loss: 0.156 accuracy: 0.930\n",
      "2017-09-06 08:51:08,073 - INFO - step: 1256,loss: 0.179 accuracy: 0.922\n",
      "2017-09-06 08:51:09,297 - INFO - step: 1257,loss: 0.208 accuracy: 0.922\n",
      "2017-09-06 08:51:10,534 - INFO - step: 1258,loss: 0.114 accuracy: 0.953\n",
      "2017-09-06 08:51:11,774 - INFO - step: 1259,loss: 0.157 accuracy: 0.914\n",
      "2017-09-06 08:51:12,896 - INFO - step: 1260,loss: 0.149 accuracy: 0.938\n",
      "2017-09-06 08:51:12,898 - INFO - \n",
      "train_epoch:62.000\n",
      "2017-09-06 08:51:12,900 - INFO - loss_total: 0.145 accuracy_total: 0.939\n",
      "2017-09-06 08:51:12,901 - INFO - \n",
      "Evaluation:62.000\n",
      "2017-09-06 08:51:13,445 - INFO - step: 1260,loss: 0.245 accuracy: 0.914\n",
      "2017-09-06 08:51:13,446 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:51:14,743 - INFO - step: 1261,loss: 0.135 accuracy: 0.945\n",
      "2017-09-06 08:51:15,915 - INFO - step: 1262,loss: 0.164 accuracy: 0.922\n",
      "2017-09-06 08:51:17,170 - INFO - step: 1263,loss: 0.142 accuracy: 0.938\n",
      "2017-09-06 08:51:18,405 - INFO - step: 1264,loss: 0.191 accuracy: 0.898\n",
      "2017-09-06 08:51:19,659 - INFO - step: 1265,loss: 0.121 accuracy: 0.953\n",
      "2017-09-06 08:51:20,940 - INFO - step: 1266,loss: 0.137 accuracy: 0.953\n",
      "2017-09-06 08:51:22,193 - INFO - step: 1267,loss: 0.155 accuracy: 0.945\n",
      "2017-09-06 08:51:23,410 - INFO - step: 1268,loss: 0.137 accuracy: 0.945\n",
      "2017-09-06 08:51:24,616 - INFO - step: 1269,loss: 0.128 accuracy: 0.953\n",
      "2017-09-06 08:51:25,897 - INFO - step: 1270,loss: 0.188 accuracy: 0.914\n",
      "2017-09-06 08:51:27,105 - INFO - step: 1271,loss: 0.139 accuracy: 0.938\n",
      "2017-09-06 08:51:28,316 - INFO - step: 1272,loss: 0.148 accuracy: 0.914\n",
      "2017-09-06 08:51:29,553 - INFO - step: 1273,loss: 0.133 accuracy: 0.930\n",
      "2017-09-06 08:51:30,781 - INFO - step: 1274,loss: 0.140 accuracy: 0.922\n",
      "2017-09-06 08:51:31,999 - INFO - step: 1275,loss: 0.165 accuracy: 0.906\n",
      "2017-09-06 08:51:33,214 - INFO - step: 1276,loss: 0.140 accuracy: 0.938\n",
      "2017-09-06 08:51:34,475 - INFO - step: 1277,loss: 0.151 accuracy: 0.930\n",
      "2017-09-06 08:51:35,712 - INFO - step: 1278,loss: 0.080 accuracy: 0.977\n",
      "2017-09-06 08:51:36,943 - INFO - step: 1279,loss: 0.133 accuracy: 0.969\n",
      "2017-09-06 08:51:38,052 - INFO - step: 1280,loss: 0.113 accuracy: 0.969\n",
      "2017-09-06 08:51:38,056 - INFO - \n",
      "train_epoch:63.000\n",
      "2017-09-06 08:51:38,058 - INFO - loss_total: 0.142 accuracy_total: 0.938\n",
      "2017-09-06 08:51:39,281 - INFO - step: 1281,loss: 0.143 accuracy: 0.914\n",
      "2017-09-06 08:51:40,508 - INFO - step: 1282,loss: 0.122 accuracy: 0.945\n",
      "2017-09-06 08:51:41,748 - INFO - step: 1283,loss: 0.139 accuracy: 0.938\n",
      "2017-09-06 08:51:42,958 - INFO - step: 1284,loss: 0.093 accuracy: 0.984\n",
      "2017-09-06 08:51:44,147 - INFO - step: 1285,loss: 0.149 accuracy: 0.938\n",
      "2017-09-06 08:51:45,399 - INFO - step: 1286,loss: 0.087 accuracy: 0.984\n",
      "2017-09-06 08:51:46,626 - INFO - step: 1287,loss: 0.144 accuracy: 0.930\n",
      "2017-09-06 08:51:47,842 - INFO - step: 1288,loss: 0.159 accuracy: 0.922\n",
      "2017-09-06 08:51:49,010 - INFO - step: 1289,loss: 0.156 accuracy: 0.914\n",
      "2017-09-06 08:51:50,230 - INFO - step: 1290,loss: 0.184 accuracy: 0.922\n",
      "2017-09-06 08:51:51,436 - INFO - step: 1291,loss: 0.181 accuracy: 0.930\n",
      "2017-09-06 08:51:52,645 - INFO - step: 1292,loss: 0.131 accuracy: 0.930\n",
      "2017-09-06 08:51:53,890 - INFO - step: 1293,loss: 0.126 accuracy: 0.945\n",
      "2017-09-06 08:51:55,111 - INFO - step: 1294,loss: 0.119 accuracy: 0.953\n",
      "2017-09-06 08:51:56,301 - INFO - step: 1295,loss: 0.157 accuracy: 0.930\n",
      "2017-09-06 08:51:57,526 - INFO - step: 1296,loss: 0.097 accuracy: 0.969\n",
      "2017-09-06 08:51:58,745 - INFO - step: 1297,loss: 0.173 accuracy: 0.922\n",
      "2017-09-06 08:51:59,964 - INFO - step: 1298,loss: 0.148 accuracy: 0.961\n",
      "2017-09-06 08:52:01,176 - INFO - step: 1299,loss: 0.108 accuracy: 0.961\n",
      "2017-09-06 08:52:02,285 - INFO - step: 1300,loss: 0.122 accuracy: 0.954\n",
      "2017-09-06 08:52:02,288 - INFO - \n",
      "train_epoch:64.000\n",
      "2017-09-06 08:52:02,290 - INFO - loss_total: 0.137 accuracy_total: 0.942\n",
      "2017-09-06 08:52:02,292 - INFO - \n",
      "Evaluation:64.000\n",
      "2017-09-06 08:52:02,836 - INFO - step: 1300,loss: 0.278 accuracy: 0.899\n",
      "2017-09-06 08:52:02,838 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:52:04,079 - INFO - step: 1301,loss: 0.094 accuracy: 0.953\n",
      "2017-09-06 08:52:05,302 - INFO - step: 1302,loss: 0.137 accuracy: 0.930\n",
      "2017-09-06 08:52:06,483 - INFO - step: 1303,loss: 0.140 accuracy: 0.945\n",
      "2017-09-06 08:52:07,697 - INFO - step: 1304,loss: 0.099 accuracy: 0.969\n",
      "2017-09-06 08:52:08,924 - INFO - step: 1305,loss: 0.155 accuracy: 0.930\n",
      "2017-09-06 08:52:10,165 - INFO - step: 1306,loss: 0.130 accuracy: 0.945\n",
      "2017-09-06 08:52:11,416 - INFO - step: 1307,loss: 0.064 accuracy: 0.984\n",
      "2017-09-06 08:52:12,690 - INFO - step: 1308,loss: 0.170 accuracy: 0.930\n",
      "2017-09-06 08:52:13,921 - INFO - step: 1309,loss: 0.170 accuracy: 0.906\n",
      "2017-09-06 08:52:15,150 - INFO - step: 1310,loss: 0.210 accuracy: 0.891\n",
      "2017-09-06 08:52:16,386 - INFO - step: 1311,loss: 0.130 accuracy: 0.961\n",
      "2017-09-06 08:52:17,616 - INFO - step: 1312,loss: 0.135 accuracy: 0.945\n",
      "2017-09-06 08:52:18,852 - INFO - step: 1313,loss: 0.156 accuracy: 0.930\n",
      "2017-09-06 08:52:20,056 - INFO - step: 1314,loss: 0.112 accuracy: 0.977\n",
      "2017-09-06 08:52:21,310 - INFO - step: 1315,loss: 0.125 accuracy: 0.953\n",
      "2017-09-06 08:52:22,599 - INFO - step: 1316,loss: 0.061 accuracy: 0.992\n",
      "2017-09-06 08:52:23,844 - INFO - step: 1317,loss: 0.177 accuracy: 0.914\n",
      "2017-09-06 08:52:25,083 - INFO - step: 1318,loss: 0.155 accuracy: 0.930\n",
      "2017-09-06 08:52:26,313 - INFO - step: 1319,loss: 0.133 accuracy: 0.930\n",
      "2017-09-06 08:52:27,414 - INFO - step: 1320,loss: 0.190 accuracy: 0.923\n",
      "2017-09-06 08:52:27,417 - INFO - \n",
      "train_epoch:65.000\n",
      "2017-09-06 08:52:27,419 - INFO - loss_total: 0.137 accuracy_total: 0.942\n",
      "2017-09-06 08:52:28,697 - INFO - step: 1321,loss: 0.100 accuracy: 0.977\n",
      "2017-09-06 08:52:29,991 - INFO - step: 1322,loss: 0.098 accuracy: 0.969\n",
      "2017-09-06 08:52:31,211 - INFO - step: 1323,loss: 0.159 accuracy: 0.930\n",
      "2017-09-06 08:52:32,410 - INFO - step: 1324,loss: 0.111 accuracy: 0.938\n",
      "2017-09-06 08:52:33,642 - INFO - step: 1325,loss: 0.129 accuracy: 0.945\n",
      "2017-09-06 08:52:34,930 - INFO - step: 1326,loss: 0.167 accuracy: 0.922\n",
      "2017-09-06 08:52:36,154 - INFO - step: 1327,loss: 0.131 accuracy: 0.922\n",
      "2017-09-06 08:52:37,388 - INFO - step: 1328,loss: 0.151 accuracy: 0.930\n",
      "2017-09-06 08:52:38,631 - INFO - step: 1329,loss: 0.151 accuracy: 0.922\n",
      "2017-09-06 08:52:39,836 - INFO - step: 1330,loss: 0.142 accuracy: 0.938\n",
      "2017-09-06 08:52:41,054 - INFO - step: 1331,loss: 0.112 accuracy: 0.945\n",
      "2017-09-06 08:52:42,276 - INFO - step: 1332,loss: 0.166 accuracy: 0.914\n",
      "2017-09-06 08:52:43,503 - INFO - step: 1333,loss: 0.142 accuracy: 0.953\n",
      "2017-09-06 08:52:44,714 - INFO - step: 1334,loss: 0.109 accuracy: 0.977\n",
      "2017-09-06 08:52:45,917 - INFO - step: 1335,loss: 0.119 accuracy: 0.938\n",
      "2017-09-06 08:52:47,144 - INFO - step: 1336,loss: 0.145 accuracy: 0.930\n",
      "2017-09-06 08:52:48,352 - INFO - step: 1337,loss: 0.146 accuracy: 0.945\n",
      "2017-09-06 08:52:49,582 - INFO - step: 1338,loss: 0.087 accuracy: 0.977\n",
      "2017-09-06 08:52:50,785 - INFO - step: 1339,loss: 0.125 accuracy: 0.961\n",
      "2017-09-06 08:52:51,888 - INFO - step: 1340,loss: 0.116 accuracy: 0.938\n",
      "2017-09-06 08:52:51,890 - INFO - \n",
      "train_epoch:66.000\n",
      "2017-09-06 08:52:51,892 - INFO - loss_total: 0.130 accuracy_total: 0.943\n",
      "2017-09-06 08:52:51,893 - INFO - \n",
      "Evaluation:66.000\n",
      "2017-09-06 08:52:52,436 - INFO - step: 1340,loss: 0.263 accuracy: 0.914\n",
      "2017-09-06 08:52:52,437 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:52:53,656 - INFO - step: 1341,loss: 0.106 accuracy: 0.977\n",
      "2017-09-06 08:52:54,844 - INFO - step: 1342,loss: 0.162 accuracy: 0.906\n",
      "2017-09-06 08:52:56,085 - INFO - step: 1343,loss: 0.131 accuracy: 0.945\n",
      "2017-09-06 08:52:57,342 - INFO - step: 1344,loss: 0.102 accuracy: 0.953\n",
      "2017-09-06 08:52:58,547 - INFO - step: 1345,loss: 0.158 accuracy: 0.914\n",
      "2017-09-06 08:52:59,760 - INFO - step: 1346,loss: 0.161 accuracy: 0.922\n",
      "2017-09-06 08:53:00,985 - INFO - step: 1347,loss: 0.176 accuracy: 0.938\n",
      "2017-09-06 08:53:02,223 - INFO - step: 1348,loss: 0.141 accuracy: 0.930\n",
      "2017-09-06 08:53:03,456 - INFO - step: 1349,loss: 0.114 accuracy: 0.961\n",
      "2017-09-06 08:53:04,678 - INFO - step: 1350,loss: 0.206 accuracy: 0.930\n",
      "2017-09-06 08:53:05,901 - INFO - step: 1351,loss: 0.138 accuracy: 0.953\n",
      "2017-09-06 08:53:07,122 - INFO - step: 1352,loss: 0.118 accuracy: 0.961\n",
      "2017-09-06 08:53:08,341 - INFO - step: 1353,loss: 0.143 accuracy: 0.938\n",
      "2017-09-06 08:53:09,565 - INFO - step: 1354,loss: 0.113 accuracy: 0.961\n",
      "2017-09-06 08:53:10,795 - INFO - step: 1355,loss: 0.133 accuracy: 0.945\n",
      "2017-09-06 08:53:12,002 - INFO - step: 1356,loss: 0.119 accuracy: 0.945\n",
      "2017-09-06 08:53:13,180 - INFO - step: 1357,loss: 0.133 accuracy: 0.953\n",
      "2017-09-06 08:53:14,390 - INFO - step: 1358,loss: 0.128 accuracy: 0.938\n",
      "2017-09-06 08:53:15,605 - INFO - step: 1359,loss: 0.111 accuracy: 0.953\n",
      "2017-09-06 08:53:16,719 - INFO - step: 1360,loss: 0.220 accuracy: 0.923\n",
      "2017-09-06 08:53:16,722 - INFO - \n",
      "train_epoch:67.000\n",
      "2017-09-06 08:53:16,725 - INFO - loss_total: 0.141 accuracy_total: 0.942\n",
      "2017-09-06 08:53:17,953 - INFO - step: 1361,loss: 0.160 accuracy: 0.930\n",
      "2017-09-06 08:53:19,161 - INFO - step: 1362,loss: 0.151 accuracy: 0.938\n",
      "2017-09-06 08:53:20,381 - INFO - step: 1363,loss: 0.169 accuracy: 0.922\n",
      "2017-09-06 08:53:21,613 - INFO - step: 1364,loss: 0.132 accuracy: 0.938\n",
      "2017-09-06 08:53:22,857 - INFO - step: 1365,loss: 0.150 accuracy: 0.953\n",
      "2017-09-06 08:53:24,053 - INFO - step: 1366,loss: 0.127 accuracy: 0.938\n",
      "2017-09-06 08:53:25,282 - INFO - step: 1367,loss: 0.108 accuracy: 0.969\n",
      "2017-09-06 08:53:26,495 - INFO - step: 1368,loss: 0.116 accuracy: 0.953\n",
      "2017-09-06 08:53:27,717 - INFO - step: 1369,loss: 0.110 accuracy: 0.953\n",
      "2017-09-06 08:53:28,962 - INFO - step: 1370,loss: 0.148 accuracy: 0.945\n",
      "2017-09-06 08:53:30,172 - INFO - step: 1371,loss: 0.122 accuracy: 0.969\n",
      "2017-09-06 08:53:31,390 - INFO - step: 1372,loss: 0.095 accuracy: 0.961\n",
      "2017-09-06 08:53:32,612 - INFO - step: 1373,loss: 0.118 accuracy: 0.945\n",
      "2017-09-06 08:53:33,857 - INFO - step: 1374,loss: 0.082 accuracy: 0.977\n",
      "2017-09-06 08:53:35,087 - INFO - step: 1375,loss: 0.125 accuracy: 0.938\n",
      "2017-09-06 08:53:36,308 - INFO - step: 1376,loss: 0.108 accuracy: 0.961\n",
      "2017-09-06 08:53:37,535 - INFO - step: 1377,loss: 0.118 accuracy: 0.930\n",
      "2017-09-06 08:53:38,771 - INFO - step: 1378,loss: 0.106 accuracy: 0.953\n",
      "2017-09-06 08:53:39,990 - INFO - step: 1379,loss: 0.251 accuracy: 0.883\n",
      "2017-09-06 08:53:41,099 - INFO - step: 1380,loss: 0.150 accuracy: 0.923\n",
      "2017-09-06 08:53:41,102 - INFO - \n",
      "train_epoch:68.000\n",
      "2017-09-06 08:53:41,104 - INFO - loss_total: 0.132 accuracy_total: 0.944\n",
      "2017-09-06 08:53:41,106 - INFO - \n",
      "Evaluation:68.000\n",
      "2017-09-06 08:53:41,661 - INFO - step: 1380,loss: 0.279 accuracy: 0.903\n",
      "2017-09-06 08:53:41,662 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:53:42,891 - INFO - step: 1381,loss: 0.144 accuracy: 0.938\n",
      "2017-09-06 08:53:44,127 - INFO - step: 1382,loss: 0.127 accuracy: 0.953\n",
      "2017-09-06 08:53:45,377 - INFO - step: 1383,loss: 0.116 accuracy: 0.953\n",
      "2017-09-06 08:53:46,596 - INFO - step: 1384,loss: 0.116 accuracy: 0.953\n",
      "2017-09-06 08:53:47,810 - INFO - step: 1385,loss: 0.106 accuracy: 0.961\n",
      "2017-09-06 08:53:49,049 - INFO - step: 1386,loss: 0.155 accuracy: 0.945\n",
      "2017-09-06 08:53:50,289 - INFO - step: 1387,loss: 0.154 accuracy: 0.930\n",
      "2017-09-06 08:53:51,468 - INFO - step: 1388,loss: 0.086 accuracy: 0.969\n",
      "2017-09-06 08:53:52,705 - INFO - step: 1389,loss: 0.142 accuracy: 0.938\n",
      "2017-09-06 08:53:53,945 - INFO - step: 1390,loss: 0.106 accuracy: 0.969\n",
      "2017-09-06 08:53:55,208 - INFO - step: 1391,loss: 0.135 accuracy: 0.961\n",
      "2017-09-06 08:53:56,467 - INFO - step: 1392,loss: 0.260 accuracy: 0.891\n",
      "2017-09-06 08:53:57,696 - INFO - step: 1393,loss: 0.142 accuracy: 0.914\n",
      "2017-09-06 08:53:58,903 - INFO - step: 1394,loss: 0.119 accuracy: 0.953\n",
      "2017-09-06 08:54:00,109 - INFO - step: 1395,loss: 0.159 accuracy: 0.953\n",
      "2017-09-06 08:54:01,336 - INFO - step: 1396,loss: 0.187 accuracy: 0.930\n",
      "2017-09-06 08:54:02,575 - INFO - step: 1397,loss: 0.089 accuracy: 0.961\n",
      "2017-09-06 08:54:03,806 - INFO - step: 1398,loss: 0.226 accuracy: 0.883\n",
      "2017-09-06 08:54:05,040 - INFO - step: 1399,loss: 0.207 accuracy: 0.930\n",
      "2017-09-06 08:54:06,164 - INFO - step: 1400,loss: 0.057 accuracy: 0.985\n",
      "2017-09-06 08:54:06,167 - INFO - \n",
      "train_epoch:69.000\n",
      "2017-09-06 08:54:06,169 - INFO - loss_total: 0.142 accuracy_total: 0.943\n",
      "2017-09-06 08:54:07,411 - INFO - step: 1401,loss: 0.122 accuracy: 0.945\n",
      "2017-09-06 08:54:08,652 - INFO - step: 1402,loss: 0.186 accuracy: 0.906\n",
      "2017-09-06 08:54:09,911 - INFO - step: 1403,loss: 0.192 accuracy: 0.914\n",
      "2017-09-06 08:54:11,123 - INFO - step: 1404,loss: 0.178 accuracy: 0.922\n",
      "2017-09-06 08:54:12,374 - INFO - step: 1405,loss: 0.104 accuracy: 0.953\n",
      "2017-09-06 08:54:13,601 - INFO - step: 1406,loss: 0.097 accuracy: 0.961\n",
      "2017-09-06 08:54:14,856 - INFO - step: 1407,loss: 0.144 accuracy: 0.938\n",
      "2017-09-06 08:54:16,104 - INFO - step: 1408,loss: 0.147 accuracy: 0.938\n",
      "2017-09-06 08:54:17,347 - INFO - step: 1409,loss: 0.169 accuracy: 0.938\n",
      "2017-09-06 08:54:18,567 - INFO - step: 1410,loss: 0.111 accuracy: 0.953\n",
      "2017-09-06 08:54:19,780 - INFO - step: 1411,loss: 0.147 accuracy: 0.930\n",
      "2017-09-06 08:54:21,009 - INFO - step: 1412,loss: 0.122 accuracy: 0.953\n",
      "2017-09-06 08:54:22,224 - INFO - step: 1413,loss: 0.137 accuracy: 0.922\n",
      "2017-09-06 08:54:23,454 - INFO - step: 1414,loss: 0.183 accuracy: 0.922\n",
      "2017-09-06 08:54:24,678 - INFO - step: 1415,loss: 0.133 accuracy: 0.938\n",
      "2017-09-06 08:54:25,934 - INFO - step: 1416,loss: 0.124 accuracy: 0.953\n",
      "2017-09-06 08:54:27,161 - INFO - step: 1417,loss: 0.126 accuracy: 0.953\n",
      "2017-09-06 08:54:28,407 - INFO - step: 1418,loss: 0.125 accuracy: 0.930\n",
      "2017-09-06 08:54:29,575 - INFO - step: 1419,loss: 0.123 accuracy: 0.953\n",
      "2017-09-06 08:54:30,699 - INFO - step: 1420,loss: 0.084 accuracy: 0.985\n",
      "2017-09-06 08:54:30,701 - INFO - \n",
      "train_epoch:70.000\n",
      "2017-09-06 08:54:30,703 - INFO - loss_total: 0.138 accuracy_total: 0.940\n",
      "2017-09-06 08:54:30,705 - INFO - \n",
      "Evaluation:70.000\n",
      "2017-09-06 08:54:31,247 - INFO - step: 1420,loss: 0.305 accuracy: 0.892\n",
      "2017-09-06 08:54:31,249 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:54:32,475 - INFO - step: 1421,loss: 0.131 accuracy: 0.930\n",
      "2017-09-06 08:54:33,699 - INFO - step: 1422,loss: 0.124 accuracy: 0.961\n",
      "2017-09-06 08:54:34,929 - INFO - step: 1423,loss: 0.112 accuracy: 0.969\n",
      "2017-09-06 08:54:36,119 - INFO - step: 1424,loss: 0.106 accuracy: 0.953\n",
      "2017-09-06 08:54:37,354 - INFO - step: 1425,loss: 0.079 accuracy: 0.984\n",
      "2017-09-06 08:54:38,586 - INFO - step: 1426,loss: 0.138 accuracy: 0.930\n",
      "2017-09-06 08:54:39,838 - INFO - step: 1427,loss: 0.144 accuracy: 0.953\n",
      "2017-09-06 08:54:41,038 - INFO - step: 1428,loss: 0.115 accuracy: 0.953\n",
      "2017-09-06 08:54:42,284 - INFO - step: 1429,loss: 0.156 accuracy: 0.930\n",
      "2017-09-06 08:54:43,477 - INFO - step: 1430,loss: 0.092 accuracy: 0.969\n",
      "2017-09-06 08:54:44,707 - INFO - step: 1431,loss: 0.107 accuracy: 0.969\n",
      "2017-09-06 08:54:45,906 - INFO - step: 1432,loss: 0.135 accuracy: 0.961\n",
      "2017-09-06 08:54:47,117 - INFO - step: 1433,loss: 0.141 accuracy: 0.930\n",
      "2017-09-06 08:54:48,329 - INFO - step: 1434,loss: 0.147 accuracy: 0.930\n",
      "2017-09-06 08:54:49,564 - INFO - step: 1435,loss: 0.181 accuracy: 0.914\n",
      "2017-09-06 08:54:50,832 - INFO - step: 1436,loss: 0.153 accuracy: 0.938\n",
      "2017-09-06 08:54:52,058 - INFO - step: 1437,loss: 0.093 accuracy: 0.961\n",
      "2017-09-06 08:54:53,272 - INFO - step: 1438,loss: 0.166 accuracy: 0.914\n",
      "2017-09-06 08:54:54,501 - INFO - step: 1439,loss: 0.132 accuracy: 0.953\n",
      "2017-09-06 08:54:55,619 - INFO - step: 1440,loss: 0.129 accuracy: 0.954\n",
      "2017-09-06 08:54:55,622 - INFO - \n",
      "train_epoch:71.000\n",
      "2017-09-06 08:54:55,624 - INFO - loss_total: 0.129 accuracy_total: 0.948\n",
      "2017-09-06 08:54:56,842 - INFO - step: 1441,loss: 0.104 accuracy: 0.953\n",
      "2017-09-06 08:54:58,093 - INFO - step: 1442,loss: 0.108 accuracy: 0.961\n",
      "2017-09-06 08:54:59,318 - INFO - step: 1443,loss: 0.075 accuracy: 0.984\n",
      "2017-09-06 08:55:00,537 - INFO - step: 1444,loss: 0.171 accuracy: 0.906\n",
      "2017-09-06 08:55:01,763 - INFO - step: 1445,loss: 0.127 accuracy: 0.961\n",
      "2017-09-06 08:55:02,983 - INFO - step: 1446,loss: 0.122 accuracy: 0.945\n",
      "2017-09-06 08:55:04,558 - INFO - step: 1447,loss: 0.144 accuracy: 0.930\n",
      "2017-09-06 08:55:05,755 - INFO - step: 1448,loss: 0.118 accuracy: 0.953\n",
      "2017-09-06 08:55:06,979 - INFO - step: 1449,loss: 0.119 accuracy: 0.961\n",
      "2017-09-06 08:55:08,211 - INFO - step: 1450,loss: 0.161 accuracy: 0.922\n",
      "2017-09-06 08:55:09,413 - INFO - step: 1451,loss: 0.121 accuracy: 0.945\n",
      "2017-09-06 08:55:10,634 - INFO - step: 1452,loss: 0.132 accuracy: 0.938\n",
      "2017-09-06 08:55:11,852 - INFO - step: 1453,loss: 0.196 accuracy: 0.930\n",
      "2017-09-06 08:55:13,061 - INFO - step: 1454,loss: 0.149 accuracy: 0.938\n",
      "2017-09-06 08:55:14,330 - INFO - step: 1455,loss: 0.124 accuracy: 0.938\n",
      "2017-09-06 08:55:15,562 - INFO - step: 1456,loss: 0.098 accuracy: 0.961\n",
      "2017-09-06 08:55:16,795 - INFO - step: 1457,loss: 0.127 accuracy: 0.953\n",
      "2017-09-06 08:55:18,032 - INFO - step: 1458,loss: 0.154 accuracy: 0.938\n",
      "2017-09-06 08:55:19,255 - INFO - step: 1459,loss: 0.165 accuracy: 0.945\n",
      "2017-09-06 08:55:20,370 - INFO - step: 1460,loss: 0.200 accuracy: 0.938\n",
      "2017-09-06 08:55:20,373 - INFO - \n",
      "train_epoch:72.000\n",
      "2017-09-06 08:55:20,375 - INFO - loss_total: 0.136 accuracy_total: 0.945\n",
      "2017-09-06 08:55:20,376 - INFO - \n",
      "Evaluation:72.000\n",
      "2017-09-06 08:55:20,918 - INFO - step: 1460,loss: 0.309 accuracy: 0.899\n",
      "2017-09-06 08:55:20,920 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:55:22,144 - INFO - step: 1461,loss: 0.134 accuracy: 0.938\n",
      "2017-09-06 08:55:23,347 - INFO - step: 1462,loss: 0.112 accuracy: 0.953\n",
      "2017-09-06 08:55:24,551 - INFO - step: 1463,loss: 0.095 accuracy: 0.953\n",
      "2017-09-06 08:55:25,794 - INFO - step: 1464,loss: 0.096 accuracy: 0.969\n",
      "2017-09-06 08:55:27,018 - INFO - step: 1465,loss: 0.117 accuracy: 0.945\n",
      "2017-09-06 08:55:28,225 - INFO - step: 1466,loss: 0.129 accuracy: 0.953\n",
      "2017-09-06 08:55:29,432 - INFO - step: 1467,loss: 0.128 accuracy: 0.953\n",
      "2017-09-06 08:55:30,667 - INFO - step: 1468,loss: 0.164 accuracy: 0.922\n",
      "2017-09-06 08:55:31,880 - INFO - step: 1469,loss: 0.204 accuracy: 0.898\n",
      "2017-09-06 08:55:33,106 - INFO - step: 1470,loss: 0.177 accuracy: 0.898\n",
      "2017-09-06 08:55:34,324 - INFO - step: 1471,loss: 0.138 accuracy: 0.953\n",
      "2017-09-06 08:55:35,512 - INFO - step: 1472,loss: 0.098 accuracy: 0.977\n",
      "2017-09-06 08:55:36,744 - INFO - step: 1473,loss: 0.130 accuracy: 0.961\n",
      "2017-09-06 08:55:37,957 - INFO - step: 1474,loss: 0.141 accuracy: 0.938\n",
      "2017-09-06 08:55:39,158 - INFO - step: 1475,loss: 0.181 accuracy: 0.914\n",
      "2017-09-06 08:55:40,378 - INFO - step: 1476,loss: 0.141 accuracy: 0.945\n",
      "2017-09-06 08:55:41,608 - INFO - step: 1477,loss: 0.104 accuracy: 0.953\n",
      "2017-09-06 08:55:42,839 - INFO - step: 1478,loss: 0.109 accuracy: 0.961\n",
      "2017-09-06 08:55:44,062 - INFO - step: 1479,loss: 0.137 accuracy: 0.953\n",
      "2017-09-06 08:55:45,167 - INFO - step: 1480,loss: 0.188 accuracy: 0.908\n",
      "2017-09-06 08:55:45,169 - INFO - \n",
      "train_epoch:73.000\n",
      "2017-09-06 08:55:45,171 - INFO - loss_total: 0.136 accuracy_total: 0.942\n",
      "2017-09-06 08:55:46,410 - INFO - step: 1481,loss: 0.114 accuracy: 0.961\n",
      "2017-09-06 08:55:47,601 - INFO - step: 1482,loss: 0.121 accuracy: 0.953\n",
      "2017-09-06 08:55:48,823 - INFO - step: 1483,loss: 0.137 accuracy: 0.930\n",
      "2017-09-06 08:55:50,020 - INFO - step: 1484,loss: 0.159 accuracy: 0.938\n",
      "2017-09-06 08:55:51,244 - INFO - step: 1485,loss: 0.146 accuracy: 0.938\n",
      "2017-09-06 08:55:52,461 - INFO - step: 1486,loss: 0.106 accuracy: 0.953\n",
      "2017-09-06 08:55:53,692 - INFO - step: 1487,loss: 0.106 accuracy: 0.961\n",
      "2017-09-06 08:55:54,914 - INFO - step: 1488,loss: 0.169 accuracy: 0.930\n",
      "2017-09-06 08:55:56,141 - INFO - step: 1489,loss: 0.153 accuracy: 0.938\n",
      "2017-09-06 08:55:57,362 - INFO - step: 1490,loss: 0.115 accuracy: 0.961\n",
      "2017-09-06 08:55:58,599 - INFO - step: 1491,loss: 0.147 accuracy: 0.930\n",
      "2017-09-06 08:55:59,850 - INFO - step: 1492,loss: 0.105 accuracy: 0.945\n",
      "2017-09-06 08:56:01,088 - INFO - step: 1493,loss: 0.183 accuracy: 0.906\n",
      "2017-09-06 08:56:02,319 - INFO - step: 1494,loss: 0.189 accuracy: 0.930\n",
      "2017-09-06 08:56:03,539 - INFO - step: 1495,loss: 0.081 accuracy: 0.977\n",
      "2017-09-06 08:56:04,979 - INFO - step: 1496,loss: 0.183 accuracy: 0.922\n",
      "2017-09-06 08:56:06,425 - INFO - step: 1497,loss: 0.098 accuracy: 0.953\n",
      "2017-09-06 08:56:09,409 - INFO - step: 1498,loss: 0.156 accuracy: 0.930\n",
      "2017-09-06 08:56:12,828 - INFO - step: 1499,loss: 0.094 accuracy: 0.969\n",
      "2017-09-06 08:56:14,629 - INFO - step: 1500,loss: 0.211 accuracy: 0.908\n",
      "2017-09-06 08:56:14,633 - INFO - \n",
      "train_epoch:74.000\n",
      "2017-09-06 08:56:14,634 - INFO - loss_total: 0.138 accuracy_total: 0.941\n",
      "2017-09-06 08:56:14,635 - INFO - \n",
      "Evaluation:74.000\n",
      "2017-09-06 08:56:15,431 - INFO - step: 1500,loss: 0.306 accuracy: 0.899\n",
      "2017-09-06 08:56:15,432 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:56:17,475 - INFO - step: 1501,loss: 0.134 accuracy: 0.938\n",
      "2017-09-06 08:56:19,460 - INFO - step: 1502,loss: 0.109 accuracy: 0.953\n",
      "2017-09-06 08:56:21,482 - INFO - step: 1503,loss: 0.100 accuracy: 0.953\n",
      "2017-09-06 08:56:23,400 - INFO - step: 1504,loss: 0.235 accuracy: 0.938\n",
      "2017-09-06 08:56:25,371 - INFO - step: 1505,loss: 0.116 accuracy: 0.961\n",
      "2017-09-06 08:56:27,261 - INFO - step: 1506,loss: 0.088 accuracy: 0.977\n",
      "2017-09-06 08:56:29,118 - INFO - step: 1507,loss: 0.176 accuracy: 0.906\n",
      "2017-09-06 08:56:31,136 - INFO - step: 1508,loss: 0.129 accuracy: 0.945\n",
      "2017-09-06 08:56:33,100 - INFO - step: 1509,loss: 0.118 accuracy: 0.938\n",
      "2017-09-06 08:56:35,012 - INFO - step: 1510,loss: 0.170 accuracy: 0.922\n",
      "2017-09-06 08:56:36,968 - INFO - step: 1511,loss: 0.140 accuracy: 0.945\n",
      "2017-09-06 08:56:38,978 - INFO - step: 1512,loss: 0.119 accuracy: 0.969\n",
      "2017-09-06 08:56:40,899 - INFO - step: 1513,loss: 0.113 accuracy: 0.953\n",
      "2017-09-06 08:56:42,900 - INFO - step: 1514,loss: 0.092 accuracy: 0.969\n",
      "2017-09-06 08:56:44,882 - INFO - step: 1515,loss: 0.187 accuracy: 0.914\n",
      "2017-09-06 08:56:46,852 - INFO - step: 1516,loss: 0.135 accuracy: 0.945\n",
      "2017-09-06 08:56:48,751 - INFO - step: 1517,loss: 0.127 accuracy: 0.961\n",
      "2017-09-06 08:56:50,716 - INFO - step: 1518,loss: 0.131 accuracy: 0.930\n",
      "2017-09-06 08:56:52,730 - INFO - step: 1519,loss: 0.155 accuracy: 0.938\n",
      "2017-09-06 08:56:54,375 - INFO - step: 1520,loss: 0.138 accuracy: 0.923\n",
      "2017-09-06 08:56:54,378 - INFO - \n",
      "train_epoch:75.000\n",
      "2017-09-06 08:56:54,380 - INFO - loss_total: 0.136 accuracy_total: 0.944\n",
      "2017-09-06 08:56:56,406 - INFO - step: 1521,loss: 0.138 accuracy: 0.938\n",
      "2017-09-06 08:56:58,413 - INFO - step: 1522,loss: 0.152 accuracy: 0.930\n",
      "2017-09-06 08:57:00,225 - INFO - step: 1523,loss: 0.117 accuracy: 0.953\n",
      "2017-09-06 08:57:02,238 - INFO - step: 1524,loss: 0.096 accuracy: 0.977\n",
      "2017-09-06 08:57:04,221 - INFO - step: 1525,loss: 0.128 accuracy: 0.961\n",
      "2017-09-06 08:57:06,177 - INFO - step: 1526,loss: 0.155 accuracy: 0.922\n",
      "2017-09-06 08:57:08,195 - INFO - step: 1527,loss: 0.096 accuracy: 0.953\n",
      "2017-09-06 08:57:10,173 - INFO - step: 1528,loss: 0.154 accuracy: 0.953\n",
      "2017-09-06 08:57:12,187 - INFO - step: 1529,loss: 0.119 accuracy: 0.945\n",
      "2017-09-06 08:57:14,114 - INFO - step: 1530,loss: 0.189 accuracy: 0.914\n",
      "2017-09-06 08:57:16,094 - INFO - step: 1531,loss: 0.124 accuracy: 0.938\n",
      "2017-09-06 08:57:18,091 - INFO - step: 1532,loss: 0.179 accuracy: 0.922\n",
      "2017-09-06 08:57:19,871 - INFO - step: 1533,loss: 0.169 accuracy: 0.922\n",
      "2017-09-06 08:57:21,863 - INFO - step: 1534,loss: 0.105 accuracy: 0.953\n",
      "2017-09-06 08:57:23,845 - INFO - step: 1535,loss: 0.105 accuracy: 0.969\n",
      "2017-09-06 08:57:25,712 - INFO - step: 1536,loss: 0.110 accuracy: 0.953\n",
      "2017-09-06 08:57:27,710 - INFO - step: 1537,loss: 0.158 accuracy: 0.922\n",
      "2017-09-06 08:57:29,684 - INFO - step: 1538,loss: 0.156 accuracy: 0.930\n",
      "2017-09-06 08:57:31,621 - INFO - step: 1539,loss: 0.160 accuracy: 0.930\n",
      "2017-09-06 08:57:33,406 - INFO - step: 1540,loss: 0.078 accuracy: 0.985\n",
      "2017-09-06 08:57:33,409 - INFO - \n",
      "train_epoch:76.000\n",
      "2017-09-06 08:57:33,411 - INFO - loss_total: 0.134 accuracy_total: 0.943\n",
      "2017-09-06 08:57:33,412 - INFO - \n",
      "Evaluation:76.000\n",
      "2017-09-06 08:57:34,285 - INFO - step: 1540,loss: 0.270 accuracy: 0.910\n",
      "2017-09-06 08:57:34,286 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:57:36,287 - INFO - step: 1541,loss: 0.135 accuracy: 0.938\n",
      "2017-09-06 08:57:38,177 - INFO - step: 1542,loss: 0.140 accuracy: 0.961\n",
      "2017-09-06 08:57:40,138 - INFO - step: 1543,loss: 0.121 accuracy: 0.953\n",
      "2017-09-06 08:57:42,086 - INFO - step: 1544,loss: 0.111 accuracy: 0.961\n",
      "2017-09-06 08:57:44,077 - INFO - step: 1545,loss: 0.097 accuracy: 0.969\n",
      "2017-09-06 08:57:45,856 - INFO - step: 1546,loss: 0.169 accuracy: 0.914\n",
      "2017-09-06 08:57:47,799 - INFO - step: 1547,loss: 0.155 accuracy: 0.953\n",
      "2017-09-06 08:57:49,719 - INFO - step: 1548,loss: 0.087 accuracy: 0.961\n",
      "2017-09-06 08:57:51,635 - INFO - step: 1549,loss: 0.124 accuracy: 0.945\n",
      "2017-09-06 08:57:53,600 - INFO - step: 1550,loss: 0.145 accuracy: 0.922\n",
      "2017-09-06 08:57:55,560 - INFO - step: 1551,loss: 0.144 accuracy: 0.945\n",
      "2017-09-06 08:57:57,552 - INFO - step: 1552,loss: 0.153 accuracy: 0.922\n",
      "2017-09-06 08:57:59,406 - INFO - step: 1553,loss: 0.107 accuracy: 0.938\n",
      "2017-09-06 08:58:01,335 - INFO - step: 1554,loss: 0.102 accuracy: 0.969\n",
      "2017-09-06 08:58:03,314 - INFO - step: 1555,loss: 0.127 accuracy: 0.945\n",
      "2017-09-06 08:58:05,203 - INFO - step: 1556,loss: 0.171 accuracy: 0.914\n",
      "2017-09-06 08:58:07,160 - INFO - step: 1557,loss: 0.126 accuracy: 0.953\n",
      "2017-09-06 08:58:09,106 - INFO - step: 1558,loss: 0.139 accuracy: 0.945\n",
      "2017-09-06 08:58:10,973 - INFO - step: 1559,loss: 0.103 accuracy: 0.953\n",
      "2017-09-06 08:58:12,769 - INFO - step: 1560,loss: 0.113 accuracy: 0.969\n",
      "2017-09-06 08:58:12,772 - INFO - \n",
      "train_epoch:77.000\n",
      "2017-09-06 08:58:12,774 - INFO - loss_total: 0.128 accuracy_total: 0.947\n",
      "2017-09-06 08:58:14,732 - INFO - step: 1561,loss: 0.164 accuracy: 0.922\n",
      "2017-09-06 08:58:16,705 - INFO - step: 1562,loss: 0.148 accuracy: 0.930\n",
      "2017-09-06 08:58:18,599 - INFO - step: 1563,loss: 0.153 accuracy: 0.930\n",
      "2017-09-06 08:58:20,558 - INFO - step: 1564,loss: 0.118 accuracy: 0.953\n",
      "2017-09-06 08:58:22,539 - INFO - step: 1565,loss: 0.093 accuracy: 0.961\n",
      "2017-09-06 08:58:24,419 - INFO - step: 1566,loss: 0.097 accuracy: 0.977\n",
      "2017-09-06 08:58:26,382 - INFO - step: 1567,loss: 0.116 accuracy: 0.953\n",
      "2017-09-06 08:58:28,320 - INFO - step: 1568,loss: 0.093 accuracy: 0.969\n",
      "2017-09-06 08:58:30,165 - INFO - step: 1569,loss: 0.137 accuracy: 0.938\n",
      "2017-09-06 08:58:32,106 - INFO - step: 1570,loss: 0.115 accuracy: 0.953\n",
      "2017-09-06 08:58:34,068 - INFO - step: 1571,loss: 0.104 accuracy: 0.961\n",
      "2017-09-06 08:58:36,018 - INFO - step: 1572,loss: 0.131 accuracy: 0.953\n",
      "2017-09-06 08:58:37,910 - INFO - step: 1573,loss: 0.180 accuracy: 0.898\n",
      "2017-09-06 08:58:39,861 - INFO - step: 1574,loss: 0.166 accuracy: 0.930\n",
      "2017-09-06 08:58:41,841 - INFO - step: 1575,loss: 0.150 accuracy: 0.930\n",
      "2017-09-06 08:58:43,679 - INFO - step: 1576,loss: 0.119 accuracy: 0.969\n",
      "2017-09-06 08:58:45,640 - INFO - step: 1577,loss: 0.120 accuracy: 0.938\n",
      "2017-09-06 08:58:47,592 - INFO - step: 1578,loss: 0.085 accuracy: 0.984\n",
      "2017-09-06 08:58:49,504 - INFO - step: 1579,loss: 0.141 accuracy: 0.922\n",
      "2017-09-06 08:58:51,263 - INFO - step: 1580,loss: 0.091 accuracy: 0.985\n",
      "2017-09-06 08:58:51,266 - INFO - \n",
      "train_epoch:78.000\n",
      "2017-09-06 08:58:51,268 - INFO - loss_total: 0.126 accuracy_total: 0.948\n",
      "2017-09-06 08:58:51,269 - INFO - \n",
      "Evaluation:78.000\n",
      "2017-09-06 08:58:52,138 - INFO - step: 1580,loss: 0.281 accuracy: 0.921\n",
      "2017-09-06 08:58:52,140 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 08:58:54,116 - INFO - step: 1581,loss: 0.157 accuracy: 0.938\n",
      "2017-09-06 08:58:56,055 - INFO - step: 1582,loss: 0.114 accuracy: 0.961\n",
      "2017-09-06 08:58:58,040 - INFO - step: 1583,loss: 0.143 accuracy: 0.945\n",
      "2017-09-06 08:59:00,002 - INFO - step: 1584,loss: 0.104 accuracy: 0.953\n",
      "2017-09-06 08:59:01,965 - INFO - step: 1585,loss: 0.115 accuracy: 0.945\n",
      "2017-09-06 08:59:03,952 - INFO - step: 1586,loss: 0.091 accuracy: 0.969\n",
      "2017-09-06 08:59:05,915 - INFO - step: 1587,loss: 0.155 accuracy: 0.914\n",
      "2017-09-06 08:59:07,844 - INFO - step: 1588,loss: 0.121 accuracy: 0.945\n",
      "2017-09-06 08:59:09,756 - INFO - step: 1589,loss: 0.138 accuracy: 0.953\n",
      "2017-09-06 08:59:11,721 - INFO - step: 1590,loss: 0.124 accuracy: 0.945\n",
      "2017-09-06 08:59:13,676 - INFO - step: 1591,loss: 0.069 accuracy: 0.977\n",
      "2017-09-06 08:59:15,576 - INFO - step: 1592,loss: 0.085 accuracy: 0.992\n",
      "2017-09-06 08:59:17,608 - INFO - step: 1593,loss: 0.192 accuracy: 0.930\n",
      "2017-09-06 08:59:19,568 - INFO - step: 1594,loss: 0.171 accuracy: 0.914\n",
      "2017-09-06 08:59:21,456 - INFO - step: 1595,loss: 0.092 accuracy: 0.969\n",
      "2017-09-06 08:59:23,414 - INFO - step: 1596,loss: 0.219 accuracy: 0.922\n",
      "2017-09-06 08:59:25,356 - INFO - step: 1597,loss: 0.193 accuracy: 0.922\n",
      "2017-09-06 08:59:27,323 - INFO - step: 1598,loss: 0.126 accuracy: 0.953\n",
      "2017-09-06 08:59:29,137 - INFO - step: 1599,loss: 0.170 accuracy: 0.922\n",
      "2017-09-06 08:59:30,955 - INFO - step: 1600,loss: 0.114 accuracy: 0.954\n",
      "2017-09-06 08:59:30,958 - INFO - \n",
      "train_epoch:79.000\n",
      "2017-09-06 08:59:30,961 - INFO - loss_total: 0.135 accuracy_total: 0.946\n",
      "2017-09-06 08:59:32,924 - INFO - step: 1601,loss: 0.106 accuracy: 0.961\n",
      "2017-09-06 08:59:34,750 - INFO - step: 1602,loss: 0.133 accuracy: 0.938\n",
      "2017-09-06 08:59:36,716 - INFO - step: 1603,loss: 0.138 accuracy: 0.953\n",
      "2017-09-06 08:59:38,650 - INFO - step: 1604,loss: 0.115 accuracy: 0.945\n",
      "2017-09-06 08:59:40,564 - INFO - step: 1605,loss: 0.159 accuracy: 0.914\n",
      "2017-09-06 08:59:42,535 - INFO - step: 1606,loss: 0.128 accuracy: 0.953\n",
      "2017-09-06 08:59:44,491 - INFO - step: 1607,loss: 0.143 accuracy: 0.953\n",
      "2017-09-06 08:59:46,479 - INFO - step: 1608,loss: 0.146 accuracy: 0.922\n",
      "2017-09-06 08:59:48,407 - INFO - step: 1609,loss: 0.094 accuracy: 0.953\n",
      "2017-09-06 08:59:50,332 - INFO - step: 1610,loss: 0.138 accuracy: 0.930\n",
      "2017-09-06 08:59:52,297 - INFO - step: 1611,loss: 0.122 accuracy: 0.953\n",
      "2017-09-06 08:59:54,223 - INFO - step: 1612,loss: 0.084 accuracy: 0.977\n",
      "2017-09-06 08:59:56,182 - INFO - step: 1613,loss: 0.114 accuracy: 0.969\n",
      "2017-09-06 08:59:58,108 - INFO - step: 1614,loss: 0.209 accuracy: 0.891\n",
      "2017-09-06 08:59:59,997 - INFO - step: 1615,loss: 0.102 accuracy: 0.953\n",
      "2017-09-06 09:00:01,947 - INFO - step: 1616,loss: 0.150 accuracy: 0.945\n",
      "2017-09-06 09:00:03,875 - INFO - step: 1617,loss: 0.119 accuracy: 0.969\n",
      "2017-09-06 09:00:05,830 - INFO - step: 1618,loss: 0.204 accuracy: 0.898\n",
      "2017-09-06 09:00:07,683 - INFO - step: 1619,loss: 0.113 accuracy: 0.961\n",
      "2017-09-06 09:00:09,459 - INFO - step: 1620,loss: 0.086 accuracy: 0.969\n",
      "2017-09-06 09:00:09,462 - INFO - \n",
      "train_epoch:80.000\n",
      "2017-09-06 09:00:09,464 - INFO - loss_total: 0.130 accuracy_total: 0.945\n",
      "2017-09-06 09:00:09,466 - INFO - \n",
      "Evaluation:80.000\n",
      "2017-09-06 09:00:10,344 - INFO - step: 1620,loss: 0.318 accuracy: 0.896\n",
      "2017-09-06 09:00:10,346 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 09:00:12,323 - INFO - step: 1621,loss: 0.195 accuracy: 0.898\n",
      "2017-09-06 09:00:14,272 - INFO - step: 1622,loss: 0.100 accuracy: 0.969\n",
      "2017-09-06 09:00:16,237 - INFO - step: 1623,loss: 0.171 accuracy: 0.922\n",
      "2017-09-06 09:00:18,206 - INFO - step: 1624,loss: 0.121 accuracy: 0.945\n",
      "2017-09-06 09:00:20,063 - INFO - step: 1625,loss: 0.096 accuracy: 0.984\n",
      "2017-09-06 09:00:22,018 - INFO - step: 1626,loss: 0.131 accuracy: 0.953\n",
      "2017-09-06 09:00:23,978 - INFO - step: 1627,loss: 0.113 accuracy: 0.969\n",
      "2017-09-06 09:00:25,800 - INFO - step: 1628,loss: 0.155 accuracy: 0.938\n",
      "2017-09-06 09:00:27,771 - INFO - step: 1629,loss: 0.069 accuracy: 0.969\n",
      "2017-09-06 09:00:29,718 - INFO - step: 1630,loss: 0.112 accuracy: 0.969\n",
      "2017-09-06 09:00:31,664 - INFO - step: 1631,loss: 0.142 accuracy: 0.938\n",
      "2017-09-06 09:00:33,605 - INFO - step: 1632,loss: 0.128 accuracy: 0.945\n",
      "2017-09-06 09:00:35,563 - INFO - step: 1633,loss: 0.137 accuracy: 0.930\n",
      "2017-09-06 09:00:37,506 - INFO - step: 1634,loss: 0.215 accuracy: 0.898\n",
      "2017-09-06 09:00:39,377 - INFO - step: 1635,loss: 0.160 accuracy: 0.898\n",
      "2017-09-06 09:00:41,314 - INFO - step: 1636,loss: 0.130 accuracy: 0.938\n",
      "2017-09-06 09:00:43,292 - INFO - step: 1637,loss: 0.179 accuracy: 0.906\n",
      "2017-09-06 09:00:45,223 - INFO - step: 1638,loss: 0.125 accuracy: 0.961\n",
      "2017-09-06 09:00:47,170 - INFO - step: 1639,loss: 0.110 accuracy: 0.969\n",
      "2017-09-06 09:00:48,937 - INFO - step: 1640,loss: 0.140 accuracy: 0.923\n",
      "2017-09-06 09:00:48,940 - INFO - \n",
      "train_epoch:81.000\n",
      "2017-09-06 09:00:48,941 - INFO - loss_total: 0.136 accuracy_total: 0.941\n",
      "2017-09-06 09:00:50,896 - INFO - step: 1641,loss: 0.065 accuracy: 0.984\n",
      "2017-09-06 09:00:52,836 - INFO - step: 1642,loss: 0.137 accuracy: 0.938\n",
      "2017-09-06 09:00:54,796 - INFO - step: 1643,loss: 0.095 accuracy: 0.969\n",
      "2017-09-06 09:00:56,737 - INFO - step: 1644,loss: 0.122 accuracy: 0.953\n",
      "2017-09-06 09:00:58,634 - INFO - step: 1645,loss: 0.144 accuracy: 0.938\n",
      "2017-09-06 09:01:00,575 - INFO - step: 1646,loss: 0.088 accuracy: 0.969\n",
      "2017-09-06 09:01:02,551 - INFO - step: 1647,loss: 0.181 accuracy: 0.906\n",
      "2017-09-06 09:01:04,453 - INFO - step: 1648,loss: 0.087 accuracy: 0.969\n",
      "2017-09-06 09:01:06,402 - INFO - step: 1649,loss: 0.157 accuracy: 0.922\n",
      "2017-09-06 09:01:08,327 - INFO - step: 1650,loss: 0.214 accuracy: 0.898\n",
      "2017-09-06 09:01:10,230 - INFO - step: 1651,loss: 0.167 accuracy: 0.945\n",
      "2017-09-06 09:01:12,200 - INFO - step: 1652,loss: 0.170 accuracy: 0.922\n",
      "2017-09-06 09:01:14,159 - INFO - step: 1653,loss: 0.142 accuracy: 0.938\n",
      "2017-09-06 09:01:16,110 - INFO - step: 1654,loss: 0.111 accuracy: 0.945\n",
      "2017-09-06 09:01:17,919 - INFO - step: 1655,loss: 0.146 accuracy: 0.930\n",
      "2017-09-06 09:01:19,863 - INFO - step: 1656,loss: 0.125 accuracy: 0.953\n",
      "2017-09-06 09:01:21,828 - INFO - step: 1657,loss: 0.073 accuracy: 0.984\n",
      "2017-09-06 09:01:23,733 - INFO - step: 1658,loss: 0.074 accuracy: 0.977\n",
      "2017-09-06 09:01:25,675 - INFO - step: 1659,loss: 0.135 accuracy: 0.938\n",
      "2017-09-06 09:01:27,410 - INFO - step: 1660,loss: 0.133 accuracy: 0.969\n",
      "2017-09-06 09:01:27,413 - INFO - \n",
      "train_epoch:82.000\n",
      "2017-09-06 09:01:27,415 - INFO - loss_total: 0.128 accuracy_total: 0.947\n",
      "2017-09-06 09:01:27,417 - INFO - \n",
      "Evaluation:82.000\n",
      "2017-09-06 09:01:28,294 - INFO - step: 1660,loss: 0.319 accuracy: 0.892\n",
      "2017-09-06 09:01:28,295 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 09:01:30,268 - INFO - step: 1661,loss: 0.158 accuracy: 0.938\n",
      "2017-09-06 09:01:32,240 - INFO - step: 1662,loss: 0.153 accuracy: 0.945\n",
      "2017-09-06 09:01:33,532 - INFO - step: 1663,loss: 0.120 accuracy: 0.953\n",
      "2017-09-06 09:01:34,739 - INFO - step: 1664,loss: 0.116 accuracy: 0.953\n",
      "2017-09-06 09:01:35,912 - INFO - step: 1665,loss: 0.096 accuracy: 0.961\n",
      "2017-09-06 09:01:37,156 - INFO - step: 1666,loss: 0.135 accuracy: 0.945\n",
      "2017-09-06 09:01:38,387 - INFO - step: 1667,loss: 0.107 accuracy: 0.961\n",
      "2017-09-06 09:01:39,585 - INFO - step: 1668,loss: 0.123 accuracy: 0.945\n",
      "2017-09-06 09:01:40,842 - INFO - step: 1669,loss: 0.141 accuracy: 0.945\n",
      "2017-09-06 09:01:42,061 - INFO - step: 1670,loss: 0.137 accuracy: 0.945\n",
      "2017-09-06 09:01:43,322 - INFO - step: 1671,loss: 0.155 accuracy: 0.938\n",
      "2017-09-06 09:01:44,537 - INFO - step: 1672,loss: 0.214 accuracy: 0.898\n",
      "2017-09-06 09:01:45,781 - INFO - step: 1673,loss: 0.135 accuracy: 0.930\n",
      "2017-09-06 09:01:46,999 - INFO - step: 1674,loss: 0.082 accuracy: 0.984\n",
      "2017-09-06 09:01:48,229 - INFO - step: 1675,loss: 0.148 accuracy: 0.930\n",
      "2017-09-06 09:01:49,467 - INFO - step: 1676,loss: 0.136 accuracy: 0.922\n",
      "2017-09-06 09:01:50,698 - INFO - step: 1677,loss: 0.129 accuracy: 0.953\n",
      "2017-09-06 09:01:51,927 - INFO - step: 1678,loss: 0.123 accuracy: 0.945\n",
      "2017-09-06 09:01:53,166 - INFO - step: 1679,loss: 0.144 accuracy: 0.945\n",
      "2017-09-06 09:01:54,301 - INFO - step: 1680,loss: 0.077 accuracy: 0.985\n",
      "2017-09-06 09:01:54,304 - INFO - \n",
      "train_epoch:83.000\n",
      "2017-09-06 09:01:54,305 - INFO - loss_total: 0.132 accuracy_total: 0.946\n",
      "2017-09-06 09:01:55,558 - INFO - step: 1681,loss: 0.160 accuracy: 0.938\n",
      "2017-09-06 09:01:56,760 - INFO - step: 1682,loss: 0.082 accuracy: 0.977\n",
      "2017-09-06 09:01:57,987 - INFO - step: 1683,loss: 0.131 accuracy: 0.945\n",
      "2017-09-06 09:01:59,242 - INFO - step: 1684,loss: 0.095 accuracy: 0.953\n",
      "2017-09-06 09:02:00,444 - INFO - step: 1685,loss: 0.134 accuracy: 0.930\n",
      "2017-09-06 09:02:01,652 - INFO - step: 1686,loss: 0.140 accuracy: 0.961\n",
      "2017-09-06 09:02:02,859 - INFO - step: 1687,loss: 0.100 accuracy: 0.969\n",
      "2017-09-06 09:02:04,081 - INFO - step: 1688,loss: 0.111 accuracy: 0.953\n",
      "2017-09-06 09:02:05,299 - INFO - step: 1689,loss: 0.115 accuracy: 0.953\n",
      "2017-09-06 09:02:06,551 - INFO - step: 1690,loss: 0.125 accuracy: 0.945\n",
      "2017-09-06 09:02:07,776 - INFO - step: 1691,loss: 0.176 accuracy: 0.898\n",
      "2017-09-06 09:02:09,014 - INFO - step: 1692,loss: 0.117 accuracy: 0.961\n",
      "2017-09-06 09:02:10,245 - INFO - step: 1693,loss: 0.165 accuracy: 0.922\n",
      "2017-09-06 09:02:11,474 - INFO - step: 1694,loss: 0.068 accuracy: 0.984\n",
      "2017-09-06 09:02:12,706 - INFO - step: 1695,loss: 0.171 accuracy: 0.930\n",
      "2017-09-06 09:02:13,931 - INFO - step: 1696,loss: 0.136 accuracy: 0.938\n",
      "2017-09-06 09:02:15,142 - INFO - step: 1697,loss: 0.180 accuracy: 0.906\n",
      "2017-09-06 09:02:16,377 - INFO - step: 1698,loss: 0.141 accuracy: 0.938\n",
      "2017-09-06 09:02:17,612 - INFO - step: 1699,loss: 0.186 accuracy: 0.930\n",
      "2017-09-06 09:02:18,725 - INFO - step: 1700,loss: 0.098 accuracy: 0.954\n",
      "2017-09-06 09:02:18,727 - INFO - \n",
      "train_epoch:84.000\n",
      "2017-09-06 09:02:18,729 - INFO - loss_total: 0.132 accuracy_total: 0.944\n",
      "2017-09-06 09:02:18,730 - INFO - \n",
      "Evaluation:84.000\n",
      "2017-09-06 09:02:19,345 - INFO - step: 1700,loss: 0.309 accuracy: 0.892\n",
      "2017-09-06 09:02:19,346 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 09:02:20,539 - INFO - step: 1701,loss: 0.116 accuracy: 0.953\n",
      "2017-09-06 09:02:21,750 - INFO - step: 1702,loss: 0.129 accuracy: 0.945\n",
      "2017-09-06 09:02:22,990 - INFO - step: 1703,loss: 0.101 accuracy: 0.953\n",
      "2017-09-06 09:02:24,224 - INFO - step: 1704,loss: 0.132 accuracy: 0.953\n",
      "2017-09-06 09:02:25,455 - INFO - step: 1705,loss: 0.148 accuracy: 0.938\n",
      "2017-09-06 09:02:26,678 - INFO - step: 1706,loss: 0.140 accuracy: 0.953\n",
      "2017-09-06 09:02:27,897 - INFO - step: 1707,loss: 0.089 accuracy: 0.977\n",
      "2017-09-06 09:02:29,159 - INFO - step: 1708,loss: 0.120 accuracy: 0.953\n",
      "2017-09-06 09:02:30,387 - INFO - step: 1709,loss: 0.143 accuracy: 0.930\n",
      "2017-09-06 09:02:31,612 - INFO - step: 1710,loss: 0.086 accuracy: 0.961\n",
      "2017-09-06 09:02:32,856 - INFO - step: 1711,loss: 0.102 accuracy: 0.961\n",
      "2017-09-06 09:02:34,065 - INFO - step: 1712,loss: 0.120 accuracy: 0.945\n",
      "2017-09-06 09:02:35,299 - INFO - step: 1713,loss: 0.132 accuracy: 0.945\n",
      "2017-09-06 09:02:36,515 - INFO - step: 1714,loss: 0.152 accuracy: 0.930\n",
      "2017-09-06 09:02:37,766 - INFO - step: 1715,loss: 0.113 accuracy: 0.938\n",
      "2017-09-06 09:02:38,980 - INFO - step: 1716,loss: 0.173 accuracy: 0.930\n",
      "2017-09-06 09:02:40,202 - INFO - step: 1717,loss: 0.098 accuracy: 0.961\n",
      "2017-09-06 09:02:41,433 - INFO - step: 1718,loss: 0.118 accuracy: 0.945\n",
      "2017-09-06 09:02:42,655 - INFO - step: 1719,loss: 0.129 accuracy: 0.938\n",
      "2017-09-06 09:02:43,769 - INFO - step: 1720,loss: 0.171 accuracy: 0.923\n",
      "2017-09-06 09:02:43,772 - INFO - \n",
      "train_epoch:85.000\n",
      "2017-09-06 09:02:43,774 - INFO - loss_total: 0.126 accuracy_total: 0.947\n",
      "2017-09-06 09:02:45,026 - INFO - step: 1721,loss: 0.178 accuracy: 0.898\n",
      "2017-09-06 09:02:46,306 - INFO - step: 1722,loss: 0.129 accuracy: 0.961\n",
      "2017-09-06 09:02:47,526 - INFO - step: 1723,loss: 0.138 accuracy: 0.945\n",
      "2017-09-06 09:02:48,792 - INFO - step: 1724,loss: 0.087 accuracy: 0.969\n",
      "2017-09-06 09:02:50,008 - INFO - step: 1725,loss: 0.052 accuracy: 0.984\n",
      "2017-09-06 09:02:51,201 - INFO - step: 1726,loss: 0.153 accuracy: 0.930\n",
      "2017-09-06 09:02:52,431 - INFO - step: 1727,loss: 0.099 accuracy: 0.961\n",
      "2017-09-06 09:02:53,657 - INFO - step: 1728,loss: 0.097 accuracy: 0.969\n",
      "2017-09-06 09:02:54,893 - INFO - step: 1729,loss: 0.085 accuracy: 0.961\n",
      "2017-09-06 09:02:56,105 - INFO - step: 1730,loss: 0.184 accuracy: 0.914\n",
      "2017-09-06 09:02:57,329 - INFO - step: 1731,loss: 0.095 accuracy: 0.945\n",
      "2017-09-06 09:02:58,567 - INFO - step: 1732,loss: 0.119 accuracy: 0.953\n",
      "2017-09-06 09:02:59,778 - INFO - step: 1733,loss: 0.140 accuracy: 0.938\n",
      "2017-09-06 09:03:01,004 - INFO - step: 1734,loss: 0.166 accuracy: 0.922\n",
      "2017-09-06 09:03:02,262 - INFO - step: 1735,loss: 0.087 accuracy: 0.969\n",
      "2017-09-06 09:03:03,477 - INFO - step: 1736,loss: 0.126 accuracy: 0.953\n",
      "2017-09-06 09:03:04,696 - INFO - step: 1737,loss: 0.204 accuracy: 0.898\n",
      "2017-09-06 09:03:05,919 - INFO - step: 1738,loss: 0.150 accuracy: 0.930\n",
      "2017-09-06 09:03:07,143 - INFO - step: 1739,loss: 0.133 accuracy: 0.938\n",
      "2017-09-06 09:03:08,243 - INFO - step: 1740,loss: 0.085 accuracy: 0.969\n",
      "2017-09-06 09:03:08,246 - INFO - \n",
      "train_epoch:86.000\n",
      "2017-09-06 09:03:08,248 - INFO - loss_total: 0.125 accuracy_total: 0.945\n",
      "2017-09-06 09:03:08,249 - INFO - \n",
      "Evaluation:86.000\n",
      "2017-09-06 09:03:08,793 - INFO - step: 1740,loss: 0.308 accuracy: 0.899\n",
      "2017-09-06 09:03:08,794 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 09:03:10,029 - INFO - step: 1741,loss: 0.131 accuracy: 0.953\n",
      "2017-09-06 09:03:11,244 - INFO - step: 1742,loss: 0.196 accuracy: 0.922\n",
      "2017-09-06 09:03:12,449 - INFO - step: 1743,loss: 0.092 accuracy: 0.977\n",
      "2017-09-06 09:03:13,689 - INFO - step: 1744,loss: 0.110 accuracy: 0.961\n",
      "2017-09-06 09:03:14,920 - INFO - step: 1745,loss: 0.177 accuracy: 0.914\n",
      "2017-09-06 09:03:16,167 - INFO - step: 1746,loss: 0.129 accuracy: 0.938\n",
      "2017-09-06 09:03:17,382 - INFO - step: 1747,loss: 0.108 accuracy: 0.961\n",
      "2017-09-06 09:03:18,638 - INFO - step: 1748,loss: 0.064 accuracy: 0.969\n",
      "2017-09-06 09:03:19,881 - INFO - step: 1749,loss: 0.159 accuracy: 0.914\n",
      "2017-09-06 09:03:21,112 - INFO - step: 1750,loss: 0.141 accuracy: 0.945\n",
      "2017-09-06 09:03:22,553 - INFO - step: 1751,loss: 0.101 accuracy: 0.969\n",
      "2017-09-06 09:03:23,779 - INFO - step: 1752,loss: 0.129 accuracy: 0.945\n",
      "2017-09-06 09:03:25,001 - INFO - step: 1753,loss: 0.134 accuracy: 0.961\n",
      "2017-09-06 09:03:26,260 - INFO - step: 1754,loss: 0.175 accuracy: 0.914\n",
      "2017-09-06 09:03:27,493 - INFO - step: 1755,loss: 0.177 accuracy: 0.914\n",
      "2017-09-06 09:03:28,719 - INFO - step: 1756,loss: 0.145 accuracy: 0.945\n",
      "2017-09-06 09:03:29,956 - INFO - step: 1757,loss: 0.142 accuracy: 0.938\n",
      "2017-09-06 09:03:31,176 - INFO - step: 1758,loss: 0.185 accuracy: 0.914\n",
      "2017-09-06 09:03:32,400 - INFO - step: 1759,loss: 0.112 accuracy: 0.961\n",
      "2017-09-06 09:03:33,508 - INFO - step: 1760,loss: 0.081 accuracy: 0.969\n",
      "2017-09-06 09:03:33,511 - INFO - \n",
      "train_epoch:87.000\n",
      "2017-09-06 09:03:33,513 - INFO - loss_total: 0.134 accuracy_total: 0.944\n",
      "2017-09-06 09:03:34,741 - INFO - step: 1761,loss: 0.151 accuracy: 0.922\n",
      "2017-09-06 09:03:35,972 - INFO - step: 1762,loss: 0.115 accuracy: 0.961\n",
      "2017-09-06 09:03:37,170 - INFO - step: 1763,loss: 0.087 accuracy: 0.969\n",
      "2017-09-06 09:03:38,385 - INFO - step: 1764,loss: 0.080 accuracy: 0.969\n",
      "2017-09-06 09:03:39,612 - INFO - step: 1765,loss: 0.125 accuracy: 0.961\n",
      "2017-09-06 09:03:40,855 - INFO - step: 1766,loss: 0.083 accuracy: 0.984\n",
      "2017-09-06 09:03:42,047 - INFO - step: 1767,loss: 0.128 accuracy: 0.945\n",
      "2017-09-06 09:03:43,281 - INFO - step: 1768,loss: 0.155 accuracy: 0.930\n",
      "2017-09-06 09:03:44,513 - INFO - step: 1769,loss: 0.139 accuracy: 0.930\n",
      "2017-09-06 09:03:45,747 - INFO - step: 1770,loss: 0.114 accuracy: 0.945\n",
      "2017-09-06 09:03:46,951 - INFO - step: 1771,loss: 0.238 accuracy: 0.883\n",
      "2017-09-06 09:03:48,178 - INFO - step: 1772,loss: 0.143 accuracy: 0.922\n",
      "2017-09-06 09:03:49,404 - INFO - step: 1773,loss: 0.145 accuracy: 0.938\n",
      "2017-09-06 09:03:50,622 - INFO - step: 1774,loss: 0.160 accuracy: 0.930\n",
      "2017-09-06 09:03:51,838 - INFO - step: 1775,loss: 0.161 accuracy: 0.914\n",
      "2017-09-06 09:03:53,061 - INFO - step: 1776,loss: 0.112 accuracy: 0.969\n",
      "2017-09-06 09:03:54,322 - INFO - step: 1777,loss: 0.077 accuracy: 0.977\n",
      "2017-09-06 09:03:55,540 - INFO - step: 1778,loss: 0.165 accuracy: 0.945\n",
      "2017-09-06 09:03:56,759 - INFO - step: 1779,loss: 0.159 accuracy: 0.930\n",
      "2017-09-06 09:03:57,906 - INFO - step: 1780,loss: 0.213 accuracy: 0.923\n",
      "2017-09-06 09:03:57,909 - INFO - \n",
      "train_epoch:88.000\n",
      "2017-09-06 09:03:57,911 - INFO - loss_total: 0.137 accuracy_total: 0.942\n",
      "2017-09-06 09:03:57,912 - INFO - \n",
      "Evaluation:88.000\n",
      "2017-09-06 09:03:58,595 - INFO - step: 1780,loss: 0.316 accuracy: 0.899\n",
      "2017-09-06 09:03:58,596 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 09:03:59,833 - INFO - step: 1781,loss: 0.158 accuracy: 0.922\n",
      "2017-09-06 09:04:01,067 - INFO - step: 1782,loss: 0.160 accuracy: 0.906\n",
      "2017-09-06 09:04:02,301 - INFO - step: 1783,loss: 0.099 accuracy: 0.969\n",
      "2017-09-06 09:04:03,543 - INFO - step: 1784,loss: 0.109 accuracy: 0.953\n",
      "2017-09-06 09:04:04,771 - INFO - step: 1785,loss: 0.208 accuracy: 0.891\n",
      "2017-09-06 09:04:05,977 - INFO - step: 1786,loss: 0.164 accuracy: 0.922\n",
      "2017-09-06 09:04:07,223 - INFO - step: 1787,loss: 0.172 accuracy: 0.922\n",
      "2017-09-06 09:04:08,455 - INFO - step: 1788,loss: 0.233 accuracy: 0.898\n",
      "2017-09-06 09:04:09,684 - INFO - step: 1789,loss: 0.087 accuracy: 0.969\n",
      "2017-09-06 09:04:10,923 - INFO - step: 1790,loss: 0.082 accuracy: 0.977\n",
      "2017-09-06 09:04:12,142 - INFO - step: 1791,loss: 0.092 accuracy: 0.969\n",
      "2017-09-06 09:04:13,400 - INFO - step: 1792,loss: 0.061 accuracy: 0.984\n",
      "2017-09-06 09:04:14,639 - INFO - step: 1793,loss: 0.149 accuracy: 0.938\n",
      "2017-09-06 09:04:15,851 - INFO - step: 1794,loss: 0.257 accuracy: 0.906\n",
      "2017-09-06 09:04:17,084 - INFO - step: 1795,loss: 0.094 accuracy: 0.969\n",
      "2017-09-06 09:04:18,319 - INFO - step: 1796,loss: 0.135 accuracy: 0.953\n",
      "2017-09-06 09:04:19,513 - INFO - step: 1797,loss: 0.158 accuracy: 0.930\n",
      "2017-09-06 09:04:20,721 - INFO - step: 1798,loss: 0.128 accuracy: 0.953\n",
      "2017-09-06 09:04:21,952 - INFO - step: 1799,loss: 0.136 accuracy: 0.938\n",
      "2017-09-06 09:04:23,088 - INFO - step: 1800,loss: 0.191 accuracy: 0.908\n",
      "2017-09-06 09:04:23,091 - INFO - \n",
      "train_epoch:89.000\n",
      "2017-09-06 09:04:23,093 - INFO - loss_total: 0.144 accuracy_total: 0.939\n",
      "2017-09-06 09:04:24,335 - INFO - step: 1801,loss: 0.096 accuracy: 0.969\n",
      "2017-09-06 09:04:25,570 - INFO - step: 1802,loss: 0.151 accuracy: 0.961\n",
      "2017-09-06 09:04:26,799 - INFO - step: 1803,loss: 0.104 accuracy: 0.977\n",
      "2017-09-06 09:04:27,998 - INFO - step: 1804,loss: 0.170 accuracy: 0.914\n",
      "2017-09-06 09:04:29,224 - INFO - step: 1805,loss: 0.171 accuracy: 0.914\n",
      "2017-09-06 09:04:30,459 - INFO - step: 1806,loss: 0.116 accuracy: 0.953\n",
      "2017-09-06 09:04:31,655 - INFO - step: 1807,loss: 0.083 accuracy: 0.977\n",
      "2017-09-06 09:04:32,884 - INFO - step: 1808,loss: 0.107 accuracy: 0.961\n",
      "2017-09-06 09:04:34,120 - INFO - step: 1809,loss: 0.108 accuracy: 0.969\n",
      "2017-09-06 09:04:35,348 - INFO - step: 1810,loss: 0.102 accuracy: 0.969\n",
      "2017-09-06 09:04:36,596 - INFO - step: 1811,loss: 0.109 accuracy: 0.938\n",
      "2017-09-06 09:04:37,824 - INFO - step: 1812,loss: 0.125 accuracy: 0.930\n",
      "2017-09-06 09:04:39,039 - INFO - step: 1813,loss: 0.190 accuracy: 0.930\n",
      "2017-09-06 09:04:40,252 - INFO - step: 1814,loss: 0.202 accuracy: 0.914\n",
      "2017-09-06 09:04:41,470 - INFO - step: 1815,loss: 0.120 accuracy: 0.953\n",
      "2017-09-06 09:04:42,742 - INFO - step: 1816,loss: 0.127 accuracy: 0.961\n",
      "2017-09-06 09:04:43,965 - INFO - step: 1817,loss: 0.147 accuracy: 0.930\n",
      "2017-09-06 09:04:45,190 - INFO - step: 1818,loss: 0.138 accuracy: 0.938\n",
      "2017-09-06 09:04:46,392 - INFO - step: 1819,loss: 0.180 accuracy: 0.922\n",
      "2017-09-06 09:04:47,494 - INFO - step: 1820,loss: 0.129 accuracy: 0.938\n",
      "2017-09-06 09:04:47,496 - INFO - \n",
      "train_epoch:90.000\n",
      "2017-09-06 09:04:47,498 - INFO - loss_total: 0.134 accuracy_total: 0.946\n",
      "2017-09-06 09:04:47,499 - INFO - \n",
      "Evaluation:90.000\n",
      "2017-09-06 09:04:48,122 - INFO - step: 1820,loss: 0.305 accuracy: 0.903\n",
      "2017-09-06 09:04:48,123 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 09:04:49,347 - INFO - step: 1821,loss: 0.101 accuracy: 0.961\n",
      "2017-09-06 09:04:50,577 - INFO - step: 1822,loss: 0.164 accuracy: 0.930\n",
      "2017-09-06 09:04:51,816 - INFO - step: 1823,loss: 0.140 accuracy: 0.938\n",
      "2017-09-06 09:04:53,038 - INFO - step: 1824,loss: 0.098 accuracy: 0.977\n",
      "2017-09-06 09:04:54,276 - INFO - step: 1825,loss: 0.152 accuracy: 0.953\n",
      "2017-09-06 09:04:55,534 - INFO - step: 1826,loss: 0.184 accuracy: 0.953\n",
      "2017-09-06 09:04:56,763 - INFO - step: 1827,loss: 0.142 accuracy: 0.930\n",
      "2017-09-06 09:04:57,991 - INFO - step: 1828,loss: 0.079 accuracy: 0.977\n",
      "2017-09-06 09:04:59,215 - INFO - step: 1829,loss: 0.139 accuracy: 0.945\n",
      "2017-09-06 09:05:00,435 - INFO - step: 1830,loss: 0.147 accuracy: 0.945\n",
      "2017-09-06 09:05:01,660 - INFO - step: 1831,loss: 0.120 accuracy: 0.969\n",
      "2017-09-06 09:05:02,871 - INFO - step: 1832,loss: 0.101 accuracy: 0.961\n",
      "2017-09-06 09:05:04,097 - INFO - step: 1833,loss: 0.134 accuracy: 0.930\n",
      "2017-09-06 09:05:05,332 - INFO - step: 1834,loss: 0.148 accuracy: 0.922\n",
      "2017-09-06 09:05:06,564 - INFO - step: 1835,loss: 0.126 accuracy: 0.953\n",
      "2017-09-06 09:05:07,790 - INFO - step: 1836,loss: 0.136 accuracy: 0.953\n",
      "2017-09-06 09:05:09,062 - INFO - step: 1837,loss: 0.153 accuracy: 0.930\n",
      "2017-09-06 09:05:10,284 - INFO - step: 1838,loss: 0.158 accuracy: 0.922\n",
      "2017-09-06 09:05:11,516 - INFO - step: 1839,loss: 0.130 accuracy: 0.953\n",
      "2017-09-06 09:05:12,630 - INFO - step: 1840,loss: 0.107 accuracy: 0.969\n",
      "2017-09-06 09:05:12,634 - INFO - \n",
      "train_epoch:91.000\n",
      "2017-09-06 09:05:12,636 - INFO - loss_total: 0.133 accuracy_total: 0.948\n",
      "2017-09-06 09:05:13,886 - INFO - step: 1841,loss: 0.106 accuracy: 0.977\n",
      "2017-09-06 09:05:15,115 - INFO - step: 1842,loss: 0.158 accuracy: 0.930\n",
      "2017-09-06 09:05:16,379 - INFO - step: 1843,loss: 0.191 accuracy: 0.906\n",
      "2017-09-06 09:05:17,603 - INFO - step: 1844,loss: 0.093 accuracy: 0.953\n",
      "2017-09-06 09:05:18,826 - INFO - step: 1845,loss: 0.185 accuracy: 0.914\n",
      "2017-09-06 09:05:20,035 - INFO - step: 1846,loss: 0.145 accuracy: 0.938\n",
      "2017-09-06 09:05:21,249 - INFO - step: 1847,loss: 0.137 accuracy: 0.945\n",
      "2017-09-06 09:05:22,534 - INFO - step: 1848,loss: 0.092 accuracy: 0.969\n",
      "2017-09-06 09:05:23,779 - INFO - step: 1849,loss: 0.111 accuracy: 0.953\n",
      "2017-09-06 09:05:25,010 - INFO - step: 1850,loss: 0.170 accuracy: 0.930\n",
      "2017-09-06 09:05:26,230 - INFO - step: 1851,loss: 0.121 accuracy: 0.953\n",
      "2017-09-06 09:05:27,488 - INFO - step: 1852,loss: 0.126 accuracy: 0.961\n",
      "2017-09-06 09:05:28,695 - INFO - step: 1853,loss: 0.112 accuracy: 0.945\n",
      "2017-09-06 09:05:29,916 - INFO - step: 1854,loss: 0.190 accuracy: 0.906\n",
      "2017-09-06 09:05:31,142 - INFO - step: 1855,loss: 0.147 accuracy: 0.922\n",
      "2017-09-06 09:05:32,377 - INFO - step: 1856,loss: 0.167 accuracy: 0.914\n",
      "2017-09-06 09:05:33,608 - INFO - step: 1857,loss: 0.100 accuracy: 0.961\n",
      "2017-09-06 09:05:34,834 - INFO - step: 1858,loss: 0.099 accuracy: 0.953\n",
      "2017-09-06 09:05:36,055 - INFO - step: 1859,loss: 0.110 accuracy: 0.969\n",
      "2017-09-06 09:05:37,172 - INFO - step: 1860,loss: 0.098 accuracy: 0.969\n",
      "2017-09-06 09:05:37,176 - INFO - \n",
      "train_epoch:92.000\n",
      "2017-09-06 09:05:37,178 - INFO - loss_total: 0.133 accuracy_total: 0.943\n",
      "2017-09-06 09:05:37,180 - INFO - \n",
      "Evaluation:92.000\n",
      "2017-09-06 09:05:37,724 - INFO - step: 1860,loss: 0.334 accuracy: 0.896\n",
      "2017-09-06 09:05:37,725 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 09:05:39,008 - INFO - step: 1861,loss: 0.126 accuracy: 0.930\n",
      "2017-09-06 09:05:40,263 - INFO - step: 1862,loss: 0.118 accuracy: 0.938\n",
      "2017-09-06 09:05:41,484 - INFO - step: 1863,loss: 0.091 accuracy: 0.969\n",
      "2017-09-06 09:05:42,742 - INFO - step: 1864,loss: 0.121 accuracy: 0.938\n",
      "2017-09-06 09:05:43,972 - INFO - step: 1865,loss: 0.101 accuracy: 0.969\n",
      "2017-09-06 09:05:45,208 - INFO - step: 1866,loss: 0.155 accuracy: 0.922\n",
      "2017-09-06 09:05:46,441 - INFO - step: 1867,loss: 0.182 accuracy: 0.914\n",
      "2017-09-06 09:05:47,648 - INFO - step: 1868,loss: 0.121 accuracy: 0.961\n",
      "2017-09-06 09:05:48,872 - INFO - step: 1869,loss: 0.156 accuracy: 0.938\n",
      "2017-09-06 09:05:50,095 - INFO - step: 1870,loss: 0.174 accuracy: 0.898\n",
      "2017-09-06 09:05:51,291 - INFO - step: 1871,loss: 0.074 accuracy: 0.969\n",
      "2017-09-06 09:05:52,522 - INFO - step: 1872,loss: 0.176 accuracy: 0.922\n",
      "2017-09-06 09:05:53,746 - INFO - step: 1873,loss: 0.176 accuracy: 0.922\n",
      "2017-09-06 09:05:54,970 - INFO - step: 1874,loss: 0.187 accuracy: 0.914\n",
      "2017-09-06 09:05:56,191 - INFO - step: 1875,loss: 0.088 accuracy: 0.961\n",
      "2017-09-06 09:05:57,400 - INFO - step: 1876,loss: 0.112 accuracy: 0.977\n",
      "2017-09-06 09:05:58,632 - INFO - step: 1877,loss: 0.113 accuracy: 0.953\n",
      "2017-09-06 09:05:59,860 - INFO - step: 1878,loss: 0.094 accuracy: 0.984\n",
      "2017-09-06 09:06:01,119 - INFO - step: 1879,loss: 0.106 accuracy: 0.961\n",
      "2017-09-06 09:06:02,247 - INFO - step: 1880,loss: 0.181 accuracy: 0.908\n",
      "2017-09-06 09:06:02,250 - INFO - \n",
      "train_epoch:93.000\n",
      "2017-09-06 09:06:02,252 - INFO - loss_total: 0.133 accuracy_total: 0.942\n",
      "2017-09-06 09:06:03,486 - INFO - step: 1881,loss: 0.150 accuracy: 0.922\n",
      "2017-09-06 09:06:04,713 - INFO - step: 1882,loss: 0.140 accuracy: 0.945\n",
      "2017-09-06 09:06:05,969 - INFO - step: 1883,loss: 0.103 accuracy: 0.953\n",
      "2017-09-06 09:06:07,199 - INFO - step: 1884,loss: 0.150 accuracy: 0.930\n",
      "2017-09-06 09:06:08,426 - INFO - step: 1885,loss: 0.115 accuracy: 0.953\n",
      "2017-09-06 09:06:09,648 - INFO - step: 1886,loss: 0.115 accuracy: 0.961\n",
      "2017-09-06 09:06:10,874 - INFO - step: 1887,loss: 0.108 accuracy: 0.961\n",
      "2017-09-06 09:06:12,089 - INFO - step: 1888,loss: 0.135 accuracy: 0.938\n",
      "2017-09-06 09:06:13,326 - INFO - step: 1889,loss: 0.124 accuracy: 0.961\n",
      "2017-09-06 09:06:14,573 - INFO - step: 1890,loss: 0.166 accuracy: 0.906\n",
      "2017-09-06 09:06:15,776 - INFO - step: 1891,loss: 0.099 accuracy: 0.977\n",
      "2017-09-06 09:06:17,011 - INFO - step: 1892,loss: 0.104 accuracy: 0.969\n",
      "2017-09-06 09:06:18,245 - INFO - step: 1893,loss: 0.191 accuracy: 0.914\n",
      "2017-09-06 09:06:19,484 - INFO - step: 1894,loss: 0.121 accuracy: 0.961\n",
      "2017-09-06 09:06:20,711 - INFO - step: 1895,loss: 0.117 accuracy: 0.945\n",
      "2017-09-06 09:06:21,973 - INFO - step: 1896,loss: 0.161 accuracy: 0.930\n",
      "2017-09-06 09:06:23,194 - INFO - step: 1897,loss: 0.066 accuracy: 0.984\n",
      "2017-09-06 09:06:24,438 - INFO - step: 1898,loss: 0.141 accuracy: 0.938\n",
      "2017-09-06 09:06:25,700 - INFO - step: 1899,loss: 0.160 accuracy: 0.930\n",
      "2017-09-06 09:06:26,819 - INFO - step: 1900,loss: 0.103 accuracy: 0.969\n",
      "2017-09-06 09:06:26,823 - INFO - \n",
      "train_epoch:94.000\n",
      "2017-09-06 09:06:26,825 - INFO - loss_total: 0.129 accuracy_total: 0.947\n",
      "2017-09-06 09:06:26,827 - INFO - \n",
      "Evaluation:94.000\n",
      "2017-09-06 09:06:27,427 - INFO - step: 1900,loss: 0.329 accuracy: 0.896\n",
      "2017-09-06 09:06:27,428 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 09:06:28,686 - INFO - step: 1901,loss: 0.171 accuracy: 0.914\n",
      "2017-09-06 09:06:29,949 - INFO - step: 1902,loss: 0.146 accuracy: 0.945\n",
      "2017-09-06 09:06:31,176 - INFO - step: 1903,loss: 0.094 accuracy: 0.984\n",
      "2017-09-06 09:06:32,385 - INFO - step: 1904,loss: 0.068 accuracy: 0.977\n",
      "2017-09-06 09:06:33,622 - INFO - step: 1905,loss: 0.113 accuracy: 0.953\n",
      "2017-09-06 09:06:34,856 - INFO - step: 1906,loss: 0.133 accuracy: 0.945\n",
      "2017-09-06 09:06:36,075 - INFO - step: 1907,loss: 0.116 accuracy: 0.945\n",
      "2017-09-06 09:06:37,297 - INFO - step: 1908,loss: 0.141 accuracy: 0.938\n",
      "2017-09-06 09:06:38,530 - INFO - step: 1909,loss: 0.085 accuracy: 0.969\n",
      "2017-09-06 09:06:39,752 - INFO - step: 1910,loss: 0.171 accuracy: 0.914\n",
      "2017-09-06 09:06:40,980 - INFO - step: 1911,loss: 0.142 accuracy: 0.945\n",
      "2017-09-06 09:06:42,207 - INFO - step: 1912,loss: 0.170 accuracy: 0.922\n",
      "2017-09-06 09:06:43,425 - INFO - step: 1913,loss: 0.123 accuracy: 0.961\n",
      "2017-09-06 09:06:44,652 - INFO - step: 1914,loss: 0.085 accuracy: 0.969\n",
      "2017-09-06 09:06:45,916 - INFO - step: 1915,loss: 0.100 accuracy: 0.953\n",
      "2017-09-06 09:06:47,136 - INFO - step: 1916,loss: 0.192 accuracy: 0.914\n",
      "2017-09-06 09:06:48,336 - INFO - step: 1917,loss: 0.139 accuracy: 0.945\n",
      "2017-09-06 09:06:49,553 - INFO - step: 1918,loss: 0.135 accuracy: 0.938\n",
      "2017-09-06 09:06:50,804 - INFO - step: 1919,loss: 0.160 accuracy: 0.930\n",
      "2017-09-06 09:06:51,917 - INFO - step: 1920,loss: 0.110 accuracy: 0.969\n",
      "2017-09-06 09:06:51,920 - INFO - \n",
      "train_epoch:95.000\n",
      "2017-09-06 09:06:51,922 - INFO - loss_total: 0.130 accuracy_total: 0.947\n",
      "2017-09-06 09:06:53,162 - INFO - step: 1921,loss: 0.159 accuracy: 0.945\n",
      "2017-09-06 09:06:54,395 - INFO - step: 1922,loss: 0.138 accuracy: 0.930\n",
      "2017-09-06 09:06:55,619 - INFO - step: 1923,loss: 0.138 accuracy: 0.945\n",
      "2017-09-06 09:06:56,846 - INFO - step: 1924,loss: 0.122 accuracy: 0.953\n",
      "2017-09-06 09:06:58,078 - INFO - step: 1925,loss: 0.109 accuracy: 0.953\n",
      "2017-09-06 09:06:59,288 - INFO - step: 1926,loss: 0.118 accuracy: 0.945\n",
      "2017-09-06 09:07:00,515 - INFO - step: 1927,loss: 0.108 accuracy: 0.938\n",
      "2017-09-06 09:07:01,707 - INFO - step: 1928,loss: 0.222 accuracy: 0.883\n",
      "2017-09-06 09:07:02,935 - INFO - step: 1929,loss: 0.135 accuracy: 0.930\n",
      "2017-09-06 09:07:04,163 - INFO - step: 1930,loss: 0.070 accuracy: 0.969\n",
      "2017-09-06 09:07:05,382 - INFO - step: 1931,loss: 0.075 accuracy: 0.992\n",
      "2017-09-06 09:07:06,606 - INFO - step: 1932,loss: 0.139 accuracy: 0.930\n",
      "2017-09-06 09:07:07,853 - INFO - step: 1933,loss: 0.176 accuracy: 0.914\n",
      "2017-09-06 09:07:09,110 - INFO - step: 1934,loss: 0.117 accuracy: 0.961\n",
      "2017-09-06 09:07:10,324 - INFO - step: 1935,loss: 0.091 accuracy: 0.969\n",
      "2017-09-06 09:07:11,571 - INFO - step: 1936,loss: 0.119 accuracy: 0.961\n",
      "2017-09-06 09:07:12,794 - INFO - step: 1937,loss: 0.113 accuracy: 0.953\n",
      "2017-09-06 09:07:14,014 - INFO - step: 1938,loss: 0.184 accuracy: 0.922\n",
      "2017-09-06 09:07:15,241 - INFO - step: 1939,loss: 0.143 accuracy: 0.938\n",
      "2017-09-06 09:07:16,360 - INFO - step: 1940,loss: 0.122 accuracy: 0.954\n",
      "2017-09-06 09:07:16,363 - INFO - \n",
      "train_epoch:96.000\n",
      "2017-09-06 09:07:16,365 - INFO - loss_total: 0.130 accuracy_total: 0.944\n",
      "2017-09-06 09:07:16,367 - INFO - \n",
      "Evaluation:96.000\n",
      "2017-09-06 09:07:16,910 - INFO - step: 1940,loss: 0.351 accuracy: 0.899\n",
      "2017-09-06 09:07:16,911 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 09:07:18,145 - INFO - step: 1941,loss: 0.122 accuracy: 0.945\n",
      "2017-09-06 09:07:19,365 - INFO - step: 1942,loss: 0.107 accuracy: 0.953\n",
      "2017-09-06 09:07:20,620 - INFO - step: 1943,loss: 0.119 accuracy: 0.961\n",
      "2017-09-06 09:07:21,881 - INFO - step: 1944,loss: 0.123 accuracy: 0.938\n",
      "2017-09-06 09:07:23,110 - INFO - step: 1945,loss: 0.138 accuracy: 0.945\n",
      "2017-09-06 09:07:24,344 - INFO - step: 1946,loss: 0.116 accuracy: 0.945\n",
      "2017-09-06 09:07:25,598 - INFO - step: 1947,loss: 0.087 accuracy: 0.969\n",
      "2017-09-06 09:07:26,819 - INFO - step: 1948,loss: 0.102 accuracy: 0.969\n",
      "2017-09-06 09:07:27,987 - INFO - step: 1949,loss: 0.130 accuracy: 0.961\n",
      "2017-09-06 09:07:29,212 - INFO - step: 1950,loss: 0.177 accuracy: 0.914\n",
      "2017-09-06 09:07:30,474 - INFO - step: 1951,loss: 0.100 accuracy: 0.969\n",
      "2017-09-06 09:07:31,678 - INFO - step: 1952,loss: 0.129 accuracy: 0.945\n",
      "2017-09-06 09:07:32,878 - INFO - step: 1953,loss: 0.112 accuracy: 0.961\n",
      "2017-09-06 09:07:34,104 - INFO - step: 1954,loss: 0.167 accuracy: 0.930\n",
      "2017-09-06 09:07:35,379 - INFO - step: 1955,loss: 0.106 accuracy: 0.961\n",
      "2017-09-06 09:07:36,592 - INFO - step: 1956,loss: 0.170 accuracy: 0.922\n",
      "2017-09-06 09:07:37,831 - INFO - step: 1957,loss: 0.179 accuracy: 0.914\n",
      "2017-09-06 09:07:39,050 - INFO - step: 1958,loss: 0.133 accuracy: 0.938\n",
      "2017-09-06 09:07:40,316 - INFO - step: 1959,loss: 0.124 accuracy: 0.938\n",
      "2017-09-06 09:07:41,425 - INFO - step: 1960,loss: 0.136 accuracy: 0.923\n",
      "2017-09-06 09:07:41,428 - INFO - \n",
      "train_epoch:97.000\n",
      "2017-09-06 09:07:41,430 - INFO - loss_total: 0.129 accuracy_total: 0.945\n",
      "2017-09-06 09:07:42,672 - INFO - step: 1961,loss: 0.120 accuracy: 0.953\n",
      "2017-09-06 09:07:43,862 - INFO - step: 1962,loss: 0.132 accuracy: 0.922\n",
      "2017-09-06 09:07:45,092 - INFO - step: 1963,loss: 0.175 accuracy: 0.930\n",
      "2017-09-06 09:07:46,326 - INFO - step: 1964,loss: 0.144 accuracy: 0.938\n",
      "2017-09-06 09:07:47,536 - INFO - step: 1965,loss: 0.178 accuracy: 0.898\n",
      "2017-09-06 09:07:48,772 - INFO - step: 1966,loss: 0.156 accuracy: 0.945\n",
      "2017-09-06 09:07:49,989 - INFO - step: 1967,loss: 0.145 accuracy: 0.930\n",
      "2017-09-06 09:07:51,202 - INFO - step: 1968,loss: 0.078 accuracy: 0.969\n",
      "2017-09-06 09:07:52,389 - INFO - step: 1969,loss: 0.101 accuracy: 0.953\n",
      "2017-09-06 09:07:53,606 - INFO - step: 1970,loss: 0.140 accuracy: 0.922\n",
      "2017-09-06 09:07:54,809 - INFO - step: 1971,loss: 0.112 accuracy: 0.945\n",
      "2017-09-06 09:07:56,022 - INFO - step: 1972,loss: 0.166 accuracy: 0.914\n",
      "2017-09-06 09:07:57,241 - INFO - step: 1973,loss: 0.110 accuracy: 0.938\n",
      "2017-09-06 09:07:58,516 - INFO - step: 1974,loss: 0.123 accuracy: 0.938\n",
      "2017-09-06 09:07:59,740 - INFO - step: 1975,loss: 0.129 accuracy: 0.953\n",
      "2017-09-06 09:08:00,959 - INFO - step: 1976,loss: 0.106 accuracy: 0.945\n",
      "2017-09-06 09:08:02,156 - INFO - step: 1977,loss: 0.112 accuracy: 0.961\n",
      "2017-09-06 09:08:03,410 - INFO - step: 1978,loss: 0.117 accuracy: 0.953\n",
      "2017-09-06 09:08:04,662 - INFO - step: 1979,loss: 0.100 accuracy: 0.961\n",
      "2017-09-06 09:08:05,751 - INFO - step: 1980,loss: 0.085 accuracy: 0.985\n",
      "2017-09-06 09:08:05,755 - INFO - \n",
      "train_epoch:98.000\n",
      "2017-09-06 09:08:05,757 - INFO - loss_total: 0.126 accuracy_total: 0.943\n",
      "2017-09-06 09:08:05,758 - INFO - \n",
      "Evaluation:98.000\n",
      "2017-09-06 09:08:06,296 - INFO - step: 1980,loss: 0.333 accuracy: 0.899\n",
      "2017-09-06 09:08:06,298 - INFO - \n",
      "Evaluation-end\n",
      "2017-09-06 09:08:07,473 - INFO - step: 1981,loss: 0.091 accuracy: 0.969\n",
      "2017-09-06 09:08:08,673 - INFO - step: 1982,loss: 0.143 accuracy: 0.930\n",
      "2017-09-06 09:08:09,908 - INFO - step: 1983,loss: 0.095 accuracy: 0.961\n",
      "2017-09-06 09:08:11,159 - INFO - step: 1984,loss: 0.176 accuracy: 0.914\n",
      "2017-09-06 09:08:12,401 - INFO - step: 1985,loss: 0.088 accuracy: 0.984\n",
      "2017-09-06 09:08:13,623 - INFO - step: 1986,loss: 0.144 accuracy: 0.938\n",
      "2017-09-06 09:08:14,855 - INFO - step: 1987,loss: 0.093 accuracy: 0.977\n",
      "2017-09-06 09:08:16,107 - INFO - step: 1988,loss: 0.126 accuracy: 0.953\n",
      "2017-09-06 09:08:17,334 - INFO - step: 1989,loss: 0.111 accuracy: 0.961\n",
      "2017-09-06 09:08:18,562 - INFO - step: 1990,loss: 0.157 accuracy: 0.938\n",
      "2017-09-06 09:08:19,787 - INFO - step: 1991,loss: 0.086 accuracy: 0.977\n",
      "2017-09-06 09:08:21,027 - INFO - step: 1992,loss: 0.181 accuracy: 0.930\n",
      "2017-09-06 09:08:22,297 - INFO - step: 1993,loss: 0.149 accuracy: 0.922\n",
      "2017-09-06 09:08:23,540 - INFO - step: 1994,loss: 0.165 accuracy: 0.898\n",
      "2017-09-06 09:08:24,759 - INFO - step: 1995,loss: 0.230 accuracy: 0.867\n",
      "2017-09-06 09:08:25,992 - INFO - step: 1996,loss: 0.080 accuracy: 0.977\n",
      "2017-09-06 09:08:27,191 - INFO - step: 1997,loss: 0.120 accuracy: 0.953\n",
      "2017-09-06 09:08:28,451 - INFO - step: 1998,loss: 0.128 accuracy: 0.938\n",
      "2017-09-06 09:08:29,673 - INFO - step: 1999,loss: 0.050 accuracy: 0.992\n",
      "2017-09-06 09:08:30,815 - INFO - step: 2000,loss: 0.038 accuracy: 1.000\n",
      "2017-09-06 09:08:30,818 - INFO - \n",
      "train_epoch:99.000\n",
      "2017-09-06 09:08:30,820 - INFO - loss_total: 0.123 accuracy_total: 0.949\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zx/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
